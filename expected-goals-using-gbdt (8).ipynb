{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95291152",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-26T19:37:00.644045Z",
     "iopub.status.busy": "2025-05-26T19:37:00.643713Z",
     "iopub.status.idle": "2025-05-26T19:37:01.346881Z",
     "shell.execute_reply": "2025-05-26T19:37:01.346216Z"
    },
    "papermill": {
     "duration": 0.713491,
     "end_time": "2025-05-26T19:37:01.348792",
     "exception": false,
     "start_time": "2025-05-26T19:37:00.635301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        #print(os.path.join(dirname, filename))\n",
    "        pass\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aaa50c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T19:37:01.362934Z",
     "iopub.status.busy": "2025-05-26T19:37:01.362564Z",
     "iopub.status.idle": "2025-05-26T19:37:58.394537Z",
     "shell.execute_reply": "2025-05-26T19:37:58.393745Z"
    },
    "papermill": {
     "duration": 57.041215,
     "end_time": "2025-05-26T19:37:58.396600",
     "exception": false,
     "start_time": "2025-05-26T19:37:01.355385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install statsbombpy --quiet\n",
    "!pip install optuna --quiet\n",
    "!pip install joblib --quiet\n",
    "!pip install xgboost --quiet\n",
    "!pip install kaleido --quiet\n",
    "!pip install mplsoccer --quiet\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from statsbombpy import sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "398313a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T19:37:58.410905Z",
     "iopub.status.busy": "2025-05-26T19:37:58.410435Z",
     "iopub.status.idle": "2025-05-26T19:37:59.743647Z",
     "shell.execute_reply": "2025-05-26T19:37:59.742944Z"
    },
    "papermill": {
     "duration": 1.342528,
     "end_time": "2025-05-26T19:37:59.745687",
     "exception": false,
     "start_time": "2025-05-26T19:37:58.403159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2302f4aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T19:37:59.761104Z",
     "iopub.status.busy": "2025-05-26T19:37:59.760595Z",
     "iopub.status.idle": "2025-05-26T19:38:00.330824Z",
     "shell.execute_reply": "2025-05-26T19:38:00.330004Z"
    },
    "papermill": {
     "duration": 0.579462,
     "end_time": "2025-05-26T19:38:00.332914",
     "exception": false,
     "start_time": "2025-05-26T19:37:59.753452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1. Bundesliga' 'African Cup of Nations' 'Champions League'\n",
      " 'Copa America' 'Copa del Rey' \"FA Women's Super League\"\n",
      " 'FIFA U20 World Cup' 'FIFA World Cup' 'Indian Super league' 'La Liga'\n",
      " 'Liga Profesional' 'Ligue 1' 'Major League Soccer'\n",
      " 'North American League' 'NWSL' 'Premier League' 'Serie A' 'UEFA Euro'\n",
      " 'UEFA Europa League' \"UEFA Women's Euro\" \"Women's World Cup\"]\n"
     ]
    }
   ],
   "source": [
    "competitions_df = sb.competitions()\n",
    "comp_names = competitions_df['competition_name'].unique()\n",
    "print(comp_names)\n",
    "target = {name: competitions_df.loc[competitions_df['competition_name'] == name, ['competition_id', 'season_id']] for name in comp_names}\n",
    "target_df = pd.concat(target, axis=0, keys=target.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c322941c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T19:38:00.347248Z",
     "iopub.status.busy": "2025-05-26T19:38:00.346893Z",
     "iopub.status.idle": "2025-05-26T19:38:43.691206Z",
     "shell.execute_reply": "2025-05-26T19:38:43.690071Z"
    },
    "papermill": {
     "duration": 43.353711,
     "end_time": "2025-05-26T19:38:43.693386",
     "exception": false,
     "start_time": "2025-05-26T19:38:00.339675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 281\n",
      "9 27\n",
      "1267 107\n",
      "16 4\n",
      "16 1\n",
      "16 2\n",
      "16 27\n",
      "16 26\n",
      "16 25\n",
      "16 24\n",
      "16 23\n",
      "16 22\n",
      "16 21\n",
      "16 41\n",
      "16 39\n",
      "16 37\n",
      "16 44\n",
      "16 76\n",
      "16 277\n",
      "16 71\n",
      "16 276\n",
      "223 282\n",
      "87 84\n",
      "87 268\n",
      "87 279\n",
      "37 90\n",
      "37 42\n",
      "37 4\n",
      "1470 274\n",
      "43 106\n",
      "43 3\n",
      "43 55\n",
      "43 54\n",
      "43 51\n",
      "43 272\n",
      "43 270\n",
      "43 269\n",
      "1238 108\n",
      "11 90\n",
      "11 42\n",
      "11 4\n",
      "11 1\n",
      "11 2\n",
      "11 27\n",
      "11 26\n",
      "11 25\n",
      "11 24\n",
      "11 23\n",
      "11 22\n",
      "11 21\n",
      "11 41\n",
      "11 40\n",
      "11 39\n",
      "11 38\n",
      "11 37\n",
      "11 278\n",
      "81 48\n",
      "81 275\n",
      "7 235\n",
      "7 108\n",
      "7 27\n",
      "44 107\n",
      "116 68\n",
      "49 3\n",
      "2 27\n",
      "2 44\n",
      "12 27\n",
      "12 86\n",
      "55 282\n",
      "55 43\n",
      "35 75\n",
      "53 106\n",
      "72 107\n",
      "72 30\n"
     ]
    }
   ],
   "source": [
    "all_matches = []\n",
    "\n",
    "# Iterate through each row of the target_df DataFrame\n",
    "for _, row in target_df.droplevel(0).iterrows():  # Use droplevel to remove the multi-index created by pd.concat\n",
    "    competition_id = row['competition_id']\n",
    "    season_id = row['season_id']\n",
    "    print(f'{competition_id} {season_id}')\n",
    "    try:\n",
    "        # Fetch matches for the competition and season\n",
    "        matches = sb.matches(competition_id=int(competition_id), season_id=int(season_id))\n",
    "        all_matches.append(matches)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching matches for competition_id={competition_id} and season_id={season_id}: {e}\")\n",
    "\n",
    "# Concatenate all matches into a single DataFrame\n",
    "if all_matches:\n",
    "    matches_df = pd.concat(all_matches, ignore_index=True)\n",
    "else:\n",
    "    matches_df = pd.DataFrame()  # Return an empty DataFrame if no matches are fetched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92fce534",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T19:38:43.714088Z",
     "iopub.status.busy": "2025-05-26T19:38:43.713765Z",
     "iopub.status.idle": "2025-05-26T20:57:02.785760Z",
     "shell.execute_reply": "2025-05-26T20:57:02.784822Z"
    },
    "papermill": {
     "duration": 4699.100565,
     "end_time": "2025-05-26T20:57:02.803934",
     "exception": false,
     "start_time": "2025-05-26T19:38:43.703369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>shot_end_location</th>\n",
       "      <th>shot_statsbomb_xg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[100.4, 35.1]</td>\n",
       "      <td>[101.6, 35.2]</td>\n",
       "      <td>0.056644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[114.6, 33.5]</td>\n",
       "      <td>[118.1, 35.7, 0.2]</td>\n",
       "      <td>0.143381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[106.2, 55.8]</td>\n",
       "      <td>[113.4, 46.8]</td>\n",
       "      <td>0.038188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[113.9, 47.4]</td>\n",
       "      <td>[114.1, 46.8]</td>\n",
       "      <td>0.052781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[89.2, 42.5]</td>\n",
       "      <td>[101.4, 41.3]</td>\n",
       "      <td>0.021272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        location   shot_end_location  shot_statsbomb_xg\n",
       "0  [100.4, 35.1]       [101.6, 35.2]           0.056644\n",
       "1  [114.6, 33.5]  [118.1, 35.7, 0.2]           0.143381\n",
       "2  [106.2, 55.8]       [113.4, 46.8]           0.038188\n",
       "3  [113.9, 47.4]       [114.1, 46.8]           0.052781\n",
       "4   [89.2, 42.5]       [101.4, 41.3]           0.021272"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch event data for a match\n",
    "def fetch_events(match_id):\n",
    "    try:\n",
    "        events = sb.events(match_id=match_id)\n",
    "        # Filter for shots and select only necessary columns\n",
    "        shots = events[events['type'] == 'Shot'][['location', 'shot_end_location', 'shot_statsbomb_xg']]\n",
    "        return shots\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching events for match_id={match_id}: {e}\")\n",
    "        return None  # Return None instead of an empty DataFrame on error\n",
    "\n",
    "# Collect all event data from the matches\n",
    "all_events = [fetch_events(match_id) for match_id in matches_df['match_id']]\n",
    "\n",
    "# Filter out any None values (i.e., matches with errors)\n",
    "all_events = [df for df in all_events if df is not None]\n",
    "\n",
    "# Concatenate all DataFrames at once (more efficient)\n",
    "if all_events:\n",
    "    events_df = pd.concat(all_events, ignore_index=True)\n",
    "else:\n",
    "    events_df = pd.DataFrame()  # In case no valid data was fetched\n",
    "\n",
    "events_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c630ad0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:57:02.839043Z",
     "iopub.status.busy": "2025-05-26T20:57:02.838712Z",
     "iopub.status.idle": "2025-05-26T20:57:02.862057Z",
     "shell.execute_reply": "2025-05-26T20:57:02.860984Z"
    },
    "papermill": {
     "duration": 0.041838,
     "end_time": "2025-05-26T20:57:02.864331",
     "exception": false,
     "start_time": "2025-05-26T20:57:02.822493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shot_statsbomb_xg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>87111.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.106297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.149382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.027673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.054790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.110060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.995122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       shot_statsbomb_xg\n",
       "count       87111.000000\n",
       "mean            0.106297\n",
       "std             0.149382\n",
       "min             0.000180\n",
       "25%             0.027673\n",
       "50%             0.054790\n",
       "75%             0.110060\n",
       "max             0.995122"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a38f60ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:57:02.885930Z",
     "iopub.status.busy": "2025-05-26T20:57:02.885521Z",
     "iopub.status.idle": "2025-05-26T20:57:02.890838Z",
     "shell.execute_reply": "2025-05-26T20:57:02.890026Z"
    },
    "papermill": {
     "duration": 0.017699,
     "end_time": "2025-05-26T20:57:02.892488",
     "exception": false,
     "start_time": "2025-05-26T20:57:02.874789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "events_df.rename(columns={'shot_statsbomb_xg': 'xG'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fabcd56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:57:02.913916Z",
     "iopub.status.busy": "2025-05-26T20:57:02.913071Z",
     "iopub.status.idle": "2025-05-26T20:57:02.918424Z",
     "shell.execute_reply": "2025-05-26T20:57:02.917593Z"
    },
    "papermill": {
     "duration": 0.018383,
     "end_time": "2025-05-26T20:57:02.920629",
     "exception": false,
     "start_time": "2025-05-26T20:57:02.902246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "events_df.rename(columns={\n",
    "        \n",
    "        'location': 'shot_location',\n",
    "        'shot_end_location': 'end_location'\n",
    "        \n",
    "    }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c225d8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:57:02.954872Z",
     "iopub.status.busy": "2025-05-26T20:57:02.954591Z",
     "iopub.status.idle": "2025-05-26T20:57:02.976455Z",
     "shell.execute_reply": "2025-05-26T20:57:02.975580Z"
    },
    "papermill": {
     "duration": 0.039386,
     "end_time": "2025-05-26T20:57:02.978143",
     "exception": false,
     "start_time": "2025-05-26T20:57:02.938757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shot Analysis:\n",
      "  Start: (11.8, 39.6)\n",
      "  End: (1.2, 37.7)\n",
      "  X Direction: -10.6 (towards left goal)\n",
      "  Distance to left goal: 11.8m\n",
      "  Distance to right goal: 108.2m\n",
      "  Target goal: Left\n",
      "  Distance to target: 11.8m\n",
      "  Angle: 80.7°\n",
      "{'target_goal': 'Left', 'distance': 11.775202758339237, 'angle': 80.67459776542395, 'left_goal_distance': 11.775202758339237, 'right_goal_distance': 108.23056592294064}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def determine_target_goal(shot_location, end_location=None):\n",
    "    \"\"\"\n",
    "    Determine which goal the shot is targeting.\n",
    "    Returns goal_center, left_post, right_post for the target goal.\n",
    "    \"\"\"\n",
    "    shot_x, shot_y = shot_location[:2]\n",
    "    \n",
    "    # Define both goals based on your coordinate system\n",
    "    # Left goal (at x=0)\n",
    "    left_goal_center = np.array([0.0, 40.0])\n",
    "    left_goal_left_post = np.array([0.0, 30.0])   # Top post (y=30)\n",
    "    left_goal_right_post = np.array([0.0, 50.0])  # Bottom post (y=50)\n",
    "    \n",
    "    # Right goal (at x=120)\n",
    "    right_goal_center = np.array([120.0, 40.0])\n",
    "    right_goal_left_post = np.array([120.0, 30.0])   # Top post (y=30)\n",
    "    right_goal_right_post = np.array([120.0, 50.0])  # Bottom post (y=50)\n",
    "    \n",
    "    # Calculate distances to both goals\n",
    "    dist_to_left = np.linalg.norm(left_goal_center - np.array([shot_x, shot_y]))\n",
    "    dist_to_right = np.linalg.norm(right_goal_center - np.array([shot_x, shot_y]))\n",
    "    \n",
    "    # If we have end location, use trajectory to determine target\n",
    "    if end_location is not None and len(end_location) >= 2:\n",
    "        end_x, end_y = end_location[:2]\n",
    "        # Check if ball is moving towards left goal (decreasing x) or right goal (increasing x)\n",
    "        x_direction = end_x - shot_x\n",
    "        \n",
    "        if x_direction < 0:  # Moving towards left goal\n",
    "            return left_goal_center, left_goal_left_post, left_goal_right_post\n",
    "        else:  # Moving towards right goal\n",
    "            return right_goal_center, right_goal_left_post, right_goal_right_post\n",
    "    else:\n",
    "        # No end location, use nearest goal\n",
    "        if dist_to_left < dist_to_right:\n",
    "            return left_goal_center, left_goal_left_post, left_goal_right_post\n",
    "        else:\n",
    "            return right_goal_center, right_goal_left_post, right_goal_right_post\n",
    "\n",
    "def calculate_distance_to_goal(shot_location, end_location=None):\n",
    "    \"\"\"Calculate the Euclidean distance from shot location to the center of the target goal.\"\"\"\n",
    "    goal_center, _, _ = determine_target_goal(shot_location, end_location)\n",
    "    shot_loc = np.array(shot_location[:2])  # Take only x, y from shot_location\n",
    "    return np.linalg.norm(goal_center - shot_loc)\n",
    "\n",
    "def calculate_angle_to_goal(shot_location, end_location=None):\n",
    "    \"\"\"Calculate the angle between the shot location and the goalposts of the target goal.\"\"\"\n",
    "    goal_center, left_post, right_post = determine_target_goal(shot_location, end_location)\n",
    "    shot_loc = np.array(shot_location[:2])\n",
    "    \n",
    "    # Calculate distances\n",
    "    left_dist = np.linalg.norm(left_post - shot_loc)\n",
    "    right_dist = np.linalg.norm(right_post - shot_loc)\n",
    "    goal_width = np.linalg.norm(left_post - right_post)\n",
    "    \n",
    "    # Use cosine rule to calculate angle\n",
    "    if left_dist == 0 or right_dist == 0:\n",
    "        return 0  # Prevent division by zero for rare edge cases\n",
    "    \n",
    "    cos_angle = (left_dist**2 + right_dist**2 - goal_width**2) / (2 * left_dist * right_dist)\n",
    "    # Clamp to valid range to avoid numerical errors\n",
    "    cos_angle = np.clip(cos_angle, -1.0, 1.0)\n",
    "    angle = np.arccos(cos_angle)\n",
    "    return np.degrees(angle)\n",
    "\n",
    "def calculate_shot_displacement(start_x, start_y, end_x, end_y):\n",
    "    \"\"\"Calculate the displacement between start and end positions.\"\"\"\n",
    "    displacement = np.sqrt((end_x - start_x)**2 + (end_y - start_y)**2)\n",
    "    return displacement\n",
    "\n",
    "def calculate_shot_trajectory(start_x, start_y, end_x, end_y):\n",
    "    \"\"\"Calculate the trajectory angle in degrees.\"\"\"\n",
    "    return np.arctan2((end_y - start_y), (end_x - start_x)) * 180 / np.pi\n",
    "\n",
    "def process_shot_features(events_df):\n",
    "    \"\"\"\n",
    "    Process all shot features for the events dataframe.\n",
    "    This function handles both goals automatically.\n",
    "    \"\"\"\n",
    "    # Extract starting positions\n",
    "    events_df['starting_x'] = events_df['shot_location'].apply(lambda loc: loc[0])\n",
    "    events_df['starting_y'] = events_df['shot_location'].apply(lambda loc: loc[1])\n",
    "    \n",
    "    # Extract ending positions (ignoring z if present)\n",
    "    events_df[['end_x', 'end_y']] = pd.DataFrame(\n",
    "        events_df['end_location'].apply(lambda loc: loc[:2]).tolist(), \n",
    "        index=events_df.index\n",
    "    )\n",
    "    \n",
    "    # Calculate distance and angle to target goal (using both start and end positions)\n",
    "    events_df['distance_to_goal'] = events_df.apply(\n",
    "        lambda row: calculate_distance_to_goal(\n",
    "            [row['starting_x'], row['starting_y']], \n",
    "            [row['end_x'], row['end_y']]\n",
    "        ), axis=1\n",
    "    )\n",
    "    \n",
    "    events_df['angle_to_goal'] = events_df.apply(\n",
    "        lambda row: calculate_angle_to_goal(\n",
    "            [row['starting_x'], row['starting_y']], \n",
    "            [row['end_x'], row['end_y']]\n",
    "        ), axis=1\n",
    "    )\n",
    "    \n",
    "    # Calculate shot displacement and trajectory\n",
    "    events_df['shot_displacement'] = events_df.apply(\n",
    "        lambda row: calculate_shot_displacement(\n",
    "            row['starting_x'], row['starting_y'], \n",
    "            row['end_x'], row['end_y']\n",
    "        ), axis=1\n",
    "    )\n",
    "    \n",
    "    events_df['shot_trajectory'] = events_df.apply(\n",
    "        lambda row: calculate_shot_trajectory(\n",
    "            row['starting_x'], row['starting_y'], \n",
    "            row['end_x'], row['end_y']\n",
    "        ), axis=1\n",
    "    )\n",
    "    \n",
    "    return events_df\n",
    "\n",
    "def debug_shot_analysis(shot_location, end_location=None):\n",
    "    \"\"\"\n",
    "    Debug function to show which goal is being targeted and why.\n",
    "    Useful for validating the goal selection logic.\n",
    "    \"\"\"\n",
    "    shot_x, shot_y = shot_location[:2]\n",
    "    \n",
    "    # Calculate distances to both goals\n",
    "    left_dist = np.linalg.norm(np.array([0.0, 40.0]) - np.array([shot_x, shot_y]))\n",
    "    right_dist = np.linalg.norm(np.array([120.0, 40.0]) - np.array([shot_x, shot_y]))\n",
    "    \n",
    "    goal_center, left_post, right_post = determine_target_goal(shot_location, end_location)\n",
    "    distance = calculate_distance_to_goal(shot_location, end_location)\n",
    "    angle = calculate_angle_to_goal(shot_location, end_location)\n",
    "    \n",
    "    target_goal = \"Left\" if goal_center[0] == 0 else \"Right\"\n",
    "    \n",
    "    print(f\"Shot Analysis:\")\n",
    "    print(f\"  Start: ({shot_x:.1f}, {shot_y:.1f})\")\n",
    "    if end_location:\n",
    "        end_x, end_y = end_location[:2]\n",
    "        print(f\"  End: ({end_x:.1f}, {end_y:.1f})\")\n",
    "        x_direction = end_x - shot_x\n",
    "        print(f\"  X Direction: {x_direction:.1f} ({'towards left goal' if x_direction < 0 else 'towards right goal'})\")\n",
    "    print(f\"  Distance to left goal: {left_dist:.1f}m\")\n",
    "    print(f\"  Distance to right goal: {right_dist:.1f}m\")\n",
    "    print(f\"  Target goal: {target_goal}\")\n",
    "    print(f\"  Distance to target: {distance:.1f}m\")\n",
    "    print(f\"  Angle: {angle:.1f}°\")\n",
    "    \n",
    "    return {\n",
    "        'target_goal': target_goal,\n",
    "        'distance': distance,\n",
    "        'angle': angle,\n",
    "        'left_goal_distance': left_dist,\n",
    "        'right_goal_distance': right_dist\n",
    "    }\n",
    "\n",
    "\n",
    "print(debug_shot_analysis([11.77, 39.65], [1.17, 37.66]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8edd2631",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:57:02.999660Z",
     "iopub.status.busy": "2025-05-26T20:57:02.999384Z",
     "iopub.status.idle": "2025-05-26T20:57:11.517040Z",
     "shell.execute_reply": "2025-05-26T20:57:11.516255Z"
    },
    "papermill": {
     "duration": 8.530038,
     "end_time": "2025-05-26T20:57:11.518840",
     "exception": false,
     "start_time": "2025-05-26T20:57:02.988802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shot_location</th>\n",
       "      <th>end_location</th>\n",
       "      <th>xG</th>\n",
       "      <th>starting_x</th>\n",
       "      <th>starting_y</th>\n",
       "      <th>end_x</th>\n",
       "      <th>end_y</th>\n",
       "      <th>distance_to_goal</th>\n",
       "      <th>angle_to_goal</th>\n",
       "      <th>shot_displacement</th>\n",
       "      <th>shot_trajectory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[100.4, 35.1]</td>\n",
       "      <td>[101.6, 35.2]</td>\n",
       "      <td>0.056644</td>\n",
       "      <td>100.4</td>\n",
       "      <td>35.1</td>\n",
       "      <td>101.6</td>\n",
       "      <td>35.2</td>\n",
       "      <td>20.203218</td>\n",
       "      <td>51.827413</td>\n",
       "      <td>1.204159</td>\n",
       "      <td>4.763642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[114.6, 33.5]</td>\n",
       "      <td>[118.1, 35.7, 0.2]</td>\n",
       "      <td>0.143381</td>\n",
       "      <td>114.6</td>\n",
       "      <td>33.5</td>\n",
       "      <td>118.1</td>\n",
       "      <td>35.7</td>\n",
       "      <td>8.450444</td>\n",
       "      <td>104.827355</td>\n",
       "      <td>4.134005</td>\n",
       "      <td>32.152295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[106.2, 55.8]</td>\n",
       "      <td>[113.4, 46.8]</td>\n",
       "      <td>0.038188</td>\n",
       "      <td>106.2</td>\n",
       "      <td>55.8</td>\n",
       "      <td>113.4</td>\n",
       "      <td>46.8</td>\n",
       "      <td>20.978084</td>\n",
       "      <td>39.061877</td>\n",
       "      <td>11.525624</td>\n",
       "      <td>-51.340192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[113.9, 47.4]</td>\n",
       "      <td>[114.1, 46.8]</td>\n",
       "      <td>0.052781</td>\n",
       "      <td>113.9</td>\n",
       "      <td>47.4</td>\n",
       "      <td>114.1</td>\n",
       "      <td>46.8</td>\n",
       "      <td>9.590099</td>\n",
       "      <td>93.765758</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>-71.565051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[89.2, 42.5]</td>\n",
       "      <td>[101.4, 41.3]</td>\n",
       "      <td>0.021272</td>\n",
       "      <td>89.2</td>\n",
       "      <td>42.5</td>\n",
       "      <td>101.4</td>\n",
       "      <td>41.3</td>\n",
       "      <td>30.901294</td>\n",
       "      <td>35.775033</td>\n",
       "      <td>12.258874</td>\n",
       "      <td>-5.617581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shot_location        end_location        xG  starting_x  starting_y  end_x  \\\n",
       "0  [100.4, 35.1]       [101.6, 35.2]  0.056644       100.4        35.1  101.6   \n",
       "1  [114.6, 33.5]  [118.1, 35.7, 0.2]  0.143381       114.6        33.5  118.1   \n",
       "2  [106.2, 55.8]       [113.4, 46.8]  0.038188       106.2        55.8  113.4   \n",
       "3  [113.9, 47.4]       [114.1, 46.8]  0.052781       113.9        47.4  114.1   \n",
       "4   [89.2, 42.5]       [101.4, 41.3]  0.021272        89.2        42.5  101.4   \n",
       "\n",
       "   end_y  distance_to_goal  angle_to_goal  shot_displacement  shot_trajectory  \n",
       "0   35.2         20.203218      51.827413           1.204159         4.763642  \n",
       "1   35.7          8.450444     104.827355           4.134005        32.152295  \n",
       "2   46.8         20.978084      39.061877          11.525624       -51.340192  \n",
       "3   46.8          9.590099      93.765758           0.632456       -71.565051  \n",
       "4   41.3         30.901294      35.775033          12.258874        -5.617581  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_df = process_shot_features(events_df)\n",
    "events_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfc679e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:57:11.541250Z",
     "iopub.status.busy": "2025-05-26T20:57:11.540699Z",
     "iopub.status.idle": "2025-05-26T20:57:11.563351Z",
     "shell.execute_reply": "2025-05-26T20:57:11.562515Z"
    },
    "papermill": {
     "duration": 0.03548,
     "end_time": "2025-05-26T20:57:11.564915",
     "exception": false,
     "start_time": "2025-05-26T20:57:11.529435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xG</th>\n",
       "      <th>starting_x</th>\n",
       "      <th>starting_y</th>\n",
       "      <th>end_x</th>\n",
       "      <th>end_y</th>\n",
       "      <th>distance_to_goal</th>\n",
       "      <th>angle_to_goal</th>\n",
       "      <th>shot_displacement</th>\n",
       "      <th>shot_trajectory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.056644</td>\n",
       "      <td>100.4</td>\n",
       "      <td>35.1</td>\n",
       "      <td>101.6</td>\n",
       "      <td>35.2</td>\n",
       "      <td>20.203218</td>\n",
       "      <td>51.827413</td>\n",
       "      <td>1.204159</td>\n",
       "      <td>4.763642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.143381</td>\n",
       "      <td>114.6</td>\n",
       "      <td>33.5</td>\n",
       "      <td>118.1</td>\n",
       "      <td>35.7</td>\n",
       "      <td>8.450444</td>\n",
       "      <td>104.827355</td>\n",
       "      <td>4.134005</td>\n",
       "      <td>32.152295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.038188</td>\n",
       "      <td>106.2</td>\n",
       "      <td>55.8</td>\n",
       "      <td>113.4</td>\n",
       "      <td>46.8</td>\n",
       "      <td>20.978084</td>\n",
       "      <td>39.061877</td>\n",
       "      <td>11.525624</td>\n",
       "      <td>-51.340192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.052781</td>\n",
       "      <td>113.9</td>\n",
       "      <td>47.4</td>\n",
       "      <td>114.1</td>\n",
       "      <td>46.8</td>\n",
       "      <td>9.590099</td>\n",
       "      <td>93.765758</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>-71.565051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.021272</td>\n",
       "      <td>89.2</td>\n",
       "      <td>42.5</td>\n",
       "      <td>101.4</td>\n",
       "      <td>41.3</td>\n",
       "      <td>30.901294</td>\n",
       "      <td>35.775033</td>\n",
       "      <td>12.258874</td>\n",
       "      <td>-5.617581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         xG  starting_x  starting_y  end_x  end_y  distance_to_goal  \\\n",
       "0  0.056644       100.4        35.1  101.6   35.2         20.203218   \n",
       "1  0.143381       114.6        33.5  118.1   35.7          8.450444   \n",
       "2  0.038188       106.2        55.8  113.4   46.8         20.978084   \n",
       "3  0.052781       113.9        47.4  114.1   46.8          9.590099   \n",
       "4  0.021272        89.2        42.5  101.4   41.3         30.901294   \n",
       "\n",
       "   angle_to_goal  shot_displacement  shot_trajectory  \n",
       "0      51.827413           1.204159         4.763642  \n",
       "1     104.827355           4.134005        32.152295  \n",
       "2      39.061877          11.525624       -51.340192  \n",
       "3      93.765758           0.632456       -71.565051  \n",
       "4      35.775033          12.258874        -5.617581  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_df.drop('shot_location', axis = 1, inplace = True)\n",
    "events_df.drop('end_location', axis = 1, inplace = True)\n",
    "events_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17328365",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:57:11.586491Z",
     "iopub.status.busy": "2025-05-26T20:57:11.585846Z",
     "iopub.status.idle": "2025-05-26T20:57:12.385609Z",
     "shell.execute_reply": "2025-05-26T20:57:12.384910Z"
    },
    "papermill": {
     "duration": 0.812647,
     "end_time": "2025-05-26T20:57:12.387621",
     "exception": false,
     "start_time": "2025-05-26T20:57:11.574974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "events_df.to_csv('version1_shots_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06a1d97b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:57:12.409322Z",
     "iopub.status.busy": "2025-05-26T20:57:12.408985Z",
     "iopub.status.idle": "2025-05-26T20:57:12.547445Z",
     "shell.execute_reply": "2025-05-26T20:57:12.546641Z"
    },
    "papermill": {
     "duration": 0.151388,
     "end_time": "2025-05-26T20:57:12.549437",
     "exception": false,
     "start_time": "2025-05-26T20:57:12.398049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>xG</th>\n",
       "      <th>starting_x</th>\n",
       "      <th>starting_y</th>\n",
       "      <th>end_x</th>\n",
       "      <th>end_y</th>\n",
       "      <th>distance_to_goal</th>\n",
       "      <th>angle_to_goal</th>\n",
       "      <th>shot_displacement</th>\n",
       "      <th>shot_trajectory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.056644</td>\n",
       "      <td>100.4</td>\n",
       "      <td>35.1</td>\n",
       "      <td>101.6</td>\n",
       "      <td>35.2</td>\n",
       "      <td>20.203218</td>\n",
       "      <td>51.827413</td>\n",
       "      <td>1.204159</td>\n",
       "      <td>4.763642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.143381</td>\n",
       "      <td>114.6</td>\n",
       "      <td>33.5</td>\n",
       "      <td>118.1</td>\n",
       "      <td>35.7</td>\n",
       "      <td>8.450444</td>\n",
       "      <td>104.827355</td>\n",
       "      <td>4.134005</td>\n",
       "      <td>32.152295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.038188</td>\n",
       "      <td>106.2</td>\n",
       "      <td>55.8</td>\n",
       "      <td>113.4</td>\n",
       "      <td>46.8</td>\n",
       "      <td>20.978084</td>\n",
       "      <td>39.061877</td>\n",
       "      <td>11.525624</td>\n",
       "      <td>-51.340192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.052781</td>\n",
       "      <td>113.9</td>\n",
       "      <td>47.4</td>\n",
       "      <td>114.1</td>\n",
       "      <td>46.8</td>\n",
       "      <td>9.590099</td>\n",
       "      <td>93.765758</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>-71.565051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.021272</td>\n",
       "      <td>89.2</td>\n",
       "      <td>42.5</td>\n",
       "      <td>101.4</td>\n",
       "      <td>41.3</td>\n",
       "      <td>30.901294</td>\n",
       "      <td>35.775033</td>\n",
       "      <td>12.258874</td>\n",
       "      <td>-5.617581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        xG  starting_x  starting_y  end_x  end_y  \\\n",
       "0           0  0.056644       100.4        35.1  101.6   35.2   \n",
       "1           1  0.143381       114.6        33.5  118.1   35.7   \n",
       "2           2  0.038188       106.2        55.8  113.4   46.8   \n",
       "3           3  0.052781       113.9        47.4  114.1   46.8   \n",
       "4           4  0.021272        89.2        42.5  101.4   41.3   \n",
       "\n",
       "   distance_to_goal  angle_to_goal  shot_displacement  shot_trajectory  \n",
       "0         20.203218      51.827413           1.204159         4.763642  \n",
       "1          8.450444     104.827355           4.134005        32.152295  \n",
       "2         20.978084      39.061877          11.525624       -51.340192  \n",
       "3          9.590099      93.765758           0.632456       -71.565051  \n",
       "4         30.901294      35.775033          12.258874        -5.617581  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =  pd.read_csv('/kaggle/working/version1_shots_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00ad93b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:57:12.572425Z",
     "iopub.status.busy": "2025-05-26T20:57:12.572085Z",
     "iopub.status.idle": "2025-05-26T20:57:12.579281Z",
     "shell.execute_reply": "2025-05-26T20:57:12.578622Z"
    },
    "papermill": {
     "duration": 0.020491,
     "end_time": "2025-05-26T20:57:12.580934",
     "exception": false,
     "start_time": "2025-05-26T20:57:12.560443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.drop('Unnamed: 0', axis =1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b606c499",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:57:12.602414Z",
     "iopub.status.busy": "2025-05-26T20:57:12.602149Z",
     "iopub.status.idle": "2025-05-26T20:57:15.731626Z",
     "shell.execute_reply": "2025-05-26T20:57:15.730431Z"
    },
    "papermill": {
     "duration": 3.144925,
     "end_time": "2025-05-26T20:57:15.735994",
     "exception": false,
     "start_time": "2025-05-26T20:57:12.591069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting enhanced feature engineering...\n",
      "Feature engineering complete. Dataset shape: (87111, 36)\n",
      "         xG  starting_x  starting_y  end_x  end_y  distance_to_goal  \\\n",
      "0  0.056644       100.4        35.1  101.6   35.2         20.203218   \n",
      "1  0.143381       114.6        33.5  118.1   35.7          8.450444   \n",
      "2  0.038188       106.2        55.8  113.4   46.8         20.978084   \n",
      "3  0.052781       113.9        47.4  114.1   46.8          9.590099   \n",
      "4  0.021272        89.2        42.5  101.4   41.3         30.901294   \n",
      "\n",
      "   angle_to_goal  shot_displacement  shot_trajectory  tactical_zone  ...  \\\n",
      "0      51.827413           1.204159         4.763642             12  ...   \n",
      "1     104.827355           4.134005        32.152295             12  ...   \n",
      "2      39.061877          11.525624       -51.340192             18  ...   \n",
      "3      93.765758           0.632456       -71.565051             12  ...   \n",
      "4      35.775033          12.258874        -5.617581             11  ...   \n",
      "\n",
      "   position_quality  distance_angle_interaction  zone14_distance_interaction  \\\n",
      "0          0.451475                 1047.080509                     0.000000   \n",
      "1          0.606307                  885.837668                     0.000000   \n",
      "2          0.420664                  819.443335                     0.000000   \n",
      "3          0.578133                  899.222904                     0.000000   \n",
      "4          0.582074                 1105.494836                    30.901294   \n",
      "\n",
      "   penalty_box_angle  shot_direction_category  direction_Sharp_Left  \\\n",
      "0           0.000000                   Center                 False   \n",
      "1         104.827355                    Right                 False   \n",
      "2          39.061877                     Left                 False   \n",
      "3          93.765758                     Left                 False   \n",
      "4           0.000000                   Center                 False   \n",
      "\n",
      "   direction_Left  direction_Center  direction_Right  direction_Sharp_Right  \n",
      "0           False              True            False                  False  \n",
      "1           False             False             True                  False  \n",
      "2            True             False            False                  False  \n",
      "3            True             False            False                  False  \n",
      "4           False              True            False                  False  \n",
      "\n",
      "[5 rows x 36 columns]\n",
      "Using 31 features for modeling\n"
     ]
    }
   ],
   "source": [
    "zone_boundaries = {\n",
    "            'horizontal': [0, 20, 40, 60, 80, 100, 120],  # 6 zones\n",
    "            'vertical': [0, 26.67, 53.33, 80]  # 3 zones\n",
    "}\n",
    "        \n",
    "# Special zones of interest\n",
    "zone_14_left = {'x': (20, 40), 'y': (26.67, 53.33)}  # Left Zone 14\n",
    "zone_14_right = {'x': (80, 100), 'y': (26.67, 53.33)}  # Right Zone 14\n",
    "\n",
    "# Goal definitions\n",
    "left_goal = {'center': [0, 40], 'posts': [[0, 30], [0, 50]]}\n",
    "right_goal = {'center': [120, 40], 'posts': [[120, 30], [120, 50]]}\n",
    "        \n",
    "def assign_tactical_zone(x, y):\n",
    "    \"\"\"Assign tactical zone (1-18) based on x,y coordinates\"\"\"\n",
    "    # Determine horizontal zone (1-6)\n",
    "    h_zone = 1\n",
    "    for i, boundary in enumerate(zone_boundaries['horizontal'][1:], 1):\n",
    "        if x <= boundary:\n",
    "            h_zone = i\n",
    "            break\n",
    "    \n",
    "    # Determine vertical zone (1-3)\n",
    "    v_zone = 1\n",
    "    for i, boundary in enumerate(zone_boundaries['vertical'][1:], 1):\n",
    "        if y <= boundary:\n",
    "            v_zone = i\n",
    "            break\n",
    "    \n",
    "    # Calculate final zone (1-18)\n",
    "    zone = (v_zone - 1) * 6 + h_zone\n",
    "    return zone\n",
    "\n",
    "def is_zone_14( x, y):\n",
    "    \"\"\"Check if position is in Zone 14 (either side)\"\"\"\n",
    "    left_14 = (zone_14_left['x'][0] <= x <= zone_14_left['x'][1] and \n",
    "              zone_14_left['y'][0] <= y <= zone_14_left['y'][1])\n",
    "    right_14 = (zone_14_right['x'][0] <= x <= zone_14_right['x'][1] and \n",
    "               zone_14_right['y'][0] <= y <= zone_14_right['y'][1])\n",
    "    return left_14 or right_14\n",
    "    \n",
    "def calculate_advanced_features(df):\n",
    "    \"\"\"Calculate advanced tactical and spatial features\"\"\"\n",
    "    enhanced_df = df.copy()\n",
    "    \n",
    "    # Basic zone assignment\n",
    "    enhanced_df['tactical_zone'] = enhanced_df.apply(\n",
    "        lambda row: assign_tactical_zone(row['starting_x'], row['starting_y']), axis=1\n",
    "    )\n",
    "    \n",
    "    # Zone 14 indicator\n",
    "    enhanced_df['is_zone_14'] = enhanced_df.apply(\n",
    "        lambda row: is_zone_14(row['starting_x'], row['starting_y']), axis=1\n",
    "    )\n",
    "    \n",
    "    # Central corridor (middle third vertically)\n",
    "    enhanced_df['is_central_corridor'] = (\n",
    "        (enhanced_df['starting_y'] >= 26.67) & \n",
    "        (enhanced_df['starting_y'] <= 53.33)\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Penalty box features\n",
    "    enhanced_df['is_in_left_penalty_box'] = (\n",
    "        (enhanced_df['starting_x'] <= 18) & \n",
    "        (enhanced_df['starting_y'] >= 18) & \n",
    "        (enhanced_df['starting_y'] <= 62)\n",
    "    ).astype(int)\n",
    "    \n",
    "    enhanced_df['is_in_right_penalty_box'] = (\n",
    "        (enhanced_df['starting_x'] >= 102) & \n",
    "        (enhanced_df['starting_y'] >= 18) & \n",
    "        (enhanced_df['starting_y'] <= 62)\n",
    "    ).astype(int)\n",
    "        \n",
    "    # Six-yard box features\n",
    "    enhanced_df['is_in_left_six_yard'] = (\n",
    "        (enhanced_df['starting_x'] <= 6) & \n",
    "        (enhanced_df['starting_y'] >= 30) & \n",
    "        (enhanced_df['starting_y'] <= 50)\n",
    "    ).astype(int)\n",
    "    \n",
    "    enhanced_df['is_in_right_six_yard'] = (\n",
    "        (enhanced_df['starting_x'] >= 114) & \n",
    "        (enhanced_df['starting_y'] >= 30) & \n",
    "        (enhanced_df['starting_y'] <= 50)\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Distance to penalty spot\n",
    "    enhanced_df['distance_to_left_penalty_spot'] = np.sqrt(\n",
    "        (enhanced_df['starting_x'] - 12)**2 + \n",
    "        (enhanced_df['starting_y'] - 40)**2\n",
    "    )\n",
    "    \n",
    "    enhanced_df['distance_to_right_penalty_spot'] = np.sqrt(\n",
    "        (enhanced_df['starting_x'] - 108)**2 + \n",
    "        (enhanced_df['starting_y'] - 40)**2\n",
    "    )\n",
    "        \n",
    "    # Wing position indicators\n",
    "    enhanced_df['is_left_wing'] = (enhanced_df['starting_y'] <= 26.67).astype(int)\n",
    "    enhanced_df['is_right_wing'] = (enhanced_df['starting_y'] >= 53.33).astype(int)\n",
    "    \n",
    "    # Shot precision (how close to goal center the shot ended)\n",
    "    enhanced_df['shot_precision_left'] = np.sqrt(\n",
    "        (enhanced_df['end_x'] - 0)**2 + \n",
    "        (enhanced_df['end_y'] - 40)**2\n",
    "    )\n",
    "    \n",
    "    enhanced_df['shot_precision_right'] = np.sqrt(\n",
    "        (enhanced_df['end_x'] - 120)**2 + \n",
    "        (enhanced_df['end_y'] - 40)**2\n",
    "    )\n",
    "    \n",
    "    # Goal mouth targeting (how well centered the shot was)\n",
    "    enhanced_df['goal_mouth_accuracy'] = enhanced_df.apply(\n",
    "        calculate_goal_mouth_accuracy, axis=1\n",
    "    )\n",
    "    \n",
    "    # Shot power proxy (displacement/time would be better, but using displacement)\n",
    "    enhanced_df['shot_power_proxy'] = enhanced_df['shot_displacement']\n",
    "    \n",
    "    # Angle quality (normalized angle - better angles get higher scores)\n",
    "    max_angle = enhanced_df['angle_to_goal'].max()\n",
    "    enhanced_df['angle_quality'] = enhanced_df['angle_to_goal'] / max_angle\n",
    "    \n",
    "    # Distance quality (inverse relationship - closer is better)\n",
    "    max_distance = enhanced_df['distance_to_goal'].max()\n",
    "    enhanced_df['distance_quality'] = 1 - (enhanced_df['distance_to_goal'] / max_distance)\n",
    "        \n",
    "    # Combined position quality score\n",
    "    enhanced_df['position_quality'] = (\n",
    "        enhanced_df['angle_quality'] * 0.4 + \n",
    "        enhanced_df['distance_quality'] * 0.4 + \n",
    "        enhanced_df['is_zone_14'].astype(int) * 0.2\n",
    "    )\n",
    "    \n",
    "    return enhanced_df\n",
    "    \n",
    "def calculate_goal_mouth_accuracy(row):\n",
    "    \"\"\"Calculate how accurately the shot was aimed at goal center\"\"\"\n",
    "    # Determine target goal based on shot direction\n",
    "    if row['end_x'] < row['starting_x']:  # Shooting towards left goal\n",
    "        target_center_y = 40\n",
    "    else:  # Shooting towards right goal\n",
    "        target_center_y = 40\n",
    "    \n",
    "    # Distance from goal center (vertically)\n",
    "    accuracy = abs(row['end_y'] - target_center_y)\n",
    "    return accuracy\n",
    "    \n",
    "def create_zone_heatmap(df, save_path='tactical_zones_heatmap.png'):\n",
    "    \"\"\"Create heatmap showing xG by tactical zone\"\"\"\n",
    "    zone_xg = df.groupby('tactical_zone')['xG'].agg(['mean', 'count']).reset_index()\n",
    "    \n",
    "    # Create 3x6 grid for zones\n",
    "    heatmap_data = np.zeros((3, 6))\n",
    "    \n",
    "    for _, row in zone_xg.iterrows():\n",
    "        zone = int(row['tactical_zone'])\n",
    "        if row['count'] >= 5:  # Only show zones with sufficient data\n",
    "            v_idx = (zone - 1) // 6\n",
    "            h_idx = (zone - 1) % 6\n",
    "            heatmap_data[v_idx, h_idx] = row['mean']\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(heatmap_data, annot=True, cmap='YlOrRd', \n",
    "               xticklabels=[f'H{i+1}' for i in range(6)],\n",
    "               yticklabels=[f'V{i+1}' for i in range(3)])\n",
    "    plt.title('Average xG by Tactical Zone')\n",
    "    plt.xlabel('Horizontal Zones (Left to Right)')\n",
    "    plt.ylabel('Vertical Zones (Top to Bottom)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "print(\"Starting enhanced feature engineering...\")\n",
    "\n",
    "# Calculate advanced features\n",
    "enhanced_df = calculate_advanced_features(data)\n",
    "        \n",
    "# Create interaction features\n",
    "enhanced_df['distance_angle_interaction'] = (\n",
    "    enhanced_df['distance_to_goal'] * enhanced_df['angle_to_goal']\n",
    ")\n",
    "\n",
    "enhanced_df['zone14_distance_interaction'] = (\n",
    "    enhanced_df['is_zone_14'].astype(int) * enhanced_df['distance_to_goal']\n",
    ")\n",
    "\n",
    "enhanced_df['penalty_box_angle'] = (\n",
    "    (enhanced_df['is_in_left_penalty_box'] + enhanced_df['is_in_right_penalty_box']) * \n",
    "    enhanced_df['angle_to_goal']\n",
    ")\n",
    "        \n",
    "# Shot trajectory categorization\n",
    "enhanced_df['shot_direction_category'] = pd.cut(\n",
    "    enhanced_df['shot_trajectory'], \n",
    "    bins=[-180, -90, -30, 30, 90, 180], \n",
    "    labels=['Sharp_Left', 'Left', 'Center', 'Right', 'Sharp_Right']\n",
    ")\n",
    "\n",
    "# One-hot encode categorical features\n",
    "direction_dummies = pd.get_dummies(enhanced_df['shot_direction_category'], prefix='direction')\n",
    "enhanced_df = pd.concat([enhanced_df, direction_dummies], axis=1)\n",
    "\n",
    "print(f\"Feature engineering complete. Dataset shape: {enhanced_df.shape}\")\n",
    "       \n",
    "\n",
    "create_zone_heatmap(enhanced_df)\n",
    "    \n",
    "# Select features for modeling\n",
    "feature_cols = [\n",
    "    # Original features\n",
    "    'distance_to_goal', 'angle_to_goal', 'starting_x', 'starting_y', \n",
    "    'end_x', 'end_y', 'shot_displacement', 'shot_trajectory',\n",
    "    \n",
    "    # New tactical features\n",
    "    'tactical_zone', 'is_zone_14', 'is_central_corridor',\n",
    "    'is_in_left_penalty_box', 'is_in_right_penalty_box',\n",
    "    'is_in_left_six_yard', 'is_in_right_six_yard',\n",
    "    'distance_to_left_penalty_spot', 'distance_to_right_penalty_spot',\n",
    "    'is_left_wing', 'is_right_wing',\n",
    "    'goal_mouth_accuracy', 'angle_quality', 'distance_quality',\n",
    "    'position_quality',\n",
    "    \n",
    "    # Interaction features\n",
    "    'distance_angle_interaction', 'zone14_distance_interaction',\n",
    "    'penalty_box_angle',\n",
    "    \n",
    "    # Direction features\n",
    "    'direction_Center', 'direction_Left', 'direction_Right', \n",
    "    'direction_Sharp_Left', 'direction_Sharp_Right'\n",
    "]\n",
    "\n",
    "target_col = 'xG'\n",
    "print(enhanced_df.head())\n",
    "# Handle missing columns\n",
    "available_features = [col for col in feature_cols if col in enhanced_df.columns]\n",
    "print(f\"Using {len(available_features)} features for modeling\")\n",
    "\n",
    "features = enhanced_df[available_features]\n",
    "Y = enhanced_df[target_col]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f405f85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:57:15.805473Z",
     "iopub.status.busy": "2025-05-26T20:57:15.804581Z",
     "iopub.status.idle": "2025-05-26T20:57:18.212668Z",
     "shell.execute_reply": "2025-05-26T20:57:18.211907Z"
    },
    "papermill": {
     "duration": 2.445038,
     "end_time": "2025-05-26T20:57:18.214707",
     "exception": false,
     "start_time": "2025-05-26T20:57:15.769669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "enhanced_df.to_csv('enhanced_version1_shots_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7041a417",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:57:18.236839Z",
     "iopub.status.busy": "2025-05-26T20:57:18.236560Z",
     "iopub.status.idle": "2025-05-26T20:57:26.327032Z",
     "shell.execute_reply": "2025-05-26T20:57:26.325842Z"
    },
    "papermill": {
     "duration": 8.103687,
     "end_time": "2025-05-26T20:57:26.329025",
     "exception": false,
     "start_time": "2025-05-26T20:57:18.225338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install kaleido --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b176e78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:57:26.352655Z",
     "iopub.status.busy": "2025-05-26T20:57:26.352325Z",
     "iopub.status.idle": "2025-05-26T21:05:12.034711Z",
     "shell.execute_reply": "2025-05-26T21:05:12.033517Z"
    },
    "papermill": {
     "duration": 465.696789,
     "end_time": "2025-05-26T21:05:12.036631",
     "exception": false,
     "start_time": "2025-05-26T20:57:26.339842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Analyzing 29 numerical columns...\n",
      "📊 Processing xG (1/29)...\n",
      "✅ Saved: xG_analysis.png\n",
      "📊 Processing starting_x (2/29)...\n",
      "✅ Saved: starting_x_analysis.png\n",
      "📊 Processing starting_y (3/29)...\n",
      "✅ Saved: starting_y_analysis.png\n",
      "📊 Processing end_x (4/29)...\n",
      "✅ Saved: end_x_analysis.png\n",
      "📊 Processing end_y (5/29)...\n",
      "✅ Saved: end_y_analysis.png\n",
      "📊 Processing distance_to_goal (6/29)...\n",
      "✅ Saved: distance_to_goal_analysis.png\n",
      "📊 Processing angle_to_goal (7/29)...\n",
      "✅ Saved: angle_to_goal_analysis.png\n",
      "📊 Processing shot_displacement (8/29)...\n",
      "✅ Saved: shot_displacement_analysis.png\n",
      "📊 Processing shot_trajectory (9/29)...\n",
      "✅ Saved: shot_trajectory_analysis.png\n",
      "📊 Processing tactical_zone (10/29)...\n",
      "✅ Saved: tactical_zone_analysis.png\n",
      "📊 Processing is_central_corridor (11/29)...\n",
      "✅ Saved: is_central_corridor_analysis.png\n",
      "📊 Processing is_in_left_penalty_box (12/29)...\n",
      "✅ Saved: is_in_left_penalty_box_analysis.png\n",
      "📊 Processing is_in_right_penalty_box (13/29)...\n",
      "✅ Saved: is_in_right_penalty_box_analysis.png\n",
      "📊 Processing is_in_left_six_yard (14/29)...\n",
      "✅ Saved: is_in_left_six_yard_analysis.png\n",
      "📊 Processing is_in_right_six_yard (15/29)...\n",
      "✅ Saved: is_in_right_six_yard_analysis.png\n",
      "📊 Processing distance_to_left_penalty_spot (16/29)...\n",
      "✅ Saved: distance_to_left_penalty_spot_analysis.png\n",
      "📊 Processing distance_to_right_penalty_spot (17/29)...\n",
      "✅ Saved: distance_to_right_penalty_spot_analysis.png\n",
      "📊 Processing is_left_wing (18/29)...\n",
      "✅ Saved: is_left_wing_analysis.png\n",
      "📊 Processing is_right_wing (19/29)...\n",
      "✅ Saved: is_right_wing_analysis.png\n",
      "📊 Processing shot_precision_left (20/29)...\n",
      "✅ Saved: shot_precision_left_analysis.png\n",
      "📊 Processing shot_precision_right (21/29)...\n",
      "✅ Saved: shot_precision_right_analysis.png\n",
      "📊 Processing goal_mouth_accuracy (22/29)...\n",
      "✅ Saved: goal_mouth_accuracy_analysis.png\n",
      "📊 Processing shot_power_proxy (23/29)...\n",
      "✅ Saved: shot_power_proxy_analysis.png\n",
      "📊 Processing angle_quality (24/29)...\n",
      "✅ Saved: angle_quality_analysis.png\n",
      "📊 Processing distance_quality (25/29)...\n",
      "✅ Saved: distance_quality_analysis.png\n",
      "📊 Processing position_quality (26/29)...\n",
      "✅ Saved: position_quality_analysis.png\n",
      "📊 Processing distance_angle_interaction (27/29)...\n",
      "✅ Saved: distance_angle_interaction_analysis.png\n",
      "📊 Processing zone14_distance_interaction (28/29)...\n",
      "✅ Saved: zone14_distance_interaction_analysis.png\n",
      "📊 Processing penalty_box_angle (29/29)...\n",
      "✅ Saved: penalty_box_angle_analysis.png\n",
      "📈 Creating correlation heatmap...\n",
      "✅ Saved: correlation_heatmap.png\n",
      "\n",
      "📋 Analysis Summary:\n",
      "✅ Successfully analyzed: 29 columns\n"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# High-quality plot configuration\n",
    "PLOT_CONFIG = {\n",
    "    'toImageButtonOptions': {\n",
    "        'format': 'png',\n",
    "        'filename': 'plot',\n",
    "        'height': 1200,\n",
    "        'width': 1200,\n",
    "        'scale': 3  # High DPI\n",
    "    }\n",
    "}\n",
    "\n",
    "# Modern color palette\n",
    "COLORS = {\n",
    "    'primary': '#6366f1',      # Indigo\n",
    "    'secondary': '#ec4899',    # Pink\n",
    "    'tertiary': '#10b981',     # Emerald\n",
    "    'background': '#f8fafc',   # Slate-50\n",
    "    'text': '#1e293b',         # Slate-800\n",
    "    'light': '#e2e8f0',       # Slate-200\n",
    "    'accent': '#f59e0b'        # Amber\n",
    "}\n",
    "\n",
    "def safe_kde(data, x_range=None):\n",
    "    \"\"\"\n",
    "    Safely create KDE, handling edge cases that cause LinAlgError.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if data has sufficient variance\n",
    "        if len(np.unique(data)) < 2 or np.std(data) < 1e-10:\n",
    "            # If data is constant or nearly constant, return uniform distribution\n",
    "            if x_range is None:\n",
    "                x_range = np.linspace(data.min() - 0.1, data.max() + 0.1, 100)\n",
    "            return x_range, np.ones_like(x_range) / len(x_range)\n",
    "        \n",
    "        # Try to create KDE\n",
    "        kde = stats.gaussian_kde(data)\n",
    "        if x_range is None:\n",
    "            data_range = data.max() - data.min()\n",
    "            padding = data_range * 0.1 if data_range > 0 else 1\n",
    "            x_range = np.linspace(data.min() - padding, data.max() + padding, 200)\n",
    "        \n",
    "        y_kde = kde(x_range)\n",
    "        return x_range, y_kde\n",
    "        \n",
    "    except (np.linalg.LinAlgError, ValueError):\n",
    "        # Fallback: create a simple histogram-like density\n",
    "        if x_range is None:\n",
    "            x_range = np.linspace(data.min() - 0.1, data.max() + 0.1, 100)\n",
    "        \n",
    "        hist, bin_edges = np.histogram(data, bins=min(30, len(np.unique(data))))\n",
    "        # Interpolate histogram to x_range\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "        y_kde = np.interp(x_range, bin_centers, hist)\n",
    "        y_kde = y_kde / np.trapz(y_kde, x_range)  # Normalize\n",
    "        \n",
    "        return x_range, y_kde\n",
    "\n",
    "def create_comprehensive_plot(data, column):\n",
    "    \"\"\"\n",
    "    Create a comprehensive, high-quality plot for a single variable.\n",
    "    \"\"\"\n",
    "    col_data = data[column].dropna()\n",
    "    \n",
    "    if len(col_data) == 0:\n",
    "        print(f\"Warning: No valid data for column '{column}'\")\n",
    "        return None\n",
    "    \n",
    "    # Create subplots with improved layout\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=2,\n",
    "        subplot_titles=[\n",
    "            '📊 Distribution & Density', '📦 Box Plot Analysis',\n",
    "            '🌧️ Raincloud Visualization', '📈 Cumulative Distribution',\n",
    "            '🎯 Normality Assessment', '📋 Statistical Summary'\n",
    "        ],\n",
    "        specs=[\n",
    "            [{'type': 'xy'}, {'type': 'xy'}],\n",
    "            [{'type': 'xy'}, {'type': 'xy'}],\n",
    "            [{'type': 'xy'}, {'type': 'table'}]\n",
    "        ],\n",
    "        vertical_spacing=0.08,\n",
    "        horizontal_spacing=0.1\n",
    "    )\n",
    "\n",
    "    # 1. Enhanced Histogram + KDE\n",
    "    try:\n",
    "        # Create histogram\n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=col_data,\n",
    "                name='Distribution',\n",
    "                nbinsx=min(50, max(10, len(np.unique(col_data)))),\n",
    "                marker=dict(\n",
    "                    color=COLORS['light'],\n",
    "                    line=dict(color=COLORS['primary'], width=1)\n",
    "                ),\n",
    "                opacity=0.7,\n",
    "                histnorm='probability density'\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Add KDE if possible\n",
    "        x_range, y_kde = safe_kde(col_data)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=x_range,\n",
    "                y=y_kde,\n",
    "                mode='lines',\n",
    "                name='Density Curve',\n",
    "                line=dict(color=COLORS['primary'], width=3),\n",
    "                fill='tonexty',\n",
    "                fillcolor=f\"rgba(99, 102, 241, 0.1)\"\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not create KDE for {column}: {e}\")\n",
    "        # Fallback to histogram only\n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=col_data,\n",
    "                name='Distribution',\n",
    "                marker=dict(color=COLORS['primary']),\n",
    "                opacity=0.7\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "    # 2. Enhanced Box Plot\n",
    "    fig.add_trace(\n",
    "        go.Box(\n",
    "            y=col_data,\n",
    "            name=column,\n",
    "            marker=dict(color=COLORS['secondary']),\n",
    "            line=dict(color=COLORS['text']),\n",
    "            boxmean='sd',  # Show mean and standard deviation\n",
    "            notched=True,\n",
    "            boxpoints='outliers'\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # 3. Raincloud Plot\n",
    "    try:\n",
    "        x_kde, y_kde = safe_kde(col_data)\n",
    "        \n",
    "        # Mirrored KDE (cloud part)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=x_kde,\n",
    "                y=y_kde,\n",
    "                mode='lines',\n",
    "                name='Upper Density',\n",
    "                line=dict(color=COLORS['tertiary'], width=2),\n",
    "                fill='tozeroy',\n",
    "                fillcolor=f\"rgba(16, 185, 129, 0.3)\",\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=x_kde,\n",
    "                y=-y_kde,\n",
    "                mode='lines',\n",
    "                name='Lower Density',\n",
    "                line=dict(color=COLORS['tertiary'], width=2),\n",
    "                fill='tozeroy',\n",
    "                fillcolor=f\"rgba(16, 185, 129, 0.3)\",\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # Rain (jittered points)\n",
    "        n_points = min(1000, len(col_data))  # Limit points for performance\n",
    "        if len(col_data) > n_points:\n",
    "            sample_idx = np.random.choice(len(col_data), n_points, replace=False)\n",
    "            sample_data = col_data.iloc[sample_idx]\n",
    "        else:\n",
    "            sample_data = col_data\n",
    "            \n",
    "        jitter = np.random.normal(0, max(y_kde) * 0.05, size=len(sample_data))\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=sample_data,\n",
    "                y=jitter,\n",
    "                mode='markers',\n",
    "                name='Data Points',\n",
    "                marker=dict(\n",
    "                    color=COLORS['accent'],\n",
    "                    size=4,\n",
    "                    opacity=0.6,\n",
    "                    line=dict(width=0.5, color=COLORS['text'])\n",
    "                ),\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not create raincloud plot for {column}: {e}\")\n",
    "        # Fallback to simple scatter\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=col_data,\n",
    "                y=np.zeros_like(col_data),\n",
    "                mode='markers',\n",
    "                name='Data Points',\n",
    "                marker=dict(color=COLORS['primary'], size=4)\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "\n",
    "    # 4. ECDF\n",
    "    ecdf = ECDF(col_data)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=ecdf.x,\n",
    "            y=ecdf.y,\n",
    "            mode='lines',\n",
    "            name='ECDF',\n",
    "            line=dict(color=COLORS['primary'], width=3),\n",
    "            fill='tonexty',\n",
    "            fillcolor=f\"rgba(99, 102, 241, 0.1)\"\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "\n",
    "    # 5. Q-Q Plot for normality assessment\n",
    "    try:\n",
    "        qq = stats.probplot(col_data, dist=\"norm\")\n",
    "        \n",
    "        # Data points\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=qq[0][0],\n",
    "                y=qq[0][1],\n",
    "                mode='markers',\n",
    "                name='Observed',\n",
    "                marker=dict(\n",
    "                    color=COLORS['secondary'],\n",
    "                    size=6,\n",
    "                    opacity=0.7,\n",
    "                    line=dict(width=1, color=COLORS['text'])\n",
    "                ),\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=3, col=1\n",
    "        )\n",
    "        \n",
    "        # Reference line\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=qq[0][0],\n",
    "                y=qq[1][0] * qq[0][0] + qq[1][1],\n",
    "                mode='lines',\n",
    "                name='Expected Normal',\n",
    "                line=dict(color=COLORS['accent'], width=3, dash='dash'),\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=3, col=1\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not create Q-Q plot for {column}: {e}\")\n",
    "\n",
    "    # 6. Statistical Summary Table\n",
    "    stats_summary = col_data.describe()\n",
    "    skewness = stats.skew(col_data)\n",
    "    kurtosis = stats.kurtosis(col_data)\n",
    "    \n",
    "    # Calculate additional statistics\n",
    "    cv = stats_summary['std'] / stats_summary['mean'] if stats_summary['mean'] != 0 else 0\n",
    "    range_val = stats_summary['max'] - stats_summary['min']\n",
    "    \n",
    "    # Outlier detection\n",
    "    Q1, Q3 = stats_summary['25%'], stats_summary['75%']\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = col_data[(col_data < Q1 - 1.5 * IQR) | (col_data > Q3 + 1.5 * IQR)]\n",
    "    \n",
    "    # Create summary table\n",
    "    summary_data = [\n",
    "        ['Count', f\"{len(col_data):,}\"],\n",
    "        ['Mean', f\"{stats_summary['mean']:.3f}\"],\n",
    "        ['Median', f\"{stats_summary['50%']:.3f}\"],\n",
    "        ['Std Dev', f\"{stats_summary['std']:.3f}\"],\n",
    "        ['Min', f\"{stats_summary['min']:.3f}\"],\n",
    "        ['Max', f\"{stats_summary['max']:.3f}\"],\n",
    "        ['Range', f\"{range_val:.3f}\"],\n",
    "        ['Coeff. of Var.', f\"{cv:.3f}\"],\n",
    "        ['Skewness', f\"{skewness:.3f}\"],\n",
    "        ['Kurtosis', f\"{kurtosis:.3f}\"],\n",
    "        ['Outliers', f\"{len(outliers)} ({len(outliers)/len(col_data)*100:.1f}%)\"],\n",
    "        ['Normality', interpret_normality(col_data)]\n",
    "    ]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Table(\n",
    "            header=dict(\n",
    "                values=['<b>Statistic</b>', '<b>Value</b>'],\n",
    "                fill_color=COLORS['primary'],\n",
    "                font=dict(color='white', size=12),\n",
    "                align='left'\n",
    "            ),\n",
    "            cells=dict(\n",
    "                values=list(zip(*summary_data)),\n",
    "                fill_color=[COLORS['background'], 'white'],\n",
    "                font=dict(color=COLORS['text'], size=11),\n",
    "                align='left'\n",
    "            )\n",
    "        ),\n",
    "        row=3, col=2\n",
    "    )\n",
    "\n",
    "    # Update layout with modern styling\n",
    "    fig.update_layout(\n",
    "        height=1200,\n",
    "        width=1200,\n",
    "        title=dict(\n",
    "            text=f\"<b>Comprehensive Analysis: {column}</b>\",\n",
    "            font=dict(size=20, color=COLORS['text']),\n",
    "            x=0.5\n",
    "        ),\n",
    "        showlegend=False,\n",
    "        plot_bgcolor='white',\n",
    "        paper_bgcolor='white',\n",
    "        font=dict(family=\"Arial, sans-serif\", color=COLORS['text'])\n",
    "    )\n",
    "    \n",
    "    # Update axes styling\n",
    "    for i in range(1, 6):  # 5 subplot axes\n",
    "        fig.update_xaxes(\n",
    "            showgrid=True,\n",
    "            gridwidth=1,\n",
    "            gridcolor=COLORS['light'],\n",
    "            zeroline=False,\n",
    "            row=(i-1)//2 + 1,\n",
    "            col=(i-1)%2 + 1\n",
    "        )\n",
    "        fig.update_yaxes(\n",
    "            showgrid=True,\n",
    "            gridwidth=1,\n",
    "            gridcolor=COLORS['light'],\n",
    "            zeroline=False,\n",
    "            row=(i-1)//2 + 1,\n",
    "            col=(i-1)%2 + 1\n",
    "        )\n",
    "\n",
    "    return fig\n",
    "\n",
    "def interpret_normality(data):\n",
    "    \"\"\"Assess normality using Shapiro-Wilk test.\"\"\"\n",
    "    if len(data) > 5000:\n",
    "        # Use Kolmogorov-Smirnov for large samples\n",
    "        _, p_value = stats.kstest(data, 'norm', args=(data.mean(), data.std()))\n",
    "        test_name = \"K-S\"\n",
    "    else:\n",
    "        # Use Shapiro-Wilk for smaller samples\n",
    "        _, p_value = stats.shapiro(data)\n",
    "        test_name = \"S-W\"\n",
    "    \n",
    "    if p_value > 0.05:\n",
    "        return f\"Normal ({test_name} p={p_value:.3f})\"\n",
    "    else:\n",
    "        return f\"Non-normal ({test_name} p={p_value:.3f})\"\n",
    "\n",
    "def create_correlation_heatmap(data, columns):\n",
    "    \"\"\"Create an enhanced correlation heatmap.\"\"\"\n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = data[columns].corr()\n",
    "    \n",
    "    # Create mask for upper triangle\n",
    "    mask = np.triu(np.ones_like(corr_matrix))\n",
    "    corr_matrix_masked = corr_matrix.mask(mask.astype(bool))\n",
    "    \n",
    "    # Create heatmap\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=corr_matrix.values,\n",
    "        x=corr_matrix.columns,\n",
    "        y=corr_matrix.columns,\n",
    "        colorscale=[\n",
    "            [0, '#d73027'],      # Strong negative\n",
    "            [0.25, '#fc8d59'],   # Moderate negative\n",
    "            [0.5, '#ffffbf'],    # Neutral\n",
    "            [0.75, '#91bfdb'],   # Moderate positive\n",
    "            [1, '#4575b4']       # Strong positive\n",
    "        ],\n",
    "        zmin=-1, zmax=1,\n",
    "        text=np.round(corr_matrix.values, 2),\n",
    "        texttemplate=\"%{text}\",\n",
    "        textfont=dict(size=10, color='black'),\n",
    "        hoverongaps=False,\n",
    "        hovertemplate='<b>%{y}</b> vs <b>%{x}</b><br>Correlation: %{z:.3f}<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text='<b>Feature Correlation Matrix</b>',\n",
    "            font=dict(size=18, color=COLORS['text']),\n",
    "            x=0.5\n",
    "        ),\n",
    "        height=600,\n",
    "        width=700,\n",
    "        xaxis=dict(\n",
    "            tickangle=45,\n",
    "            side='bottom',\n",
    "            title='Features'\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title='Features',\n",
    "            autorange='reversed'\n",
    "        ),\n",
    "        plot_bgcolor='white',\n",
    "        paper_bgcolor='white'\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def analyze_dataset(data, columns_to_analyze=None):\n",
    "    \"\"\"\n",
    "    Analyze entire dataset with improved error handling and performance.\n",
    "    \"\"\"\n",
    "    if columns_to_analyze is None:\n",
    "        columns_to_analyze = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    print(f\"🔍 Analyzing {len(columns_to_analyze)} numerical columns...\")\n",
    "    \n",
    "    successful_plots = 0\n",
    "    failed_plots = []\n",
    "    \n",
    "    # Analyze each column\n",
    "    for i, column in enumerate(columns_to_analyze, 1):\n",
    "        try:\n",
    "            print(f\"📊 Processing {column} ({i}/{len(columns_to_analyze)})...\")\n",
    "            fig = create_comprehensive_plot(data, column)\n",
    "            \n",
    "            if fig:\n",
    "                # Save with high quality\n",
    "                filename = f\"{column.replace('/', '_').replace(' ', '_')}_analysis.png\"\n",
    "                fig.write_image(filename, width=1200, height=1200, scale=3)\n",
    "                successful_plots += 1\n",
    "                print(f\"✅ Saved: {filename}\")\n",
    "            else:\n",
    "                failed_plots.append(column)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error analyzing {column}: {str(e)}\")\n",
    "            failed_plots.append(column)\n",
    "    \n",
    "    # Create correlation heatmap\n",
    "    try:\n",
    "        print(\"📈 Creating correlation heatmap...\")\n",
    "        corr_fig = create_correlation_heatmap(data, columns_to_analyze)\n",
    "        corr_fig.write_image(\"correlation_heatmap.png\", width=700, height=600, scale=3)\n",
    "        print(\"✅ Saved: correlation_heatmap.png\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error creating correlation heatmap: {str(e)}\")\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n📋 Analysis Summary:\")\n",
    "    print(f\"✅ Successfully analyzed: {successful_plots} columns\")\n",
    "    if failed_plots:\n",
    "        print(f\"❌ Failed to analyze: {len(failed_plots)} columns\")\n",
    "        print(f\"   Failed columns: {', '.join(failed_plots)}\")\n",
    "    \n",
    "    return successful_plots, failed_plots\n",
    "\n",
    "\n",
    "successful, failed = analyze_dataset(enhanced_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcb054a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T21:05:12.061869Z",
     "iopub.status.busy": "2025-05-26T21:05:12.061297Z",
     "iopub.status.idle": "2025-05-26T21:05:12.067502Z",
     "shell.execute_reply": "2025-05-26T21:05:12.066666Z"
    },
    "papermill": {
     "duration": 0.020499,
     "end_time": "2025-05-26T21:05:12.069135",
     "exception": false,
     "start_time": "2025-05-26T21:05:12.048636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['xG', 'starting_x', 'starting_y', 'end_x', 'end_y', 'distance_to_goal',\n",
       "       'angle_to_goal', 'shot_displacement', 'shot_trajectory',\n",
       "       'tactical_zone', 'is_zone_14', 'is_central_corridor',\n",
       "       'is_in_left_penalty_box', 'is_in_right_penalty_box',\n",
       "       'is_in_left_six_yard', 'is_in_right_six_yard',\n",
       "       'distance_to_left_penalty_spot', 'distance_to_right_penalty_spot',\n",
       "       'is_left_wing', 'is_right_wing', 'shot_precision_left',\n",
       "       'shot_precision_right', 'goal_mouth_accuracy', 'shot_power_proxy',\n",
       "       'angle_quality', 'distance_quality', 'position_quality',\n",
       "       'distance_angle_interaction', 'zone14_distance_interaction',\n",
       "       'penalty_box_angle', 'shot_direction_category', 'direction_Sharp_Left',\n",
       "       'direction_Left', 'direction_Center', 'direction_Right',\n",
       "       'direction_Sharp_Right'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8f4160a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T21:05:12.093538Z",
     "iopub.status.busy": "2025-05-26T21:05:12.093058Z",
     "iopub.status.idle": "2025-05-26T21:05:12.096523Z",
     "shell.execute_reply": "2025-05-26T21:05:12.095730Z"
    },
    "papermill": {
     "duration": 0.017058,
     "end_time": "2025-05-26T21:05:12.098036",
     "exception": false,
     "start_time": "2025-05-26T21:05:12.080978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# features = [col for col in enhanced_df.columns if col != 'xG']\n",
    "# Y = 'xG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01d78a86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T21:05:12.122488Z",
     "iopub.status.busy": "2025-05-26T21:05:12.122148Z",
     "iopub.status.idle": "2025-05-26T21:05:12.125585Z",
     "shell.execute_reply": "2025-05-26T21:05:12.124799Z"
    },
    "papermill": {
     "duration": 0.017361,
     "end_time": "2025-05-26T21:05:12.127147",
     "exception": false,
     "start_time": "2025-05-26T21:05:12.109786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93a789d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T21:05:12.152115Z",
     "iopub.status.busy": "2025-05-26T21:05:12.151648Z",
     "iopub.status.idle": "2025-05-26T21:05:12.155190Z",
     "shell.execute_reply": "2025-05-26T21:05:12.154403Z"
    },
    "papermill": {
     "duration": 0.017946,
     "end_time": "2025-05-26T21:05:12.156825",
     "exception": false,
     "start_time": "2025-05-26T21:05:12.138879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92e24aff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T21:05:12.184352Z",
     "iopub.status.busy": "2025-05-26T21:05:12.184007Z",
     "iopub.status.idle": "2025-05-26T21:05:28.366632Z",
     "shell.execute_reply": "2025-05-26T21:05:28.365523Z"
    },
    "papermill": {
     "duration": 16.199074,
     "end_time": "2025-05-26T21:05:28.368562",
     "exception": false,
     "start_time": "2025-05-26T21:05:12.169488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /opt/conda/lib/python3.10/site-packages (4.2.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from lightgbm) (1.26.4)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from lightgbm) (1.14.1)\r\n",
      "Requirement already satisfied: xgboost[gpu] in /opt/conda/lib/python3.10/site-packages (2.0.3)\r\n",
      "\u001b[33mWARNING: xgboost 2.0.3 does not provide the extra 'gpu'\u001b[0m\u001b[33m\r\n",
      "\u001b[0mRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xgboost[gpu]) (1.26.4)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from xgboost[gpu]) (1.14.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm --config-settings=cmake.define.USE_CUDA=ON\n",
    "!pip install xgboost[gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81e4f99e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T21:05:28.395247Z",
     "iopub.status.busy": "2025-05-26T21:05:28.394901Z",
     "iopub.status.idle": "2025-05-26T21:05:28.411166Z",
     "shell.execute_reply": "2025-05-26T21:05:28.410439Z"
    },
    "papermill": {
     "duration": 0.031957,
     "end_time": "2025-05-26T21:05:28.412860",
     "exception": false,
     "start_time": "2025-05-26T21:05:28.380903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# from sklearn.inspection import permutation_importance\n",
    "# from sklearn.metrics import make_scorer\n",
    "# from xgboost import XGBRegressor\n",
    "# from lightgbm import LGBMRegressor\n",
    "# import json\n",
    "# import joblib\n",
    "# import optuna\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# def check_gpu_availability():\n",
    "#     \"\"\"Check if GPU is available for XGBoost and LightGBM\"\"\"\n",
    "#     print(\"Checking GPU availability...\")\n",
    "    \n",
    "#     # Check XGBoost GPU support\n",
    "#     try:\n",
    "#         import xgboost as xgb\n",
    "#         xgb_gpu = xgb.XGBRegressor(device='cuda', n_estimators=1)\n",
    "#         print(\"✓ XGBoost GPU support available\")\n",
    "#         xgb_device = 'cuda'\n",
    "#     except:\n",
    "#         print(\"✗ XGBoost GPU support not available, using CPU\")\n",
    "#         xgb_device = 'cpu'\n",
    "    \n",
    "#     # Check LightGBM GPU support\n",
    "#     try:\n",
    "#         import lightgbm as lgb\n",
    "#         lgb_gpu = lgb.LGBMRegressor(device='gpu', n_estimators=1)\n",
    "#         print(\"✓ LightGBM GPU support available\")\n",
    "#         lgb_device = 'gpu'\n",
    "#     except:\n",
    "#         print(\"✗ LightGBM GPU support not available, using CPU\")\n",
    "#         lgb_device = 'cpu'\n",
    "    \n",
    "#     return xgb_device, lgb_device\n",
    "\n",
    "# def prepare_data(data, features, target):\n",
    "#     \"\"\"\n",
    "#     Prepare data for training with proper feature selection, encoding, and validation\n",
    "#     \"\"\"\n",
    "#     from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "#     print(f\"Data shape: {data.shape}\")\n",
    "#     print(f\"Features type: {type(features)}\")\n",
    "#     print(f\"Target type: {type(target)}\")\n",
    "    \n",
    "#     # Convert features to list if it's not already\n",
    "#     if isinstance(features, pd.DataFrame):\n",
    "#         feature_list = features.columns.tolist()\n",
    "#         print(\"Features was a DataFrame, using column names\")\n",
    "#     elif isinstance(features, pd.Series):\n",
    "#         feature_list = features.tolist()\n",
    "#         print(\"Features was a Series, converting to list\")\n",
    "#     elif isinstance(features, (list, tuple)):\n",
    "#         feature_list = list(features)\n",
    "#         print(\"Features is already a list/tuple\")\n",
    "#     else:\n",
    "#         raise ValueError(f\"Features must be a list, tuple, Series, or DataFrame. Got {type(features)}\")\n",
    "    \n",
    "#     # Convert target to string if it's not already\n",
    "#     if isinstance(target, pd.Series):\n",
    "#         target_name = target.name if target.name else str(target.iloc[0])\n",
    "#         print(f\"Target was a Series, using name: {target_name}\")\n",
    "#     elif isinstance(target, (list, tuple)):\n",
    "#         target_name = target[0] if len(target) == 1 else str(target)\n",
    "#         print(f\"Target was a list/tuple, using: {target_name}\")\n",
    "#     else:\n",
    "#         target_name = str(target)\n",
    "#         print(f\"Target converted to string: {target_name}\")\n",
    "    \n",
    "#     # Validate features exist in data\n",
    "#     missing_features = [f for f in feature_list if f not in data.columns]\n",
    "#     if missing_features:\n",
    "#         print(f\"Missing features in data: {missing_features}\")\n",
    "#         print(f\"Available columns: {list(data.columns)}\")\n",
    "#         raise ValueError(f\"Features not found in data: {missing_features}\")\n",
    "    \n",
    "#     # Validate target exists in data\n",
    "#     if target_name not in data.columns:\n",
    "#         print(f\"Target '{target_name}' not found in data\")\n",
    "#         print(f\"Available columns: {list(data.columns)}\")\n",
    "#         raise ValueError(f\"Target '{target_name}' not found in data\")\n",
    "    \n",
    "#     print(f\"Using {len(feature_list)} features: {feature_list[:5]}...\" if len(feature_list) > 5 else f\"Using features: {feature_list}\")\n",
    "#     print(f\"Using target: {target_name}\")\n",
    "    \n",
    "#     # Select features and target\n",
    "#     X = data[feature_list].copy()\n",
    "#     y = data[target_name].copy()\n",
    "    \n",
    "#     # Check data types and identify categorical columns\n",
    "#     print(\"\\nData type analysis:\")\n",
    "#     categorical_columns = []\n",
    "#     numeric_columns = []\n",
    "    \n",
    "#     for col in X.columns:\n",
    "#         dtype = X[col].dtype\n",
    "#         unique_vals = X[col].nunique()\n",
    "#         print(f\"{col}: {dtype}, unique values: {unique_vals}\")\n",
    "        \n",
    "#         if dtype == 'object' or dtype == 'category':\n",
    "#             categorical_columns.append(col)\n",
    "#         elif dtype in ['int64', 'float64', 'bool']:\n",
    "#             numeric_columns.append(col)\n",
    "#         else:\n",
    "#             # Handle other dtypes case by case\n",
    "#             if X[col].dtype.name.startswith('int') or X[col].dtype.name.startswith('float'):\n",
    "#                 numeric_columns.append(col)\n",
    "#             else:\n",
    "#                 categorical_columns.append(col)\n",
    "    \n",
    "#     print(f\"\\nCategorical columns ({len(categorical_columns)}): {categorical_columns}\")\n",
    "#     print(f\"Numeric columns ({len(numeric_columns)}): {numeric_columns}\")\n",
    "    \n",
    "#     # Encode categorical variables\n",
    "#     label_encoders = {}\n",
    "#     if categorical_columns:\n",
    "#         print(\"\\nEncoding categorical variables...\")\n",
    "#         for col in categorical_columns:\n",
    "#             print(f\"Encoding {col}: {list(X[col].unique())}\")\n",
    "#             le = LabelEncoder()\n",
    "#             X[col] = le.fit_transform(X[col].astype(str))\n",
    "#             label_encoders[col] = le\n",
    "    \n",
    "#     # Check for missing values\n",
    "#     if X.isnull().sum().sum() > 0:\n",
    "#         print(\"Warning: Missing values found in features\")\n",
    "#         print(X.isnull().sum()[X.isnull().sum() > 0])\n",
    "#         # Fill missing values with median for numeric, mode for categorical\n",
    "#         for col in X.columns:\n",
    "#             if X[col].isnull().sum() > 0:\n",
    "#                 if col in categorical_columns:\n",
    "#                     X[col].fillna(X[col].mode()[0], inplace=True)\n",
    "#                 else:\n",
    "#                     X[col].fillna(X[col].median(), inplace=True)\n",
    "    \n",
    "#     if y.isnull().sum() > 0:\n",
    "#         print(f\"Warning: {y.isnull().sum()} missing values found in target\")\n",
    "#         # Remove rows with missing target values\n",
    "#         mask = ~y.isnull()\n",
    "#         X = X[mask]\n",
    "#         y = y[mask]\n",
    "#         print(f\"Removed {(~mask).sum()} rows with missing target values\")\n",
    "    \n",
    "#     # Ensure all data is numeric\n",
    "#     print(\"\\nFinal data type check:\")\n",
    "#     for col in X.columns:\n",
    "#         if not pd.api.types.is_numeric_dtype(X[col]):\n",
    "#             print(f\"Warning: {col} is still not numeric, converting...\")\n",
    "#             X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "#             if X[col].isnull().sum() > 0:\n",
    "#                 X[col].fillna(X[col].median(), inplace=True)\n",
    "    \n",
    "#     # Split the data\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "#     print(f\"\\nData shapes after split:\")\n",
    "#     print(f\"X_train: {X_train.shape}\")\n",
    "#     print(f\"X_test: {X_test.shape}\")\n",
    "#     print(f\"y_train: {y_train.shape}\")\n",
    "#     print(f\"y_test: {y_test.shape}\")\n",
    "    \n",
    "#     # Scale the features\n",
    "#     scaler = StandardScaler()\n",
    "#     X_train_scaled = scaler.fit_transform(X_train)\n",
    "#     X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "#     print(f\"Training set shape after scaling: {X_train_scaled.shape}\")\n",
    "#     print(f\"Test set shape after scaling: {X_test_scaled.shape}\")\n",
    "    \n",
    "#     return X_train_scaled, X_test_scaled, y_train, y_test, scaler, feature_list, label_encoders\n",
    "\n",
    "# def custom_score(y_true, y_pred):\n",
    "#     mse = mean_squared_error(y_true, y_pred)\n",
    "#     mae = mean_absolute_error(y_true, y_pred)\n",
    "#     r2 = r2_score(y_true, y_pred)\n",
    "#     # Avoid division by zero\n",
    "#     score = r2  # Start with R²\n",
    "#     if mse > 0:\n",
    "#         score += 1 / (1 + mse)  # Add inverse MSE (normalized)\n",
    "#     if mae > 0:\n",
    "#         score += 1 / (1 + mae)  # Add inverse MAE (normalized)\n",
    "#     return score\n",
    "\n",
    "# def optimize_xgboost(X_train_scaled, y_train, n_trials, device='cuda'):\n",
    "#     def objective(trial):\n",
    "#         params = {\n",
    "#             'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "#             'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.5, log=True),\n",
    "#             'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n",
    "#             'min_child_weight': trial.suggest_int('min_child_weight', 1, 20),\n",
    "#             'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "#             'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "#             'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n",
    "#             'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log=True),\n",
    "#             'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log=True),\n",
    "#             'max_leaves': trial.suggest_int('max_leaves', 0, 1000),\n",
    "#             'max_bin': trial.suggest_int('max_bin', 200, 1000),\n",
    "#             'device': device,\n",
    "#             'tree_method': 'hist' if device == 'cuda' else 'auto'\n",
    "#         }\n",
    "      \n",
    "#         model = XGBRegressor(**params, random_state=42)\n",
    "#         try:\n",
    "#             scores = cross_val_score(\n",
    "#                 model, X_train_scaled, y_train,\n",
    "#                 cv=5,\n",
    "#                 scoring=make_scorer(custom_score, greater_is_better=True),\n",
    "#                 n_jobs=1 if device == 'cuda' else -1\n",
    "#             )\n",
    "#             return -scores.mean()\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error in XGBoost trial: {e}\")\n",
    "#             return float('inf')\n",
    "\n",
    "#     study = optuna.create_study(direction='minimize')\n",
    "#     study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "#     return study.best_params\n",
    "\n",
    "# def optimize_lightgbm(X_train_scaled, y_train, n_trials, device='gpu'):\n",
    "#     def objective(trial):\n",
    "#         params = {\n",
    "#             'num_leaves': trial.suggest_int('num_leaves', 5, 100),\n",
    "#             'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.5, log=True),\n",
    "#             'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n",
    "#             'min_child_samples': trial.suggest_int('min_child_samples', 1, 300),\n",
    "#             'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "#             'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "#             'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "#             'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "#             'max_depth': trial.suggest_int('max_depth', -1, 20),\n",
    "#             'min_split_gain': trial.suggest_float('min_split_gain', 1e-8, 1.0, log=True),\n",
    "#             'max_bin': trial.suggest_int('max_bin', 200, 1000),\n",
    "#             'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt', 'goss']),\n",
    "#             'device': device,\n",
    "#             'gpu_use_dp': True if device == 'gpu' else False,\n",
    "#             'force_col_wise': True if device == 'gpu' else False\n",
    "#         }\n",
    "        \n",
    "#         model = LGBMRegressor(**params, random_state=42, verbose=-1)\n",
    "#         try:\n",
    "#             scores = cross_val_score(\n",
    "#                 model, X_train_scaled, y_train,\n",
    "#                 cv=5,\n",
    "#                 scoring=make_scorer(custom_score, greater_is_better=True),\n",
    "#                 n_jobs=1 if device == 'gpu' else -1\n",
    "#             )\n",
    "#             return -scores.mean()\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error in LightGBM trial: {e}\")\n",
    "#             return float('inf')\n",
    "\n",
    "#     study = optuna.create_study(direction='minimize')\n",
    "#     study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "#     return study.best_params\n",
    "\n",
    "# def train_and_evaluate_model(model_class, best_params, X_train_scaled, y_train, X_test_scaled, y_test, features, model_name):\n",
    "#     # Add verbose=-1 for LightGBM to reduce output\n",
    "#     if model_class == LGBMRegressor:\n",
    "#         best_params['verbose'] = -1\n",
    "    \n",
    "#     model = model_class(**best_params, random_state=42)\n",
    "    \n",
    "#     print(f\"Training {model_name} on {'GPU' if ('device' in best_params and best_params['device'] in ['cuda', 'gpu']) else 'CPU'}...\")\n",
    "#     model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "#     y_pred = model.predict(X_test_scaled)\n",
    "#     mse = mean_squared_error(y_test, y_pred)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "#     print(f'{model_name} Results:')\n",
    "#     print(f'Mean Squared Error: {mse:.6f}')\n",
    "#     print(f'Root Mean Squared Error: {rmse:.6f}')\n",
    "#     print(f'R-squared Score: {r2:.6f}')\n",
    "    \n",
    "#     joblib.dump(model, f'best_{model_name.lower()}_model.pkl')\n",
    "    \n",
    "#     plot_feature_importance(model, features, model_name)\n",
    "#     plot_predicted_vs_true(y_test, y_pred, mse, rmse, r2, model_name)\n",
    "    \n",
    "#     return model, mse, rmse, r2\n",
    "\n",
    "# def plot_feature_importance(model, features, model_name):\n",
    "#     feature_importance = model.feature_importances_\n",
    "    \n",
    "#     plt.figure(figsize=(12, 8))\n",
    "#     sns.barplot(x=feature_importance, y=features, orient='h', palette='viridis')\n",
    "#     plt.title(f'Feature Importance - {model_name}', fontsize=16)\n",
    "#     plt.xlabel('Importance', fontsize=12)\n",
    "#     plt.ylabel('Features', fontsize=12)\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(f'{model_name.lower()}_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "#     plt.close()\n",
    "\n",
    "# def plot_predicted_vs_true(y_test, y_pred, mse, rmse, r2, model_name):\n",
    "#     plt.figure(figsize=(10, 8))\n",
    "#     plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "#     plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "#     plt.xlabel('True xG', fontsize=12)\n",
    "#     plt.ylabel('Predicted xG', fontsize=12)\n",
    "#     plt.title(f'{model_name} - Predicted vs. True xG', fontsize=16)\n",
    "#     plt.annotate(f'MSE: {mse:.3f}\\nRMSE: {rmse:.3f}\\nR²: {r2:.3f}',\n",
    "#                  xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "#                  bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=0.8),\n",
    "#                  fontsize=10)\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(f'{model_name.lower()}_predicted_vs_true.png', dpi=300, bbox_inches='tight')\n",
    "#     plt.close()\n",
    "\n",
    "# def save_model(model, model_name, accuracy, error):\n",
    "#     filename = f\"{model_name}_acc_{accuracy:.4f}_err_{error:.4f}.pkl\"\n",
    "#     joblib.dump(model, filename)\n",
    "#     print(f\"Model saved as {filename}\")\n",
    "\n",
    "# def save_metrics_and_params(model_name, metrics, params, n_trials, n_features):\n",
    "#     data = {\n",
    "#         \"model_name\": model_name,\n",
    "#         \"metrics\": metrics,\n",
    "#         \"hyperparameters\": params,\n",
    "#         \"n_trials\": n_trials,\n",
    "#         \"n_features\": n_features\n",
    "#     }\n",
    "#     filename = f\"{model_name}_metrics_and_params.json\"\n",
    "#     with open(filename, 'w') as f:\n",
    "#         json.dump(data, f, indent=4)\n",
    "#     print(f\"Metrics and parameters saved as {filename}\")\n",
    "\n",
    "# def compare_models(data, features, target):\n",
    "#     \"\"\"\n",
    "#     Compare XGBoost and LightGBM models with proper error handling\n",
    "#     \"\"\"\n",
    "#     print(\"Starting model comparison...\")\n",
    "    \n",
    "#     # Check GPU availability first\n",
    "#     xgb_device, lgb_device = check_gpu_availability()\n",
    "    \n",
    "#     # Prepare data with enhanced error handling\n",
    "#     try:\n",
    "#         X_train_scaled, X_test_scaled, y_train, y_test, scaler, feature_list, label_encoders = prepare_data(data, features, target)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error in data preparation: {e}\")\n",
    "#         print(\"\\nDebugging information:\")\n",
    "#         print(f\"Data columns: {list(data.columns) if hasattr(data, 'columns') else 'Not a DataFrame'}\")\n",
    "#         print(f\"Data shape: {data.shape if hasattr(data, 'shape') else 'No shape attribute'}\")\n",
    "#         print(f\"Features: {features}\")\n",
    "#         print(f\"Target: {target}\")\n",
    "#         raise\n",
    "    \n",
    "#     n_trials = 100 \n",
    "#     n_features = len(feature_list)\n",
    "    \n",
    "#     try:\n",
    "#         print(f\"\\nOptimizing XGBoost on {xgb_device.upper()}...\")\n",
    "#         xgb_best_params = optimize_xgboost(X_train_scaled, y_train, n_trials, xgb_device)\n",
    "#         print(\"XGBoost Best Parameters:\", xgb_best_params)\n",
    "        \n",
    "#         print(f\"\\nOptimizing LightGBM on {lgb_device.upper()}...\")\n",
    "#         lgb_best_params = optimize_lightgbm(X_train_scaled, y_train, n_trials, lgb_device)\n",
    "#         print(\"LightGBM Best Parameters:\", lgb_best_params)\n",
    "        \n",
    "#         print(\"\\nTraining and Evaluating XGBoost...\")\n",
    "#         xgb_model, xgb_mse, xgb_rmse, xgb_r2 = train_and_evaluate_model(\n",
    "#             XGBRegressor, xgb_best_params, X_train_scaled, y_train, X_test_scaled, y_test, feature_list, \"XGBoost\"\n",
    "#         )\n",
    "        \n",
    "#         print(\"\\nTraining and Evaluating LightGBM...\")\n",
    "#         lgb_model, lgb_mse, lgb_rmse, lgb_r2 = train_and_evaluate_model(\n",
    "#             LGBMRegressor, lgb_best_params, X_train_scaled, y_train, X_test_scaled, y_test, feature_list, \"LightGBM\"\n",
    "#         )\n",
    "        \n",
    "#         print(\"\\nModel Comparison:\")\n",
    "#         print(f\"XGBoost - MSE: {xgb_mse:.4f}, RMSE: {xgb_rmse:.4f}, R²: {xgb_r2:.4f}\")\n",
    "#         print(f\"LightGBM - MSE: {lgb_mse:.4f}, RMSE: {lgb_rmse:.4f}, R²: {lgb_r2:.4f}\")\n",
    "        \n",
    "#         # Determine the best and second-best models\n",
    "#         models = [\n",
    "#             (\"XGBoost_with_zone14\", xgb_model, xgb_r2, xgb_rmse, xgb_best_params),\n",
    "#             (\"LightGBM_with_zone14\", lgb_model, lgb_r2, lgb_rmse, lgb_best_params)\n",
    "#         ]\n",
    "#         models.sort(key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "#         # Save models and metrics\n",
    "#         for i, (model_name, model, r2, rmse, params) in enumerate(models):\n",
    "#             save_model(model, model_name, r2, rmse)\n",
    "            \n",
    "#             metrics = {\n",
    "#                 \"mse\": mean_squared_error(y_test, model.predict(X_test_scaled)),\n",
    "#                 \"rmse\": rmse,\n",
    "#                 \"r2\": r2\n",
    "#             }\n",
    "#             save_metrics_and_params(model_name, metrics, params, n_trials, n_features)\n",
    "        \n",
    "#         # Compare model performance\n",
    "#         if np.isclose(models[0][2], models[1][2], rtol=1e-4):\n",
    "#             print(\"\\nBoth models performed equally in terms of R² score.\")\n",
    "#         else:\n",
    "#             print(f\"\\n{models[0][0]} performed better with R² score of {models[0][2]:.4f}\")\n",
    "#             print(f\"{models[1][0]} came second with R² score of {models[1][2]:.4f}\")\n",
    "        \n",
    "#         # Save preprocessing objects\n",
    "#         joblib.dump(scaler, 'xgboost&lightgbm_feature_scaler_with_zone14.pkl')\n",
    "#         joblib.dump(label_encoders, 'label_encoders_with_zone14.pkl')\n",
    "#         print(\"Feature scaler and label encoders saved successfully.\")\n",
    "        \n",
    "#         return models[0][1], models[1][1], scaler, label_encoders  # Return best models and preprocessors\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error during model training/evaluation: {e}\")\n",
    "#         raise\n",
    "\n",
    "# features = [col for col in enhanced_df.columns if col != 'xG']\n",
    "# Y = 'xG'  # Target variable\n",
    "\n",
    "# print(f\"Number of features: {len(features)}\")\n",
    "# print(f\"Target variable: {Y}\")\n",
    "# print(f\"First 10 features: {features[:10]}\")\n",
    "\n",
    "\n",
    "# compare_models(enhanced_df, features, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0a2b8c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T21:05:28.437997Z",
     "iopub.status.busy": "2025-05-26T21:05:28.437759Z",
     "iopub.status.idle": "2025-05-26T22:56:18.134383Z",
     "shell.execute_reply": "2025-05-26T22:56:18.133374Z"
    },
    "papermill": {
     "duration": 6649.711491,
     "end_time": "2025-05-26T22:56:18.136127",
     "exception": false,
     "start_time": "2025-05-26T21:05:28.424636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting memory-efficient model comparison...\n",
      "Initial system memory: 729.4 MB\n",
      "Checking GPU availability...\n",
      "✓ XGBoost GPU support available and working\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ LightGBM GPU support available and working\n",
      "✓ CatBoost GPU support available and working\n",
      "\n",
      "Final device configuration:\n",
      "  XGBoost: CUDA\n",
      "  LightGBM: GPU\n",
      "  CatBoost: GPU\n",
      "\n",
      "Preparing data...\n",
      "Initial memory usage: 1126.6 MB\n",
      "Data shape: (87111, 36)\n",
      "Using 35 features and target: xG\n",
      "Memory after data selection: 1126.6 MB\n",
      "Categorical columns (1): ['shot_direction_category']...\n",
      "Numeric columns (34): ['starting_x', 'starting_y', 'end_x', 'end_y', 'distance_to_goal']...\n",
      "Encoding categorical variables...\n",
      "Memory after preprocessing: 1128.1 MB\n",
      "Train shape: (69688, 35), Test shape: (17423, 35)\n",
      "Creating scaled versions for tree models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 21:05:50,905] A new study created in memory with name: no-name-59154b93-7eac-4855-8ece-02b80066a3ad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final memory usage: 1129.7 MB\n",
      "\n",
      "============================================================\n",
      "Processing XGBoost\n",
      "============================================================\n",
      "Optimizing XGBoost hyperparameters (n_trials=50)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e96d2e490d4ba7883fd4b33d9a72b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 21:06:30,889] Trial 0 finished with value: -2.4788470198529313 and parameters: {'max_depth': 12, 'learning_rate': 0.3761877427722887, 'n_estimators': 1906, 'min_child_weight': 2, 'subsample': 0.8046678859191494, 'colsample_bytree': 0.6460625868180361, 'gamma': 7.949845943523055e-05, 'alpha': 4.593450425693394e-06, 'lambda': 8.941522374306882e-08, 'max_leaves': 269, 'max_bin': 211}. Best is trial 0 with value: -2.4788470198529313.\n",
      "[I 2025-05-26 21:07:34,131] Trial 1 finished with value: -2.61233095627862 and parameters: {'max_depth': 17, 'learning_rate': 0.0195215336492488, 'n_estimators': 2334, 'min_child_weight': 13, 'subsample': 0.9723216895159164, 'colsample_bytree': 0.7350412654841763, 'gamma': 0.002645803182249833, 'alpha': 0.001653702589707541, 'lambda': 8.588486766274157e-07, 'max_leaves': 902, 'max_bin': 839}. Best is trial 1 with value: -2.61233095627862.\n",
      "[I 2025-05-26 21:10:32,896] Trial 2 finished with value: -2.593151838472597 and parameters: {'max_depth': 20, 'learning_rate': 0.009392874022665048, 'n_estimators': 1669, 'min_child_weight': 11, 'subsample': 0.5426394129535712, 'colsample_bytree': 0.5908862644148778, 'gamma': 5.0618039748828966e-05, 'alpha': 4.1468750480288836e-07, 'lambda': 1.8097541641070025e-06, 'max_leaves': 785, 'max_bin': 509}. Best is trial 1 with value: -2.61233095627862.\n",
      "[I 2025-05-26 21:10:45,515] Trial 3 finished with value: -2.4995275559961905 and parameters: {'max_depth': 13, 'learning_rate': 0.3641066636815288, 'n_estimators': 411, 'min_child_weight': 17, 'subsample': 0.740558849897317, 'colsample_bytree': 0.5325529106719021, 'gamma': 0.0006545544709441716, 'alpha': 5.21973039514329e-06, 'lambda': 4.5721016214153747e-08, 'max_leaves': 132, 'max_bin': 489}. Best is trial 1 with value: -2.61233095627862.\n",
      "[I 2025-05-26 21:11:15,232] Trial 4 finished with value: -2.6339926272849956 and parameters: {'max_depth': 15, 'learning_rate': 0.0021252672311292855, 'n_estimators': 1721, 'min_child_weight': 12, 'subsample': 0.6492757381621281, 'colsample_bytree': 0.5221978339984255, 'gamma': 0.013619048039942985, 'alpha': 1.407307630033191e-06, 'lambda': 2.0850869871665867e-08, 'max_leaves': 48, 'max_bin': 623}. Best is trial 4 with value: -2.6339926272849956.\n",
      "[I 2025-05-26 21:11:33,850] Trial 5 finished with value: -2.6363193713022364 and parameters: {'max_depth': 5, 'learning_rate': 0.0047365699566657305, 'n_estimators': 1501, 'min_child_weight': 19, 'subsample': 0.6439568972202226, 'colsample_bytree': 0.5237369672016179, 'gamma': 1.6616841739041376e-06, 'alpha': 5.912628920545562e-05, 'lambda': 4.723503820456114e-06, 'max_leaves': 511, 'max_bin': 835}. Best is trial 5 with value: -2.6363193713022364.\n",
      "[I 2025-05-26 21:15:12,566] Trial 6 finished with value: -2.585403769583382 and parameters: {'max_depth': 19, 'learning_rate': 0.013116094035239478, 'n_estimators': 2523, 'min_child_weight': 10, 'subsample': 0.9209048595886846, 'colsample_bytree': 0.5462369713389269, 'gamma': 1.494466667613263e-08, 'alpha': 6.775235793978365e-05, 'lambda': 0.0003547882238040041, 'max_leaves': 555, 'max_bin': 398}. Best is trial 5 with value: -2.6363193713022364.\n",
      "[I 2025-05-26 21:16:48,629] Trial 7 finished with value: -2.6330642357108007 and parameters: {'max_depth': 19, 'learning_rate': 0.0021352973734615984, 'n_estimators': 1321, 'min_child_weight': 16, 'subsample': 0.918714078879536, 'colsample_bytree': 0.7093149982364948, 'gamma': 2.470586161217531e-05, 'alpha': 0.06721855580021331, 'lambda': 0.06229815607015453, 'max_leaves': 384, 'max_bin': 530}. Best is trial 5 with value: -2.6363193713022364.\n",
      "[I 2025-05-26 21:17:12,789] Trial 8 finished with value: -2.551769863172158 and parameters: {'max_depth': 17, 'learning_rate': 0.11087961340293308, 'n_estimators': 282, 'min_child_weight': 12, 'subsample': 0.5051193528952889, 'colsample_bytree': 0.7275786767501085, 'gamma': 2.5370920879570057e-05, 'alpha': 5.369170809759719e-08, 'lambda': 6.50180288235592e-05, 'max_leaves': 600, 'max_bin': 679}. Best is trial 5 with value: -2.6363193713022364.\n",
      "[I 2025-05-26 21:18:15,102] Trial 9 finished with value: -2.628669769355751 and parameters: {'max_depth': 9, 'learning_rate': 0.006048862287939955, 'n_estimators': 2054, 'min_child_weight': 4, 'subsample': 0.6129868597081762, 'colsample_bytree': 0.6429158428463666, 'gamma': 4.64122855581928e-07, 'alpha': 0.005775447308289014, 'lambda': 1.5455397462736133e-06, 'max_leaves': 174, 'max_bin': 466}. Best is trial 5 with value: -2.6363193713022364.\n",
      "[I 2025-05-26 21:18:21,743] Trial 10 finished with value: -2.625980121955644 and parameters: {'max_depth': 3, 'learning_rate': 0.039319462602815845, 'n_estimators': 947, 'min_child_weight': 20, 'subsample': 0.7650821920387152, 'colsample_bytree': 0.8910585530671857, 'gamma': 0.11693721985462652, 'alpha': 0.6681736592990193, 'lambda': 0.38973393945449963, 'max_leaves': 671, 'max_bin': 984}. Best is trial 5 with value: -2.6363193713022364.\n",
      "[I 2025-05-26 21:18:32,004] Trial 11 finished with value: -2.4959078541040634 and parameters: {'max_depth': 3, 'learning_rate': 0.0010076561325945267, 'n_estimators': 1195, 'min_child_weight': 6, 'subsample': 0.6451894722472489, 'colsample_bytree': 0.8686851125708843, 'gamma': 0.8139103612730274, 'alpha': 8.488770726759975e-05, 'lambda': 1.142893175220059e-08, 'max_leaves': 389, 'max_bin': 722}. Best is trial 5 with value: -2.6363193713022364.\n",
      "[I 2025-05-26 21:18:41,910] Trial 12 finished with value: -2.6024476645525043 and parameters: {'max_depth': 8, 'learning_rate': 0.0032627215335424807, 'n_estimators': 836, 'min_child_weight': 20, 'subsample': 0.6545766085174188, 'colsample_bytree': 0.515563393599795, 'gamma': 6.363191095028978e-07, 'alpha': 1.1555348090932784e-08, 'lambda': 0.0001107917291615351, 'max_leaves': 14, 'max_bin': 847}. Best is trial 5 with value: -2.6363193713022364.\n",
      "[I 2025-05-26 21:19:38,286] Trial 13 finished with value: -2.6379215533988574 and parameters: {'max_depth': 7, 'learning_rate': 0.0014539257156035276, 'n_estimators': 2873, 'min_child_weight': 8, 'subsample': 0.7026541322076751, 'colsample_bytree': 0.6114935996989843, 'gamma': 0.006196468993072138, 'alpha': 3.1218053861033916e-06, 'lambda': 1.3759938121983135e-05, 'max_leaves': 423, 'max_bin': 802}. Best is trial 13 with value: -2.6379215533988574.\n",
      "[I 2025-05-26 21:20:24,474] Trial 14 finished with value: -2.629184749086873 and parameters: {'max_depth': 6, 'learning_rate': 0.001074146730924767, 'n_estimators': 2891, 'min_child_weight': 8, 'subsample': 0.7255595594038965, 'colsample_bytree': 0.9879630266851503, 'gamma': 1.2014983264415487e-06, 'alpha': 0.001630680137998626, 'lambda': 0.0017765526163234986, 'max_leaves': 434, 'max_bin': 806}. Best is trial 13 with value: -2.6379215533988574.\n",
      "[I 2025-05-26 21:21:06,048] Trial 15 finished with value: -2.637666940702449 and parameters: {'max_depth': 6, 'learning_rate': 0.004840859833899638, 'n_estimators': 2940, 'min_child_weight': 16, 'subsample': 0.827049945271968, 'colsample_bytree': 0.6203793335052474, 'gamma': 0.01631891644642484, 'alpha': 2.128738828554367e-05, 'lambda': 1.0564153648337413e-05, 'max_leaves': 703, 'max_bin': 967}. Best is trial 13 with value: -2.6379215533988574.\n",
      "[I 2025-05-26 21:21:27,644] Trial 16 finished with value: -2.6345291438910334 and parameters: {'max_depth': 9, 'learning_rate': 0.04172290239738734, 'n_estimators': 2964, 'min_child_weight': 15, 'subsample': 0.8344029251586771, 'colsample_bytree': 0.6383010092567571, 'gamma': 0.036020190678304316, 'alpha': 4.3841237163382516e-07, 'lambda': 1.217444159797217e-05, 'max_leaves': 979, 'max_bin': 981}. Best is trial 13 with value: -2.6379215533988574.\n",
      "[I 2025-05-26 21:22:17,705] Trial 17 finished with value: -2.6392520968710422 and parameters: {'max_depth': 7, 'learning_rate': 0.002433256885576998, 'n_estimators': 2459, 'min_child_weight': 7, 'subsample': 0.8600073684923635, 'colsample_bytree': 0.800948469421409, 'gamma': 0.0013760403882567749, 'alpha': 1.1536950167965723e-05, 'lambda': 0.0023429008627809736, 'max_leaves': 716, 'max_bin': 917}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:23:20,074] Trial 18 finished with value: -2.6386320423893537 and parameters: {'max_depth': 8, 'learning_rate': 0.0019287336246164956, 'n_estimators': 2442, 'min_child_weight': 8, 'subsample': 0.8867568509085142, 'colsample_bytree': 0.8089385711845694, 'gamma': 0.00133138817165497, 'alpha': 0.0006618516419802546, 'lambda': 0.004022118994985385, 'max_leaves': 809, 'max_bin': 741}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:25:21,336] Trial 19 finished with value: -2.6338234692631106 and parameters: {'max_depth': 10, 'learning_rate': 0.002402861897385815, 'n_estimators': 2405, 'min_child_weight': 5, 'subsample': 0.8955051849616313, 'colsample_bytree': 0.8106379178431896, 'gamma': 0.0004698357153876172, 'alpha': 0.0006551877766343472, 'lambda': 0.008511385881620006, 'max_leaves': 795, 'max_bin': 906}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:27:16,773] Trial 20 finished with value: -2.612977091267271 and parameters: {'max_depth': 11, 'learning_rate': 0.008818247410580524, 'n_estimators': 2147, 'min_child_weight': 2, 'subsample': 0.9934217409798506, 'colsample_bytree': 0.7951488359801254, 'gamma': 0.0005436655681209634, 'alpha': 0.024504130987595265, 'lambda': 0.01101508989900504, 'max_leaves': 811, 'max_bin': 667}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:28:08,699] Trial 21 finished with value: -2.6377394791365663 and parameters: {'max_depth': 7, 'learning_rate': 0.0015698517870345089, 'n_estimators': 2632, 'min_child_weight': 8, 'subsample': 0.8798901761164227, 'colsample_bytree': 0.8128910992669383, 'gamma': 0.0029790860400349603, 'alpha': 0.0003859951927635327, 'lambda': 0.0009054375138900879, 'max_leaves': 657, 'max_bin': 762}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:28:41,153] Trial 22 finished with value: -2.6390027093896338 and parameters: {'max_depth': 5, 'learning_rate': 0.0035994439943151605, 'n_estimators': 2662, 'min_child_weight': 8, 'subsample': 0.861211934150356, 'colsample_bytree': 0.912713447529583, 'gamma': 0.0033865685715426526, 'alpha': 9.636062321150226e-06, 'lambda': 0.0060179573866696685, 'max_leaves': 874, 'max_bin': 762}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:29:02,362] Trial 23 finished with value: -2.6280055197477323 and parameters: {'max_depth': 4, 'learning_rate': 0.0033897676727430125, 'n_estimators': 2643, 'min_child_weight': 9, 'subsample': 0.8675434034416927, 'colsample_bytree': 0.9257802815412118, 'gamma': 0.19709189963729604, 'alpha': 0.0004741657056728638, 'lambda': 0.007037520892710612, 'max_leaves': 905, 'max_bin': 890}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:29:28,659] Trial 24 finished with value: -2.637171617539226 and parameters: {'max_depth': 5, 'learning_rate': 0.007118180270830158, 'n_estimators': 2204, 'min_child_weight': 6, 'subsample': 0.7939205584269912, 'colsample_bytree': 0.8485220966416641, 'gamma': 0.0010686214114766642, 'alpha': 2.6008447420910833e-05, 'lambda': 0.07732106736734762, 'max_leaves': 872, 'max_bin': 738}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:30:35,531] Trial 25 finished with value: -2.6349701085550046 and parameters: {'max_depth': 8, 'learning_rate': 0.003571556830421035, 'n_estimators': 2675, 'min_child_weight': 4, 'subsample': 0.9482281420749317, 'colsample_bytree': 0.9557705417411381, 'gamma': 0.00019917840055422553, 'alpha': 1.8864289949732604e-05, 'lambda': 0.043566620878549026, 'max_leaves': 733, 'max_bin': 581}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:30:53,155] Trial 26 finished with value: -2.637468181658656 and parameters: {'max_depth': 5, 'learning_rate': 0.016181593443970167, 'n_estimators': 2343, 'min_child_weight': 7, 'subsample': 0.8486304348218319, 'colsample_bytree': 0.7725377321983429, 'gamma': 0.04154448479937245, 'alpha': 4.598676426768785e-07, 'lambda': 0.9392388530593817, 'max_leaves': 986, 'max_bin': 937}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:32:29,629] Trial 27 finished with value: -2.635669195695323 and parameters: {'max_depth': 10, 'learning_rate': 0.0020272467850781907, 'n_estimators': 1956, 'min_child_weight': 10, 'subsample': 0.7797882858317349, 'colsample_bytree': 0.9110527552469848, 'gamma': 6.957875020670683e-06, 'alpha': 0.00023659313612706904, 'lambda': 0.0022540135930083473, 'max_leaves': 862, 'max_bin': 888}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:32:58,719] Trial 28 finished with value: -2.6135748323232 and parameters: {'max_depth': 8, 'learning_rate': 0.04599208103081013, 'n_estimators': 2759, 'min_child_weight': 4, 'subsample': 0.9415956023348148, 'colsample_bytree': 0.6916554765640407, 'gamma': 0.0031109857972740724, 'alpha': 0.008063140403404227, 'lambda': 0.0003469588890744993, 'max_leaves': 739, 'max_bin': 695}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:35:15,295] Trial 29 finished with value: -2.598444877906346 and parameters: {'max_depth': 12, 'learning_rate': 0.012145716297890435, 'n_estimators': 1895, 'min_child_weight': 3, 'subsample': 0.8119714023086257, 'colsample_bytree': 0.8414431418596064, 'gamma': 0.0001504787425287242, 'alpha': 9.792854235055737e-06, 'lambda': 0.027528500719030607, 'max_leaves': 599, 'max_bin': 239}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:39:14,569] Trial 30 finished with value: -2.6213546804625003 and parameters: {'max_depth': 13, 'learning_rate': 0.002880459458005859, 'n_estimators': 2494, 'min_child_weight': 6, 'subsample': 0.8854084495482912, 'colsample_bytree': 0.9526161578625282, 'gamma': 0.0001724069692763709, 'alpha': 1.7488907114426581e-06, 'lambda': 0.17262364276175085, 'max_leaves': 942, 'max_bin': 781}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:40:08,003] Trial 31 finished with value: -2.637370082996258 and parameters: {'max_depth': 7, 'learning_rate': 0.001441051023819837, 'n_estimators': 2766, 'min_child_weight': 8, 'subsample': 0.695331104024465, 'colsample_bytree': 0.6860830604294696, 'gamma': 0.007839516722703829, 'alpha': 2.246063511578686e-06, 'lambda': 6.92557280424202e-05, 'max_leaves': 306, 'max_bin': 787}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:40:42,042] Trial 32 finished with value: -2.6289481951698717 and parameters: {'max_depth': 6, 'learning_rate': 0.0013556634458445965, 'n_estimators': 2276, 'min_child_weight': 9, 'subsample': 0.6941688084398635, 'colsample_bytree': 0.7724090544864104, 'gamma': 0.004662787348598899, 'alpha': 1.2135893955395082e-07, 'lambda': 2.994972492797926e-07, 'max_leaves': 461, 'max_bin': 624}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:41:07,777] Trial 33 finished with value: -2.6363046970693995 and parameters: {'max_depth': 4, 'learning_rate': 0.004240352290730322, 'n_estimators': 2536, 'min_child_weight': 1, 'subsample': 0.8548616522275012, 'colsample_bytree': 0.7552306793415167, 'gamma': 0.0014072522484741, 'alpha': 5.472057741764358e-06, 'lambda': 0.0032648124801110214, 'max_leaves': 835, 'max_bin': 865}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:41:57,763] Trial 34 finished with value: -2.6380405587916727 and parameters: {'max_depth': 7, 'learning_rate': 0.001603150301123634, 'n_estimators': 2832, 'min_child_weight': 7, 'subsample': 0.7245891675185331, 'colsample_bytree': 0.582294115069642, 'gamma': 0.039660383072349016, 'alpha': 0.00015297269243770697, 'lambda': 0.0006030222528861451, 'max_leaves': 770, 'max_bin': 818}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:42:18,132] Trial 35 finished with value: -2.6364616195169246 and parameters: {'max_depth': 9, 'learning_rate': 0.006268051369783735, 'n_estimators': 1806, 'min_child_weight': 13, 'subsample': 0.7472084453273861, 'colsample_bytree': 0.5686186845318207, 'gamma': 0.11232659436485153, 'alpha': 0.0013264183339444743, 'lambda': 0.0007141333422799374, 'max_leaves': 791, 'max_bin': 930}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:42:30,972] Trial 36 finished with value: -2.608523853770447 and parameters: {'max_depth': 4, 'learning_rate': 0.44487383336271463, 'n_estimators': 2385, 'min_child_weight': 11, 'subsample': 0.8057457832332884, 'colsample_bytree': 0.8405079621107564, 'gamma': 0.732771415677818, 'alpha': 0.00016753829093696314, 'lambda': 0.00020404136022870542, 'max_leaves': 917, 'max_bin': 732}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:43:55,669] Trial 37 finished with value: -2.632606585218665 and parameters: {'max_depth': 11, 'learning_rate': 0.0018376533945563026, 'n_estimators': 2137, 'min_child_weight': 7, 'subsample': 0.9650162645158983, 'colsample_bytree': 0.8757263969872267, 'gamma': 0.02725909615306817, 'alpha': 0.005948101556135028, 'lambda': 0.011773479524392113, 'max_leaves': 756, 'max_bin': 837}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:45:02,529] Trial 38 finished with value: -2.60116178842245 and parameters: {'max_depth': 14, 'learning_rate': 0.022469644418112465, 'n_estimators': 1587, 'min_child_weight': 9, 'subsample': 0.8996356860337594, 'colsample_bytree': 0.6786197744519131, 'gamma': 0.0017669501139293082, 'alpha': 3.430802441320597e-05, 'lambda': 0.0010900610685042737, 'max_leaves': 633, 'max_bin': 653}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:45:42,750] Trial 39 finished with value: -2.520684828163616 and parameters: {'max_depth': 6, 'learning_rate': 0.1627512268681053, 'n_estimators': 2800, 'min_child_weight': 11, 'subsample': 0.6014839810238831, 'colsample_bytree': 0.7336502279597613, 'gamma': 6.668102779465915e-05, 'alpha': 0.0001370247879347719, 'lambda': 0.004433532671794691, 'max_leaves': 526, 'max_bin': 594}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:47:31,786] Trial 40 finished with value: -2.6326941004854274 and parameters: {'max_depth': 10, 'learning_rate': 0.002299697294563651, 'n_estimators': 2999, 'min_child_weight': 5, 'subsample': 0.7251299046008559, 'colsample_bytree': 0.7929267650169207, 'gamma': 0.01214017375849651, 'alpha': 9.564363641383122e-06, 'lambda': 0.02084315212248829, 'max_leaves': 697, 'max_bin': 820}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:48:24,092] Trial 41 finished with value: -2.634411461849676 and parameters: {'max_depth': 7, 'learning_rate': 0.0012346548991064433, 'n_estimators': 2577, 'min_child_weight': 7, 'subsample': 0.708631506206002, 'colsample_bytree': 0.5972268341135218, 'gamma': 0.00040506076196428193, 'alpha': 1.231760041461481e-06, 'lambda': 2.98056763495652e-05, 'max_leaves': 313, 'max_bin': 770}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:49:16,110] Trial 42 finished with value: -2.639013380423969 and parameters: {'max_depth': 7, 'learning_rate': 0.0026745631932942656, 'n_estimators': 2807, 'min_child_weight': 10, 'subsample': 0.6743267581340042, 'colsample_bytree': 0.559556849762332, 'gamma': 0.007658152039902687, 'alpha': 3.624554255271146e-06, 'lambda': 0.0003578313939742835, 'max_leaves': 576, 'max_bin': 852}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:49:48,015] Trial 43 finished with value: -2.636096212271275 and parameters: {'max_depth': 5, 'learning_rate': 0.0026613651638699607, 'n_estimators': 2758, 'min_child_weight': 12, 'subsample': 0.6683594228515729, 'colsample_bytree': 0.5899314814348636, 'gamma': 0.056986124155343584, 'alpha': 5.801394655507954e-05, 'lambda': 0.00039593239785696524, 'max_leaves': 845, 'max_bin': 935}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:50:10,183] Trial 44 finished with value: -2.6310899163679933 and parameters: {'max_depth': 8, 'learning_rate': 0.004448337684033208, 'n_estimators': 2480, 'min_child_weight': 10, 'subsample': 0.7657224987056344, 'colsample_bytree': 0.5542564364769224, 'gamma': 0.26631543995283696, 'alpha': 1.0653892501632928e-05, 'lambda': 0.00014195297882912313, 'max_leaves': 570, 'max_bin': 866}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:50:28,765] Trial 45 finished with value: -2.608059565715112 and parameters: {'max_depth': 3, 'learning_rate': 0.0016612697347579495, 'n_estimators': 2267, 'min_child_weight': 14, 'subsample': 0.6073346573032647, 'colsample_bytree': 0.7150998928050248, 'gamma': 0.00096067227397661, 'alpha': 9.324127795314815e-07, 'lambda': 0.0006009682211356257, 'max_leaves': 634, 'max_bin': 710}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:50:39,747] Trial 46 finished with value: -2.34439911170269 and parameters: {'max_depth': 7, 'learning_rate': 0.001003672637185696, 'n_estimators': 503, 'min_child_weight': 9, 'subsample': 0.5475017578332853, 'colsample_bytree': 0.665282621647839, 'gamma': 0.01239496275950243, 'alpha': 1.1994706313716894e-07, 'lambda': 0.0016296331815321575, 'max_leaves': 756, 'max_bin': 829}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:54:04,883] Trial 47 finished with value: -2.616726530721619 and parameters: {'max_depth': 16, 'learning_rate': 0.005393812553885405, 'n_estimators': 2012, 'min_child_weight': 7, 'subsample': 0.9314528216322869, 'colsample_bytree': 0.5680729860964386, 'gamma': 2.0942398809615378e-05, 'alpha': 5.402490052254711e-05, 'lambda': 0.005278543530702781, 'max_leaves': 682, 'max_bin': 754}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:55:13,465] Trial 48 finished with value: -2.6264981391430333 and parameters: {'max_depth': 9, 'learning_rate': 0.008110952864851449, 'n_estimators': 2857, 'min_child_weight': 5, 'subsample': 0.9094006206629195, 'colsample_bytree': 0.5077451829268669, 'gamma': 0.004775968145552867, 'alpha': 3.730531587447073e-06, 'lambda': 4.174600719943849e-05, 'max_leaves': 936, 'max_bin': 909}. Best is trial 17 with value: -2.6392520968710422.\n",
      "[I 2025-05-26 21:55:46,844] Trial 49 finished with value: -2.6385448753972716 and parameters: {'max_depth': 5, 'learning_rate': 0.003706600078471239, 'n_estimators': 2711, 'min_child_weight': 10, 'subsample': 0.6652165659010915, 'colsample_bytree': 0.9131619549207589, 'gamma': 0.02281975420629273, 'alpha': 0.0008687967143601211, 'lambda': 0.00026870691805558084, 'max_leaves': 537, 'max_bin': 860}. Best is trial 17 with value: -2.6392520968710422.\n",
      "\n",
      "==================================================\n",
      "Training XGBoost\n",
      "==================================================\n",
      "Initial memory: 1685.5 MB\n",
      "Using scaled data for XGBoost\n",
      "Training XGBoost...\n",
      "Memory during training: 1685.5 MB\n",
      "Memory after training: 1699.9 MB\n",
      "Training memory increase: 14.4 MB\n",
      "Feature importance plot saved to xgboost_feature_importance.png\n",
      "\n",
      "XGBoost Results:\n",
      "MSE: 0.006738\n",
      "RMSE: 0.082088\n",
      "MAE: 0.042828\n",
      "R2: 0.699683\n",
      "MAPE: 47.549293\n",
      "MAX_ERROR: 0.779049\n",
      "EXPLAINED_VARIANCE: 0.699684\n",
      "Final memory: 1700.0 MB\n",
      "Total memory increase: 14.5 MB\n",
      "Model saved to best_xgboost_model.pkl\n",
      "Preprocessing objects saved to xgboost_preprocessing.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 21:56:20,871] A new study created in memory with name: no-name-76a6d480-35b5-4318-9261-ed21ae9afe88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory after cleanup: 1700.0 MB\n",
      "Memory after XGBoost cleanup: 1700.0 MB\n",
      "\n",
      "============================================================\n",
      "Processing LightGBM\n",
      "============================================================\n",
      "Optimizing LightGBM hyperparameters (n_trials=50)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d4a3ddb2da4e4894d0f603adce060a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 833 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 833 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 833 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 833 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 833 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 833 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 21:56:21,869] Trial 0 finished with value: inf and parameters: {'num_leaves': 53, 'learning_rate': 0.011805958746862301, 'n_estimators': 237, 'min_child_samples': 63, 'subsample': 0.5927912915563807, 'colsample_bytree': 0.5199312456152505, 'reg_alpha': 1.432256654497875e-06, 'reg_lambda': 1.6515377036383607e-05, 'max_depth': -1, 'min_split_gain': 0.5667764078224098, 'max_bin': 832, 'boosting_type': 'goss'}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 557 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 557 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 557 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 557 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 557 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 323 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 557 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 21:56:22,803] Trial 1 finished with value: inf and parameters: {'num_leaves': 17, 'learning_rate': 0.44357166242783197, 'n_estimators': 1151, 'min_child_samples': 249, 'subsample': 0.9736394332826839, 'colsample_bytree': 0.8699552997513815, 'reg_alpha': 6.198770649902867e-08, 'reg_lambda': 9.331788508434249e-07, 'max_depth': 12, 'min_split_gain': 8.28089643174731e-06, 'max_bin': 556, 'boosting_type': 'goss'}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 323 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 323 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 323 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 323 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 345 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 323 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 21:56:23,742] Trial 2 finished with value: inf and parameters: {'num_leaves': 5, 'learning_rate': 0.001124116306905144, 'n_estimators': 1851, 'min_child_samples': 10, 'subsample': 0.5002589551192551, 'colsample_bytree': 0.6653431442636359, 'reg_alpha': 1.790426263148327e-08, 'reg_lambda': 0.06921042960092119, 'max_depth': 17, 'min_split_gain': 1.1603368067666851e-08, 'max_bin': 322, 'boosting_type': 'gbdt'}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 345 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 345 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 345 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 345 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 504 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 345 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 21:56:24,666] Trial 3 finished with value: inf and parameters: {'num_leaves': 65, 'learning_rate': 0.14591508586411572, 'n_estimators': 870, 'min_child_samples': 234, 'subsample': 0.7320410118648846, 'colsample_bytree': 0.9992501311253852, 'reg_alpha': 0.004520072343671124, 'reg_lambda': 1.687151832363738e-08, 'max_depth': 11, 'min_split_gain': 4.525961021527751e-06, 'max_bin': 344, 'boosting_type': 'goss'}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 504 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 504 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 504 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 504 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 575 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 504 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 21:56:25,612] Trial 4 finished with value: inf and parameters: {'num_leaves': 6, 'learning_rate': 0.016520644675662808, 'n_estimators': 1988, 'min_child_samples': 249, 'subsample': 0.7727930236869062, 'colsample_bytree': 0.9877626486169815, 'reg_alpha': 0.023250983552508105, 'reg_lambda': 2.8651622528673976e-08, 'max_depth': 1, 'min_split_gain': 0.0004171949967423409, 'max_bin': 503, 'boosting_type': 'goss'}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 575 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 575 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 575 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 575 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 575 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 21:56:26,587] Trial 5 finished with value: inf and parameters: {'num_leaves': 39, 'learning_rate': 0.05023507612185007, 'n_estimators': 988, 'min_child_samples': 133, 'subsample': 0.744063581411001, 'colsample_bytree': 0.8438391879560141, 'reg_alpha': 0.1846080004235895, 'reg_lambda': 0.026903581796373435, 'max_depth': 14, 'min_split_gain': 8.248931223935958e-06, 'max_bin': 574, 'boosting_type': 'gbdt'}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 420 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 420 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 420 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 420 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 420 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 417 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 420 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 21:56:27,538] Trial 6 finished with value: inf and parameters: {'num_leaves': 19, 'learning_rate': 0.006968802983651403, 'n_estimators': 2740, 'min_child_samples': 3, 'subsample': 0.9187727484352883, 'colsample_bytree': 0.9726057812963198, 'reg_alpha': 0.0019409840791696248, 'reg_lambda': 0.0005156407176115387, 'max_depth': 8, 'min_split_gain': 0.7616843042129754, 'max_bin': 419, 'boosting_type': 'gbdt'}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 417 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 417 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 417 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 417 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 417 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 21:56:28,481] Trial 7 finished with value: inf and parameters: {'num_leaves': 11, 'learning_rate': 0.0020041003737441675, 'n_estimators': 2233, 'min_child_samples': 45, 'subsample': 0.7735443129353138, 'colsample_bytree': 0.9790368406327393, 'reg_alpha': 7.660490810289777e-05, 'reg_lambda': 0.010187495725560028, 'max_depth': 9, 'min_split_gain': 0.0799643341582269, 'max_bin': 416, 'boosting_type': 'gbdt'}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 1001 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 1001 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 1001 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 1001 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 1001 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 270 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 1001 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 21:56:29,447] Trial 8 finished with value: inf and parameters: {'num_leaves': 17, 'learning_rate': 0.22300167391653924, 'n_estimators': 2488, 'min_child_samples': 172, 'subsample': 0.8509913256143081, 'colsample_bytree': 0.9693198877728884, 'reg_alpha': 3.15392145598478e-06, 'reg_lambda': 2.2496428492737216e-06, 'max_depth': 8, 'min_split_gain': 0.037069099029377786, 'max_bin': 1000, 'boosting_type': 'goss'}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 270 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 270 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 270 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 270 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 270 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 21:56:30,372] Trial 9 finished with value: inf and parameters: {'num_leaves': 26, 'learning_rate': 0.28083636353702773, 'n_estimators': 2444, 'min_child_samples': 31, 'subsample': 0.991040464606088, 'colsample_bytree': 0.515484353177648, 'reg_alpha': 5.1205133830921065e-05, 'reg_lambda': 0.005002911230768349, 'max_depth': 13, 'min_split_gain': 3.7311784716383718e-06, 'max_bin': 269, 'boosting_type': 'goss'}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 837 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 837 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 837 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 837 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 837 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 837 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 21:56:31,396] Trial 10 finished with value: inf and parameters: {'num_leaves': 96, 'learning_rate': 0.005765045675745478, 'n_estimators': 266, 'min_child_samples': 94, 'subsample': 0.5547854124156877, 'colsample_bytree': 0.5079531516245649, 'reg_alpha': 1.285754018557605e-06, 'reg_lambda': 5.74296900930577, 'max_depth': -1, 'min_split_gain': 0.0009731341591143431, 'max_bin': 836, 'boosting_type': 'goss'}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 714 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 714 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 714 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 714 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 714 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 714 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 21:56:32,406] Trial 11 finished with value: inf and parameters: {'num_leaves': 62, 'learning_rate': 0.04964842186111601, 'n_estimators': 120, 'min_child_samples': 294, 'subsample': 0.6241049812002124, 'colsample_bytree': 0.7909329730083734, 'reg_alpha': 1.4867416901442173e-08, 'reg_lambda': 3.9772182707139524e-06, 'max_depth': 3, 'min_split_gain': 7.418928365722827e-08, 'max_bin': 713, 'boosting_type': 'goss'}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 705 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 705 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 705 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 705 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 705 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 705 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 21:56:33,405] Trial 12 finished with value: inf and parameters: {'num_leaves': 45, 'learning_rate': 0.021368103711887996, 'n_estimators': 1132, 'min_child_samples': 185, 'subsample': 0.640593899586459, 'colsample_bytree': 0.6513524412209426, 'reg_alpha': 8.279237595626277e-07, 'reg_lambda': 4.869262644576116e-06, 'max_depth': 4, 'min_split_gain': 0.003989400577115664, 'max_bin': 704, 'boosting_type': 'goss'}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 876 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 876 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 876 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 876 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 876 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 876 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 21:56:34,459] Trial 13 finished with value: inf and parameters: {'num_leaves': 80, 'learning_rate': 0.07678392339707542, 'n_estimators': 605, 'min_child_samples': 89, 'subsample': 0.9993758117050731, 'colsample_bytree': 0.8771415270168008, 'reg_alpha': 1.5748925681991298e-07, 'reg_lambda': 5.683686662882428e-05, 'max_depth': 20, 'min_split_gain': 2.7471997977233193e-05, 'max_bin': 875, 'boosting_type': 'goss'}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 705 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 705 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 705 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 705 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 705 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 705 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 21:56:35,476] Trial 14 finished with value: inf and parameters: {'num_leaves': 34, 'learning_rate': 0.47944478788935674, 'n_estimators': 1457, 'min_child_samples': 120, 'subsample': 0.6590307526319591, 'colsample_bytree': 0.6810458241954798, 'reg_alpha': 1.6916401697740733e-05, 'reg_lambda': 2.2133984732627293e-07, 'max_depth': 5, 'min_split_gain': 4.823070383907508e-07, 'max_bin': 704, 'boosting_type': 'goss'}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 610 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 610 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 610 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 610 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 610 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 610 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 21:56:36,509] Trial 15 finished with value: inf and parameters: {'num_leaves': 57, 'learning_rate': 0.006141887914024787, 'n_estimators': 524, 'min_child_samples': 226, 'subsample': 0.8682375217650748, 'colsample_bytree': 0.5657095805743949, 'reg_alpha': 4.475701605095447, 'reg_lambda': 6.817703212167927e-05, 'max_depth': 15, 'min_split_gain': 5.1741341245224276e-05, 'max_bin': 609, 'boosting_type': 'goss'}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 844 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 844 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 844 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 844 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 844 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 844 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 21:56:37,548] Trial 16 finished with value: inf and parameters: {'num_leaves': 49, 'learning_rate': 0.012826725570537635, 'n_estimators': 1379, 'min_child_samples': 297, 'subsample': 0.5762102259842345, 'colsample_bytree': 0.7427979471361896, 'reg_alpha': 1.1572169526101769e-07, 'reg_lambda': 1.815900916962472e-07, 'max_depth': 6, 'min_split_gain': 0.009822878081004063, 'max_bin': 843, 'boosting_type': 'goss'}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 1001 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 1001 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 1001 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 1001 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 1001 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 1001 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 21:56:38,590] Trial 17 finished with value: inf and parameters: {'num_leaves': 74, 'learning_rate': 0.09671939155482107, 'n_estimators': 457, 'min_child_samples': 76, 'subsample': 0.697868001050133, 'colsample_bytree': 0.8969683273834304, 'reg_alpha': 5.333775797009042e-06, 'reg_lambda': 4.159209079025068e-05, 'max_depth': 11, 'min_split_gain': 0.38433914920545387, 'max_bin': 1000, 'boosting_type': 'goss'}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 588 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 588 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 588 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 588 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 588 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 588 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 21:56:39,585] Trial 18 finished with value: inf and parameters: {'num_leaves': 30, 'learning_rate': 0.0030154250177602047, 'n_estimators': 1755, 'min_child_samples': 196, 'subsample': 0.8306254312653196, 'colsample_bytree': 0.6046420470831015, 'reg_alpha': 3.201567390796424e-07, 'reg_lambda': 5.325966703151243e-07, 'max_depth': -1, 'min_split_gain': 0.0002838167556914077, 'max_bin': 587, 'boosting_type': 'gbdt'}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 21:58:01,903] Trial 19 finished with value: -2.6207093271534863 and parameters: {'num_leaves': 90, 'learning_rate': 0.034354471227977065, 'n_estimators': 828, 'min_child_samples': 154, 'subsample': 0.9282738932069547, 'colsample_bytree': 0.7786405502709826, 'reg_alpha': 0.00045010402417663476, 'reg_lambda': 0.353882202225327, 'max_depth': 17, 'min_split_gain': 4.972677397406122e-07, 'max_bin': 205, 'boosting_type': 'goss'}. Best is trial 19 with value: -2.6207093271534863.\n",
      "[I 2025-05-26 21:59:17,402] Trial 20 finished with value: -2.6215763420459197 and parameters: {'num_leaves': 95, 'learning_rate': 0.03202852781642406, 'n_estimators': 839, 'min_child_samples': 157, 'subsample': 0.9248431312249448, 'colsample_bytree': 0.7527012336433787, 'reg_alpha': 0.0004029336969510896, 'reg_lambda': 8.616938322896777, 'max_depth': 19, 'min_split_gain': 1.0178141320079594e-06, 'max_bin': 203, 'boosting_type': 'goss'}. Best is trial 20 with value: -2.6215763420459197.\n",
      "[I 2025-05-26 22:00:34,381] Trial 21 finished with value: -2.620513792923283 and parameters: {'num_leaves': 100, 'learning_rate': 0.03731530636511009, 'n_estimators': 826, 'min_child_samples': 150, 'subsample': 0.923949692694316, 'colsample_bytree': 0.7459137856674999, 'reg_alpha': 0.0003225401328931763, 'reg_lambda': 5.476940967681736, 'max_depth': 20, 'min_split_gain': 4.3177334488470195e-07, 'max_bin': 223, 'boosting_type': 'goss'}. Best is trial 20 with value: -2.6215763420459197.\n",
      "[I 2025-05-26 22:01:43,866] Trial 22 finished with value: -2.622450489227382 and parameters: {'num_leaves': 99, 'learning_rate': 0.03543567956169781, 'n_estimators': 737, 'min_child_samples': 152, 'subsample': 0.9231398802758197, 'colsample_bytree': 0.7395076658970889, 'reg_alpha': 0.001404352006106919, 'reg_lambda': 8.740618062229807, 'max_depth': 20, 'min_split_gain': 4.882183526479927e-07, 'max_bin': 241, 'boosting_type': 'goss'}. Best is trial 22 with value: -2.622450489227382.\n",
      "[I 2025-05-26 22:02:50,816] Trial 23 finished with value: -2.619159188512019 and parameters: {'num_leaves': 88, 'learning_rate': 0.03446559446759561, 'n_estimators': 722, 'min_child_samples': 119, 'subsample': 0.9191160530286627, 'colsample_bytree': 0.7967431860086731, 'reg_alpha': 0.0007782565790592586, 'reg_lambda': 0.5305270766705021, 'max_depth': 17, 'min_split_gain': 4.284213929634349e-07, 'max_bin': 204, 'boosting_type': 'goss'}. Best is trial 22 with value: -2.622450489227382.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 279 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 279 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 279 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 279 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 279 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 279 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 22:02:51,784] Trial 24 finished with value: inf and parameters: {'num_leaves': 90, 'learning_rate': 0.028524047666223087, 'n_estimators': 1255, 'min_child_samples': 161, 'subsample': 0.8843784399203307, 'colsample_bytree': 0.6994178496850874, 'reg_alpha': 0.01761507306106731, 'reg_lambda': 0.48069770765320685, 'max_depth': 18, 'min_split_gain': 6.8734632369506e-08, 'max_bin': 278, 'boosting_type': 'goss'}. Best is trial 22 with value: -2.622450489227382.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 384 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 384 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 384 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 384 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 384 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 384 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 22:02:52,752] Trial 25 finished with value: inf and parameters: {'num_leaves': 80, 'learning_rate': 0.08386124907206531, 'n_estimators': 1631, 'min_child_samples': 206, 'subsample': 0.8074368467335858, 'colsample_bytree': 0.7862025653960426, 'reg_alpha': 0.00017472968846833742, 'reg_lambda': 0.4279228530404578, 'max_depth': 18, 'min_split_gain': 1.6400664511174743e-06, 'max_bin': 383, 'boosting_type': 'goss'}. Best is trial 22 with value: -2.622450489227382.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 283 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 283 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 283 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 283 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 283 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 283 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 22:02:53,735] Trial 26 finished with value: inf and parameters: {'num_leaves': 91, 'learning_rate': 0.02085043730958474, 'n_estimators': 454, 'min_child_samples': 148, 'subsample': 0.9506728625194604, 'colsample_bytree': 0.7149306116198008, 'reg_alpha': 0.15289984917200694, 'reg_lambda': 1.7745084785513776, 'max_depth': 16, 'min_split_gain': 1.1072798165037042e-08, 'max_bin': 282, 'boosting_type': 'goss'}. Best is trial 22 with value: -2.622450489227382.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 478 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 478 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 478 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 478 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 478 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 478 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 22:02:54,737] Trial 27 finished with value: inf and parameters: {'num_leaves': 82, 'learning_rate': 0.0535142504431812, 'n_estimators': 981, 'min_child_samples': 115, 'subsample': 0.9506763879800291, 'colsample_bytree': 0.6251778155489381, 'reg_alpha': 0.014355636883233425, 'reg_lambda': 0.11305622066587315, 'max_depth': 20, 'min_split_gain': 5.978631864448316e-08, 'max_bin': 477, 'boosting_type': 'gbdt'}. Best is trial 22 with value: -2.622450489227382.\n",
      "[I 2025-05-26 22:03:51,433] Trial 28 finished with value: -2.6266065230714672 and parameters: {'num_leaves': 68, 'learning_rate': 0.01032609428122555, 'n_estimators': 690, 'min_child_samples': 178, 'subsample': 0.9022885607343493, 'colsample_bytree': 0.8235763878304851, 'reg_alpha': 2.2064673011831843e-05, 'reg_lambda': 6.463634592037501, 'max_depth': 18, 'min_split_gain': 8.177022785746514e-07, 'max_bin': 207, 'boosting_type': 'goss'}. Best is trial 28 with value: -2.6266065230714672.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 329 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 329 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 329 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 329 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 329 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 329 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 22:03:52,411] Trial 29 finished with value: inf and parameters: {'num_leaves': 72, 'learning_rate': 0.008757754550469472, 'n_estimators': 258, 'min_child_samples': 179, 'subsample': 0.8863807189354582, 'colsample_bytree': 0.8281252601519424, 'reg_alpha': 1.3395900067332209e-05, 'reg_lambda': 8.380425741927564, 'max_depth': 19, 'min_split_gain': 2.0141843249463687e-05, 'max_bin': 328, 'boosting_type': 'goss'}. Best is trial 28 with value: -2.6266065230714672.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 269 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 269 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 269 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 269 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 269 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 269 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 22:03:53,375] Trial 30 finished with value: inf and parameters: {'num_leaves': 69, 'learning_rate': 0.012125362590648156, 'n_estimators': 625, 'min_child_samples': 209, 'subsample': 0.8219211955337211, 'colsample_bytree': 0.9140404127066086, 'reg_alpha': 3.969528106213915e-05, 'reg_lambda': 0.0011839904890766396, 'max_depth': 15, 'min_split_gain': 1.2923404222004897e-07, 'max_bin': 268, 'boosting_type': 'goss'}. Best is trial 28 with value: -2.6266065230714672.\n",
      "[I 2025-05-26 22:05:24,632] Trial 31 finished with value: -2.6218919434443144 and parameters: {'num_leaves': 95, 'learning_rate': 0.02578021715544335, 'n_estimators': 971, 'min_child_samples': 143, 'subsample': 0.8986861210036542, 'colsample_bytree': 0.773964917240554, 'reg_alpha': 0.0011731947362099223, 'reg_lambda': 2.491525033902006, 'max_depth': 18, 'min_split_gain': 9.447727305176353e-07, 'max_bin': 202, 'boosting_type': 'goss'}. Best is trial 28 with value: -2.6266065230714672.\n",
      "[I 2025-05-26 22:07:02,714] Trial 32 finished with value: -2.626245562468014 and parameters: {'num_leaves': 100, 'learning_rate': 0.016035849604821722, 'n_estimators': 999, 'min_child_samples': 138, 'subsample': 0.9607753346803987, 'colsample_bytree': 0.8309853063027955, 'reg_alpha': 0.001710911872968371, 'reg_lambda': 1.3390034008562397, 'max_depth': 19, 'min_split_gain': 2.365049675479285e-06, 'max_bin': 242, 'boosting_type': 'goss'}. Best is trial 28 with value: -2.6266065230714672.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 372 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 372 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 372 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 372 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 372 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 372 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 22:07:03,859] Trial 33 finished with value: inf and parameters: {'num_leaves': 100, 'learning_rate': 0.015907636729135425, 'n_estimators': 1118, 'min_child_samples': 132, 'subsample': 0.9621662778140525, 'colsample_bytree': 0.8241033831253598, 'reg_alpha': 0.004013343210531878, 'reg_lambda': 0.965691264805493, 'max_depth': 18, 'min_split_gain': 1.6696252612782808e-07, 'max_bin': 371, 'boosting_type': 'goss'}. Best is trial 28 with value: -2.6266065230714672.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 293 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 293 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 293 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 293 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 293 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 293 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 22:07:05,128] Trial 34 finished with value: inf and parameters: {'num_leaves': 86, 'learning_rate': 0.0037378810639219244, 'n_estimators': 1253, 'min_child_samples': 100, 'subsample': 0.8796361487836449, 'colsample_bytree': 0.9271463645175939, 'reg_alpha': 0.001898640766462836, 'reg_lambda': 2.128400976113829, 'max_depth': 16, 'min_split_gain': 2.1937348975313697e-06, 'max_bin': 292, 'boosting_type': 'goss'}. Best is trial 28 with value: -2.6266065230714672.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 340 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 340 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 340 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 340 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 340 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 340 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 22:07:06,132] Trial 35 finished with value: inf and parameters: {'num_leaves': 95, 'learning_rate': 0.00935141963911589, 'n_estimators': 358, 'min_child_samples': 135, 'subsample': 0.9769174482754895, 'colsample_bytree': 0.8510758093623617, 'reg_alpha': 0.10135552042451976, 'reg_lambda': 0.13996552525627684, 'max_depth': 13, 'min_split_gain': 2.4711602071414875e-08, 'max_bin': 339, 'boosting_type': 'goss'}. Best is trial 28 with value: -2.6266065230714672.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 22:08:01,881] Trial 36 finished with value: -2.626859415232989 and parameters: {'num_leaves': 83, 'learning_rate': 0.017157538783294967, 'n_estimators': 1000, 'min_child_samples': 172, 'subsample': 0.8982672515806632, 'colsample_bytree': 0.8116433906032052, 'reg_alpha': 0.00011860154001995859, 'reg_lambda': 1.940762280472631, 'max_depth': 19, 'min_split_gain': 1.1014668880836937e-05, 'max_bin': 234, 'boosting_type': 'gbdt'}. Best is trial 36 with value: -2.626859415232989.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 468 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 468 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 468 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 468 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 468 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 468 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 22:08:02,889] Trial 37 finished with value: inf and parameters: {'num_leaves': 76, 'learning_rate': 0.01696860845610074, 'n_estimators': 1360, 'min_child_samples': 228, 'subsample': 0.7826632401826671, 'colsample_bytree': 0.8253274961250681, 'reg_alpha': 0.00012894803949676476, 'reg_lambda': 0.04461701625188028, 'max_depth': 20, 'min_split_gain': 1.0612827154136598e-05, 'max_bin': 467, 'boosting_type': 'gbdt'}. Best is trial 36 with value: -2.626859415232989.\n",
      "[I 2025-05-26 22:08:39,725] Trial 38 finished with value: -2.6263770938091873 and parameters: {'num_leaves': 84, 'learning_rate': 0.008274562720157379, 'n_estimators': 692, 'min_child_samples': 252, 'subsample': 0.8414062300522905, 'colsample_bytree': 0.7212179580029703, 'reg_alpha': 0.006921774763384707, 'reg_lambda': 0.01281100769597953, 'max_depth': 16, 'min_split_gain': 0.00013713195877312567, 'max_bin': 250, 'boosting_type': 'gbdt'}. Best is trial 36 with value: -2.626859415232989.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 414 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 414 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 414 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 414 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 414 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 414 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 22:08:40,873] Trial 39 finished with value: inf and parameters: {'num_leaves': 65, 'learning_rate': 0.0035397634410979386, 'n_estimators': 1050, 'min_child_samples': 266, 'subsample': 0.8485404710943492, 'colsample_bytree': 0.8555513861452485, 'reg_alpha': 1.4029433508229237, 'reg_lambda': 0.005729621041926977, 'max_depth': 15, 'min_split_gain': 8.608753211933212e-05, 'max_bin': 413, 'boosting_type': 'gbdt'}. Best is trial 36 with value: -2.626859415232989.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 309 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 309 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 309 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 309 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 309 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 309 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 22:08:41,991] Trial 40 finished with value: inf and parameters: {'num_leaves': 84, 'learning_rate': 0.004638940237976517, 'n_estimators': 1617, 'min_child_samples': 246, 'subsample': 0.8445445056993361, 'colsample_bytree': 0.9392087455686386, 'reg_alpha': 0.006344475359709708, 'reg_lambda': 0.016725594147376635, 'max_depth': 12, 'min_split_gain': 0.00018718809396102554, 'max_bin': 308, 'boosting_type': 'gbdt'}. Best is trial 36 with value: -2.626859415232989.\n",
      "[I 2025-05-26 22:09:17,334] Trial 41 finished with value: -2.6290890254637693 and parameters: {'num_leaves': 78, 'learning_rate': 0.009380781722055719, 'n_estimators': 688, 'min_child_samples': 171, 'subsample': 0.8974170189480103, 'colsample_bytree': 0.720794341633167, 'reg_alpha': 0.006007276021293035, 'reg_lambda': 0.22770134727786703, 'max_depth': 19, 'min_split_gain': 6.019857520852638e-06, 'max_bin': 243, 'boosting_type': 'gbdt'}. Best is trial 41 with value: -2.6290890254637693.\n",
      "[I 2025-05-26 22:09:47,092] Trial 42 finished with value: -2.6272132662205623 and parameters: {'num_leaves': 58, 'learning_rate': 0.009431215089046105, 'n_estimators': 673, 'min_child_samples': 273, 'subsample': 0.9015610188282653, 'colsample_bytree': 0.6998773881300688, 'reg_alpha': 0.05814291024818504, 'reg_lambda': 0.141271672771129, 'max_depth': 16, 'min_split_gain': 6.423522090712462e-06, 'max_bin': 252, 'boosting_type': 'gbdt'}. Best is trial 41 with value: -2.6290890254637693.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 355 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 355 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 355 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 355 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 355 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 355 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 22:09:48,082] Trial 43 finished with value: inf and parameters: {'num_leaves': 60, 'learning_rate': 0.008929730216405845, 'n_estimators': 721, 'min_child_samples': 274, 'subsample': 0.7958496810203979, 'colsample_bytree': 0.7035331480054372, 'reg_alpha': 0.9511945346085617, 'reg_lambda': 0.11564265563625126, 'max_depth': 16, 'min_split_gain': 9.962108050717452e-06, 'max_bin': 354, 'boosting_type': 'gbdt'}. Best is trial 41 with value: -2.6290890254637693.\n",
      "[I 2025-05-26 22:10:05,416] Trial 44 finished with value: -2.4423359131023155 and parameters: {'num_leaves': 68, 'learning_rate': 0.0020764541934612684, 'n_estimators': 373, 'min_child_samples': 273, 'subsample': 0.9036261708980764, 'colsample_bytree': 0.6632697918183255, 'reg_alpha': 0.05237544742843959, 'reg_lambda': 0.002473996426582469, 'max_depth': 14, 'min_split_gain': 5.813255367494253e-06, 'max_bin': 248, 'boosting_type': 'gbdt'}. Best is trial 41 with value: -2.6290890254637693.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 327 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 327 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 327 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 327 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 327 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 327 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 22:10:06,469] Trial 45 finished with value: inf and parameters: {'num_leaves': 53, 'learning_rate': 0.008187603928552426, 'n_estimators': 101, 'min_child_samples': 215, 'subsample': 0.8611254419084531, 'colsample_bytree': 0.7296087276690943, 'reg_alpha': 0.4521054349833464, 'reg_lambda': 0.04099704189559371, 'max_depth': 17, 'min_split_gain': 0.0005572943593661191, 'max_bin': 326, 'boosting_type': 'gbdt'}. Best is trial 41 with value: -2.6290890254637693.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 532 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 532 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 532 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 532 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 532 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 532 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 22:10:07,533] Trial 46 finished with value: inf and parameters: {'num_leaves': 76, 'learning_rate': 0.005173258772169105, 'n_estimators': 617, 'min_child_samples': 256, 'subsample': 0.8206742811663299, 'colsample_bytree': 0.8024322317435962, 'reg_alpha': 0.039546497211684475, 'reg_lambda': 0.214408017143582, 'max_depth': 14, 'min_split_gain': 3.479424930486977e-05, 'max_bin': 531, 'boosting_type': 'gbdt'}. Best is trial 41 with value: -2.6290890254637693.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 300 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 300 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 300 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 300 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 300 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 300 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 22:10:08,555] Trial 47 finished with value: inf and parameters: {'num_leaves': 56, 'learning_rate': 0.012111796224686184, 'n_estimators': 553, 'min_child_samples': 192, 'subsample': 0.74696240296646, 'colsample_bytree': 0.636704921137674, 'reg_alpha': 0.006729163585743401, 'reg_lambda': 0.017755501046863683, 'max_depth': 11, 'min_split_gain': 0.00010688087427937607, 'max_bin': 299, 'boosting_type': 'gbdt'}. Best is trial 41 with value: -2.6290890254637693.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 391 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 391 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 391 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 391 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 391 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 391 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 22:10:09,562] Trial 48 finished with value: inf and parameters: {'num_leaves': 41, 'learning_rate': 0.006563261418513119, 'n_estimators': 741, 'min_child_samples': 174, 'subsample': 0.7100851082852188, 'colsample_bytree': 0.6855612900136079, 'reg_alpha': 2.048538928786786e-05, 'reg_lambda': 0.0003916874728960059, 'max_depth': 16, 'min_split_gain': 1.681355407363912e-05, 'max_bin': 390, 'boosting_type': 'gbdt'}. Best is trial 41 with value: -2.6290890254637693.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] bin size 642 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 642 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 642 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 642 cannot run on GPU\n",
      "[LightGBM] [Fatal] bin size 642 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LightGBM trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bin size 642 cannot run on GPU\n",
      "\n",
      "[I 2025-05-26 22:10:10,617] Trial 49 finished with value: inf and parameters: {'num_leaves': 70, 'learning_rate': 0.0018892347036317206, 'n_estimators': 346, 'min_child_samples': 288, 'subsample': 0.898436694580645, 'colsample_bytree': 0.7216581080609479, 'reg_alpha': 0.27597240358895264, 'reg_lambda': 0.05774376312978017, 'max_depth': 19, 'min_split_gain': 0.001724655475771196, 'max_bin': 641, 'boosting_type': 'gbdt'}. Best is trial 41 with value: -2.6290890254637693.\n",
      "\n",
      "==================================================\n",
      "Training LightGBM\n",
      "==================================================\n",
      "Initial memory: 1719.2 MB\n",
      "Using scaled data for LightGBM\n",
      "Training LightGBM...\n",
      "Memory during training: 1719.2 MB\n",
      "Memory after training: 1719.2 MB\n",
      "Training memory increase: 0.0 MB\n",
      "Feature importance plot saved to lightgbm_feature_importance.png\n",
      "\n",
      "LightGBM Results:\n",
      "MSE: 0.006881\n",
      "RMSE: 0.082953\n",
      "MAE: 0.043314\n",
      "R2: 0.693324\n",
      "MAPE: 49.440719\n",
      "MAX_ERROR: 0.777930\n",
      "EXPLAINED_VARIANCE: 0.693324\n",
      "Final memory: 1719.7 MB\n",
      "Total memory increase: 0.5 MB\n",
      "Model saved to best_lightgbm_model.pkl\n",
      "Preprocessing objects saved to lightgbm_preprocessing.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 22:10:19,133] A new study created in memory with name: no-name-6f0bcc0c-0100-4c1c-8ec6-0ad44e5c4174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory after cleanup: 1719.7 MB\n",
      "Memory after LightGBM cleanup: 1719.7 MB\n",
      "\n",
      "============================================================\n",
      "Processing CatBoost\n",
      "============================================================\n",
      "Optimizing CatBoost hyperparameters (n_trials=50)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75dd7e5b20c4ed588c8e8115eb9b70c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in CatBoost trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 5873, in fit\n",
      "    return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 2395, in _fit\n",
      "    train_params = self._prepare_train_params(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 2321, in _prepare_train_params\n",
      "    _check_train_params(params)\n",
      "  File \"_catboost.pyx\", line 6583, in _catboost._check_train_params\n",
      "  File \"_catboost.pyx\", line 6605, in _catboost._check_train_params\n",
      "_catboost.CatBoostError: catboost/private/libs/options/bootstrap_options.cpp:44: Error: bagging temperature available for bayesian bootstrap only\n",
      "\n",
      "[I 2025-05-26 22:10:19,204] Trial 0 finished with value: inf and parameters: {'iterations': 1560, 'learning_rate': 0.3643122500671643, 'depth': 16, 'l2_leaf_reg': 0.0003473984451172297, 'bootstrap_type': 'Bernoulli', 'random_strength': 1.129586001648609e-08, 'bagging_temperature': 0.6950675073328215, 'od_type': 'IncToDec', 'od_wait': 10, 'subsample': 0.9189242139785043}. Best is trial 0 with value: inf.\n",
      "[I 2025-05-26 22:12:35,725] Trial 1 finished with value: -2.6196678354077276 and parameters: {'iterations': 1941, 'learning_rate': 0.0031531706698177506, 'depth': 12, 'l2_leaf_reg': 3.013445455450991, 'bootstrap_type': 'MVS', 'random_strength': 6.77155013038351e-05, 'bagging_temperature': 0.035435135912295745, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 1 with value: -2.6196678354077276.\n",
      "[I 2025-05-26 22:12:54,501] Trial 2 finished with value: -2.6290241995656514 and parameters: {'iterations': 931, 'learning_rate': 0.011608862849092329, 'depth': 7, 'l2_leaf_reg': 0.03345567060528399, 'bootstrap_type': 'MVS', 'random_strength': 0.7223540776335018, 'bagging_temperature': 0.8621297153641657, 'od_type': 'Iter', 'od_wait': 14}. Best is trial 2 with value: -2.6290241995656514.\n",
      "Error in CatBoost trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 5873, in fit\n",
      "    return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 2395, in _fit\n",
      "    train_params = self._prepare_train_params(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 2321, in _prepare_train_params\n",
      "    _check_train_params(params)\n",
      "  File \"_catboost.pyx\", line 6583, in _catboost._check_train_params\n",
      "  File \"_catboost.pyx\", line 6605, in _catboost._check_train_params\n",
      "_catboost.CatBoostError: catboost/private/libs/options/bootstrap_options.cpp:44: Error: bagging temperature available for bayesian bootstrap only\n",
      "\n",
      "[I 2025-05-26 22:12:54,556] Trial 3 finished with value: inf and parameters: {'iterations': 1994, 'learning_rate': 0.08690614663638757, 'depth': 4, 'l2_leaf_reg': 4.498457548539107, 'bootstrap_type': 'Bernoulli', 'random_strength': 6.618940778843235e-08, 'bagging_temperature': 0.38581331232349325, 'od_type': 'Iter', 'od_wait': 31, 'subsample': 0.60379076035817}. Best is trial 2 with value: -2.6290241995656514.\n",
      "Error in CatBoost trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 5873, in fit\n",
      "    return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 2395, in _fit\n",
      "    train_params = self._prepare_train_params(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 2321, in _prepare_train_params\n",
      "    _check_train_params(params)\n",
      "  File \"_catboost.pyx\", line 6583, in _catboost._check_train_params\n",
      "  File \"_catboost.pyx\", line 6605, in _catboost._check_train_params\n",
      "_catboost.CatBoostError: catboost/private/libs/options/bootstrap_options.cpp:44: Error: bagging temperature available for bayesian bootstrap only\n",
      "\n",
      "[I 2025-05-26 22:12:54,601] Trial 4 finished with value: inf and parameters: {'iterations': 1308, 'learning_rate': 0.06822455624179827, 'depth': 13, 'l2_leaf_reg': 0.0007917269630717671, 'bootstrap_type': 'Bernoulli', 'random_strength': 9.913672253090175, 'bagging_temperature': 0.0442626763589985, 'od_type': 'Iter', 'od_wait': 40, 'subsample': 0.6817140767403631}. Best is trial 2 with value: -2.6290241995656514.\n",
      "[I 2025-05-26 22:13:33,800] Trial 5 finished with value: -2.6008985388681993 and parameters: {'iterations': 1800, 'learning_rate': 0.001275861488908835, 'depth': 8, 'l2_leaf_reg': 5.635003639741666e-05, 'bootstrap_type': 'MVS', 'random_strength': 0.00571637990059629, 'bagging_temperature': 0.8727675889664164, 'od_type': 'IncToDec', 'od_wait': 10}. Best is trial 2 with value: -2.6290241995656514.\n",
      "[I 2025-05-26 22:15:09,378] Trial 6 finished with value: -2.5965075518524317 and parameters: {'iterations': 1400, 'learning_rate': 0.0018995015782726022, 'depth': 12, 'l2_leaf_reg': 2.1318515218522207e-06, 'bootstrap_type': 'MVS', 'random_strength': 0.004318007907619573, 'bagging_temperature': 0.1617292625251071, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 2 with value: -2.6290241995656514.\n",
      "Error in CatBoost trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 5873, in fit\n",
      "    return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 2395, in _fit\n",
      "    train_params = self._prepare_train_params(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 2321, in _prepare_train_params\n",
      "    _check_train_params(params)\n",
      "  File \"_catboost.pyx\", line 6583, in _catboost._check_train_params\n",
      "  File \"_catboost.pyx\", line 6605, in _catboost._check_train_params\n",
      "_catboost.CatBoostError: catboost/private/libs/options/bootstrap_options.cpp:44: Error: bagging temperature available for bayesian bootstrap only\n",
      "\n",
      "[I 2025-05-26 22:15:09,443] Trial 7 finished with value: inf and parameters: {'iterations': 1656, 'learning_rate': 0.019970727225556303, 'depth': 16, 'l2_leaf_reg': 0.00021687687415567215, 'bootstrap_type': 'Bernoulli', 'random_strength': 5.279928021007792e-06, 'bagging_temperature': 0.4557462192249365, 'od_type': 'IncToDec', 'od_wait': 12, 'subsample': 0.9182058894305867}. Best is trial 2 with value: -2.6290241995656514.\n",
      "[I 2025-05-26 22:16:55,226] Trial 8 finished with value: -2.6358767388008535 and parameters: {'iterations': 688, 'learning_rate': 0.013894846912416992, 'depth': 13, 'l2_leaf_reg': 6.024304869844931e-05, 'bootstrap_type': 'Bayesian', 'random_strength': 0.00022032558005306095, 'bagging_temperature': 0.027500779049284052, 'od_type': 'IncToDec', 'od_wait': 17}. Best is trial 8 with value: -2.6358767388008535.\n",
      "[I 2025-05-26 22:17:07,638] Trial 9 finished with value: -2.3944236057738277 and parameters: {'iterations': 547, 'learning_rate': 0.001229902253632419, 'depth': 7, 'l2_leaf_reg': 0.6002159343699229, 'bootstrap_type': 'MVS', 'random_strength': 0.009478509213356268, 'bagging_temperature': 0.5748357420675072, 'od_type': 'Iter', 'od_wait': 16}. Best is trial 8 with value: -2.6358767388008535.\n",
      "[I 2025-05-26 22:19:44,378] Trial 10 finished with value: -2.6323116991081603 and parameters: {'iterations': 2956, 'learning_rate': 0.0066076877924850265, 'depth': 11, 'l2_leaf_reg': 2.634756152968203e-08, 'bootstrap_type': 'Bayesian', 'random_strength': 4.348536051108862e-06, 'bagging_temperature': 0.2659042335707307, 'od_type': 'IncToDec', 'od_wait': 23}. Best is trial 8 with value: -2.6358767388008535.\n",
      "[I 2025-05-26 22:21:23,972] Trial 11 finished with value: -2.633588392287345 and parameters: {'iterations': 2799, 'learning_rate': 0.007970349387199788, 'depth': 10, 'l2_leaf_reg': 1.4269881980709516e-08, 'bootstrap_type': 'Bayesian', 'random_strength': 3.1388364875815934e-06, 'bagging_temperature': 0.26124422956941806, 'od_type': 'IncToDec', 'od_wait': 23}. Best is trial 8 with value: -2.6358767388008535.\n",
      "[I 2025-05-26 22:34:55,436] Trial 12 finished with value: -2.579336510716654 and parameters: {'iterations': 2886, 'learning_rate': 0.048989064428665276, 'depth': 14, 'l2_leaf_reg': 2.1082904532700007e-08, 'bootstrap_type': 'Bayesian', 'random_strength': 2.882927354488317e-06, 'bagging_temperature': 0.25600889677078753, 'od_type': 'IncToDec', 'od_wait': 25}. Best is trial 8 with value: -2.6358767388008535.\n",
      "[I 2025-05-26 22:35:02,906] Trial 13 finished with value: -2.4153591709279514 and parameters: {'iterations': 126, 'learning_rate': 0.0053717955027883435, 'depth': 10, 'l2_leaf_reg': 6.873343891070917e-07, 'bootstrap_type': 'Bayesian', 'random_strength': 0.00018810831326344108, 'bagging_temperature': 0.1863939675008573, 'od_type': 'IncToDec', 'od_wait': 20}. Best is trial 8 with value: -2.6358767388008535.\n",
      "[I 2025-05-26 22:36:07,999] Trial 14 finished with value: -2.6209298592951558 and parameters: {'iterations': 2443, 'learning_rate': 0.026928338141814324, 'depth': 9, 'l2_leaf_reg': 3.513839329874532e-06, 'bootstrap_type': 'Bayesian', 'random_strength': 4.220953251755064e-07, 'bagging_temperature': 0.010036989236082317, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 8 with value: -2.6358767388008535.\n",
      "[I 2025-05-26 22:36:21,100] Trial 15 finished with value: -2.631756484790042 and parameters: {'iterations': 916, 'learning_rate': 0.015163986551167059, 'depth': 4, 'l2_leaf_reg': 0.018738944595194682, 'bootstrap_type': 'Bayesian', 'random_strength': 2.1244548844756584e-05, 'bagging_temperature': 0.35626051996861663, 'od_type': 'IncToDec', 'od_wait': 50}. Best is trial 8 with value: -2.6358767388008535.\n",
      "[I 2025-05-26 22:47:49,912] Trial 16 finished with value: -2.6259166052912764 and parameters: {'iterations': 2448, 'learning_rate': 0.00648786661157132, 'depth': 14, 'l2_leaf_reg': 2.0204626261284436e-07, 'bootstrap_type': 'Bayesian', 'random_strength': 0.0008437736839173016, 'bagging_temperature': 0.14700738424437823, 'od_type': 'IncToDec', 'od_wait': 18}. Best is trial 8 with value: -2.6358767388008535.\n",
      "[I 2025-05-26 22:47:58,554] Trial 17 finished with value: -2.6270892184428427 and parameters: {'iterations': 158, 'learning_rate': 0.1446632390638445, 'depth': 10, 'l2_leaf_reg': 6.450425547951628e-06, 'bootstrap_type': 'Bayesian', 'random_strength': 0.18243485561054976, 'bagging_temperature': 0.30369338214035585, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 8 with value: -2.6358767388008535.\n",
      "[I 2025-05-26 22:48:15,557] Trial 18 finished with value: -2.6374270967086475 and parameters: {'iterations': 973, 'learning_rate': 0.03413878740902724, 'depth': 6, 'l2_leaf_reg': 2.02632141948656e-05, 'bootstrap_type': 'Bayesian', 'random_strength': 3.2499402649388945e-07, 'bagging_temperature': 0.5448597835638371, 'od_type': 'IncToDec', 'od_wait': 24}. Best is trial 18 with value: -2.6374270967086475.\n",
      "[I 2025-05-26 22:48:31,591] Trial 19 finished with value: -2.6378233684901025 and parameters: {'iterations': 877, 'learning_rate': 0.03470303528845361, 'depth': 6, 'l2_leaf_reg': 2.9929493024202343e-05, 'bootstrap_type': 'Bayesian', 'random_strength': 1.876217722745132e-07, 'bagging_temperature': 0.6207845667467237, 'od_type': 'IncToDec', 'od_wait': 27}. Best is trial 19 with value: -2.6378233684901025.\n",
      "[I 2025-05-26 22:48:47,585] Trial 20 finished with value: -2.6382079222191974 and parameters: {'iterations': 1031, 'learning_rate': 0.031776688337818756, 'depth': 5, 'l2_leaf_reg': 0.003976722708025873, 'bootstrap_type': 'Bayesian', 'random_strength': 2.573712085369963e-07, 'bagging_temperature': 0.6340353543077112, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 20 with value: -2.6382079222191974.\n",
      "[I 2025-05-26 22:49:05,353] Trial 21 finished with value: -2.637659453384244 and parameters: {'iterations': 1144, 'learning_rate': 0.037624314575804, 'depth': 5, 'l2_leaf_reg': 0.003186843610128393, 'bootstrap_type': 'Bayesian', 'random_strength': 1.7922841258566402e-07, 'bagging_temperature': 0.637855453703577, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 20 with value: -2.6382079222191974.\n",
      "[I 2025-05-26 22:49:20,082] Trial 22 finished with value: -2.6314482037587728 and parameters: {'iterations': 1240, 'learning_rate': 0.14024981580530863, 'depth': 3, 'l2_leaf_reg': 0.003489435797245524, 'bootstrap_type': 'Bayesian', 'random_strength': 2.6891773420848132e-08, 'bagging_temperature': 0.6907862146296833, 'od_type': 'IncToDec', 'od_wait': 36}. Best is trial 20 with value: -2.6382079222191974.\n",
      "[I 2025-05-26 22:49:30,825] Trial 23 finished with value: -2.6366381751338586 and parameters: {'iterations': 559, 'learning_rate': 0.031340973166148214, 'depth': 5, 'l2_leaf_reg': 0.03157822339228915, 'bootstrap_type': 'Bayesian', 'random_strength': 2.12369053614288e-07, 'bagging_temperature': 0.6730583023285615, 'od_type': 'IncToDec', 'od_wait': 36}. Best is trial 20 with value: -2.6382079222191974.\n",
      "[I 2025-05-26 22:49:50,347] Trial 24 finished with value: -2.6346971408541706 and parameters: {'iterations': 1135, 'learning_rate': 0.05030305718186019, 'depth': 6, 'l2_leaf_reg': 0.003691823054216933, 'bootstrap_type': 'Bayesian', 'random_strength': 7.175647032186275e-07, 'bagging_temperature': 0.7900286525645894, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 20 with value: -2.6382079222191974.\n",
      "[I 2025-05-26 22:50:00,515] Trial 25 finished with value: -2.633498983353974 and parameters: {'iterations': 724, 'learning_rate': 0.1327106793384373, 'depth': 3, 'l2_leaf_reg': 0.2223029075034469, 'bootstrap_type': 'Bayesian', 'random_strength': 9.30309054924846e-08, 'bagging_temperature': 0.6007870944938271, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 20 with value: -2.6382079222191974.\n",
      "[I 2025-05-26 22:50:08,098] Trial 26 finished with value: -2.6239999248502746 and parameters: {'iterations': 335, 'learning_rate': 0.2740357321760161, 'depth': 5, 'l2_leaf_reg': 0.0034691335140102616, 'bootstrap_type': 'Bayesian', 'random_strength': 1.1129282225362208e-08, 'bagging_temperature': 0.9521528318028177, 'od_type': 'IncToDec', 'od_wait': 44}. Best is trial 20 with value: -2.6382079222191974.\n",
      "[I 2025-05-26 22:50:32,175] Trial 27 finished with value: -2.629807798772373 and parameters: {'iterations': 1035, 'learning_rate': 0.0423776880868539, 'depth': 8, 'l2_leaf_reg': 0.0008260872573162177, 'bootstrap_type': 'Bayesian', 'random_strength': 2.3912341485683657e-05, 'bagging_temperature': 0.4857416297020457, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 20 with value: -2.6382079222191974.\n",
      "[I 2025-05-26 22:50:52,852] Trial 28 finished with value: -2.6296432358341466 and parameters: {'iterations': 1396, 'learning_rate': 0.08485623376598754, 'depth': 5, 'l2_leaf_reg': 9.553008066531307e-05, 'bootstrap_type': 'Bayesian', 'random_strength': 1.0865419890970556e-06, 'bagging_temperature': 0.7648977593317372, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 20 with value: -2.6382079222191974.\n",
      "Error in CatBoost trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 5873, in fit\n",
      "    return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 2395, in _fit\n",
      "    train_params = self._prepare_train_params(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 2321, in _prepare_train_params\n",
      "    _check_train_params(params)\n",
      "  File \"_catboost.pyx\", line 6583, in _catboost._check_train_params\n",
      "  File \"_catboost.pyx\", line 6605, in _catboost._check_train_params\n",
      "_catboost.CatBoostError: catboost/private/libs/options/bootstrap_options.cpp:44: Error: bagging temperature available for bayesian bootstrap only\n",
      "\n",
      "[I 2025-05-26 22:50:52,937] Trial 29 finished with value: inf and parameters: {'iterations': 1572, 'learning_rate': 0.45569698347265897, 'depth': 6, 'l2_leaf_reg': 0.0005653698290245996, 'bootstrap_type': 'Bernoulli', 'random_strength': 3.3788436481822964e-08, 'bagging_temperature': 0.6802332887318087, 'od_type': 'IncToDec', 'od_wait': 32, 'subsample': 0.5095027177890394}. Best is trial 20 with value: -2.6382079222191974.\n",
      "Error in CatBoost trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 5873, in fit\n",
      "    return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 2395, in _fit\n",
      "    train_params = self._prepare_train_params(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 2321, in _prepare_train_params\n",
      "    _check_train_params(params)\n",
      "  File \"_catboost.pyx\", line 6583, in _catboost._check_train_params\n",
      "  File \"_catboost.pyx\", line 6605, in _catboost._check_train_params\n",
      "_catboost.CatBoostError: catboost/private/libs/options/bootstrap_options.cpp:44: Error: bagging temperature available for bayesian bootstrap only\n",
      "\n",
      "[I 2025-05-26 22:50:53,020] Trial 30 finished with value: inf and parameters: {'iterations': 778, 'learning_rate': 0.25037514766091556, 'depth': 4, 'l2_leaf_reg': 0.11096378230270938, 'bootstrap_type': 'Bernoulli', 'random_strength': 1.0034855989936425e-08, 'bagging_temperature': 0.7640359615367807, 'od_type': 'IncToDec', 'od_wait': 45, 'subsample': 0.8046583548115417}. Best is trial 20 with value: -2.6382079222191974.\n",
      "[I 2025-05-26 22:51:12,644] Trial 31 finished with value: -2.6370940287663927 and parameters: {'iterations': 1147, 'learning_rate': 0.032469317379071425, 'depth': 6, 'l2_leaf_reg': 1.911777197214931e-05, 'bootstrap_type': 'Bayesian', 'random_strength': 1.450362941404276e-07, 'bagging_temperature': 0.57712541039151, 'od_type': 'IncToDec', 'od_wait': 25}. Best is trial 20 with value: -2.6382079222191974.\n",
      "[I 2025-05-26 22:51:31,580] Trial 32 finished with value: -2.6392587710112174 and parameters: {'iterations': 937, 'learning_rate': 0.018859493229949634, 'depth': 7, 'l2_leaf_reg': 2.119163211595901e-05, 'bootstrap_type': 'Bayesian', 'random_strength': 8.715893629719386e-07, 'bagging_temperature': 0.6068512251091219, 'od_type': 'IncToDec', 'od_wait': 39}. Best is trial 32 with value: -2.6392587710112174.\n",
      "[I 2025-05-26 22:51:42,806] Trial 33 finished with value: -2.637709572372237 and parameters: {'iterations': 456, 'learning_rate': 0.020421664037988885, 'depth': 7, 'l2_leaf_reg': 0.009211793625834503, 'bootstrap_type': 'Bayesian', 'random_strength': 1.7584830344499525e-05, 'bagging_temperature': 0.6380664391280841, 'od_type': 'IncToDec', 'od_wait': 39}. Best is trial 32 with value: -2.6392587710112174.\n",
      "[I 2025-05-26 22:51:56,627] Trial 34 finished with value: -2.627215856691562 and parameters: {'iterations': 522, 'learning_rate': 0.019236996338852605, 'depth': 8, 'l2_leaf_reg': 1.7378892220595913e-05, 'bootstrap_type': 'MVS', 'random_strength': 1.0815078604993683e-05, 'bagging_temperature': 0.4276673650541235, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 32 with value: -2.6392587710112174.\n",
      "[I 2025-05-26 22:52:07,039] Trial 35 finished with value: -2.625901118006195 and parameters: {'iterations': 422, 'learning_rate': 0.00931603678210459, 'depth': 7, 'l2_leaf_reg': 0.00018415546862552638, 'bootstrap_type': 'Bayesian', 'random_strength': 6.145313019017583e-05, 'bagging_temperature': 0.5180705990035159, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 32 with value: -2.6392587710112174.\n",
      "[I 2025-05-26 22:52:31,786] Trial 36 finished with value: -2.6323771142347456 and parameters: {'iterations': 843, 'learning_rate': 0.0047170486657878334, 'depth': 9, 'l2_leaf_reg': 0.011527161962901602, 'bootstrap_type': 'Bayesian', 'random_strength': 1.2337254137060556e-06, 'bagging_temperature': 0.8349436279508933, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 32 with value: -2.6392587710112174.\n",
      "[I 2025-05-26 22:52:40,775] Trial 37 finished with value: -2.613539055858193 and parameters: {'iterations': 321, 'learning_rate': 0.011125828120392074, 'depth': 7, 'l2_leaf_reg': 1.5239414309726929, 'bootstrap_type': 'MVS', 'random_strength': 5.610046903113463e-08, 'bagging_temperature': 0.7368701979092609, 'od_type': 'Iter', 'od_wait': 47}. Best is trial 32 with value: -2.6392587710112174.\n",
      "Error in CatBoost trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 5873, in fit\n",
      "    return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 2395, in _fit\n",
      "    train_params = self._prepare_train_params(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 2321, in _prepare_train_params\n",
      "    _check_train_params(params)\n",
      "  File \"_catboost.pyx\", line 6583, in _catboost._check_train_params\n",
      "  File \"_catboost.pyx\", line 6605, in _catboost._check_train_params\n",
      "_catboost.CatBoostError: catboost/private/libs/options/bootstrap_options.cpp:44: Error: bagging temperature available for bayesian bootstrap only\n",
      "\n",
      "[I 2025-05-26 22:52:40,861] Trial 38 finished with value: inf and parameters: {'iterations': 701, 'learning_rate': 0.02213063253845908, 'depth': 8, 'l2_leaf_reg': 0.0012010962716072326, 'bootstrap_type': 'Bernoulli', 'random_strength': 9.507905278438763e-07, 'bagging_temperature': 0.6464351024984919, 'od_type': 'IncToDec', 'od_wait': 38, 'subsample': 0.9978831366625682}. Best is trial 32 with value: -2.6392587710112174.\n",
      "[I 2025-05-26 22:53:16,094] Trial 39 finished with value: -2.6202169398366015 and parameters: {'iterations': 1928, 'learning_rate': 0.05913226385440316, 'depth': 7, 'l2_leaf_reg': 0.07522772492900502, 'bootstrap_type': 'Bayesian', 'random_strength': 3.778618878014493e-05, 'bagging_temperature': 0.61384974824703, 'od_type': 'IncToDec', 'od_wait': 41}. Best is trial 32 with value: -2.6392587710112174.\n",
      "[I 2025-05-26 22:53:35,250] Trial 40 finished with value: -2.616684611353213 and parameters: {'iterations': 1453, 'learning_rate': 0.015997901714899437, 'depth': 4, 'l2_leaf_reg': 0.00022434137514353565, 'bootstrap_type': 'MVS', 'random_strength': 0.0008562722958412835, 'bagging_temperature': 0.9206798638652569, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 32 with value: -2.6392587710112174.\n",
      "[I 2025-05-26 22:53:52,843] Trial 41 finished with value: -2.6306804786052567 and parameters: {'iterations': 1131, 'learning_rate': 0.08519255261928436, 'depth': 5, 'l2_leaf_reg': 0.005975947728028192, 'bootstrap_type': 'Bayesian', 'random_strength': 1.5220220829881204e-07, 'bagging_temperature': 0.6200386097662165, 'od_type': 'IncToDec', 'od_wait': 38}. Best is trial 32 with value: -2.6392587710112174.\n",
      "[I 2025-05-26 22:54:10,192] Trial 42 finished with value: -2.6385830862629867 and parameters: {'iterations': 990, 'learning_rate': 0.026066903230795142, 'depth': 6, 'l2_leaf_reg': 0.0016454403445843625, 'bootstrap_type': 'Bayesian', 'random_strength': 7.556238729857489e-06, 'bagging_temperature': 0.7255884867522902, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 32 with value: -2.6392587710112174.\n",
      "[I 2025-05-26 22:54:26,180] Trial 43 finished with value: -2.638562823195822 and parameters: {'iterations': 877, 'learning_rate': 0.025255306325528713, 'depth': 6, 'l2_leaf_reg': 0.001054133150130997, 'bootstrap_type': 'Bayesian', 'random_strength': 8.992082261766732e-06, 'bagging_temperature': 0.7203179311325867, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 32 with value: -2.6392587710112174.\n",
      "[I 2025-05-26 22:54:42,143] Trial 44 finished with value: -2.6385824111402747 and parameters: {'iterations': 879, 'learning_rate': 0.02542755581641172, 'depth': 6, 'l2_leaf_reg': 4.591455577245734e-05, 'bootstrap_type': 'Bayesian', 'random_strength': 5.882716871880989e-06, 'bagging_temperature': 0.7255154230997142, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 32 with value: -2.6392587710112174.\n",
      "Error in CatBoost trial: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 5873, in fit\n",
      "    return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 2395, in _fit\n",
      "    train_params = self._prepare_train_params(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 2321, in _prepare_train_params\n",
      "    _check_train_params(params)\n",
      "  File \"_catboost.pyx\", line 6583, in _catboost._check_train_params\n",
      "  File \"_catboost.pyx\", line 6605, in _catboost._check_train_params\n",
      "_catboost.CatBoostError: catboost/private/libs/options/bootstrap_options.cpp:44: Error: bagging temperature available for bayesian bootstrap only\n",
      "\n",
      "[I 2025-05-26 22:54:42,232] Trial 45 finished with value: inf and parameters: {'iterations': 1008, 'learning_rate': 0.011666607589379518, 'depth': 6, 'l2_leaf_reg': 0.0012897693407066388, 'bootstrap_type': 'Bernoulli', 'random_strength': 4.818457339002688e-06, 'bagging_temperature': 0.7214736325931078, 'od_type': 'IncToDec', 'od_wait': 33, 'subsample': 0.7760030590673871}. Best is trial 32 with value: -2.6392587710112174.\n",
      "[I 2025-05-26 22:54:52,006] Trial 46 finished with value: -2.6243769890717727 and parameters: {'iterations': 665, 'learning_rate': 0.024642178930167274, 'depth': 3, 'l2_leaf_reg': 7.81714500595097e-05, 'bootstrap_type': 'Bayesian', 'random_strength': 8.885055137266008e-06, 'bagging_temperature': 0.8070531160059551, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 32 with value: -2.6392587710112174.\n",
      "[I 2025-05-26 22:55:20,683] Trial 47 finished with value: -2.637488922621004 and parameters: {'iterations': 1268, 'learning_rate': 0.016723050535274907, 'depth': 8, 'l2_leaf_reg': 9.131335005279144e-07, 'bootstrap_type': 'Bayesian', 'random_strength': 1.8541072329184788e-06, 'bagging_temperature': 0.7179241534916384, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 32 with value: -2.6392587710112174.\n",
      "[I 2025-05-26 22:55:41,719] Trial 48 finished with value: -2.6346230482700763 and parameters: {'iterations': 1667, 'learning_rate': 0.06749666036344418, 'depth': 4, 'l2_leaf_reg': 7.030157562234121e-06, 'bootstrap_type': 'Bayesian', 'random_strength': 0.0001446332719643484, 'bagging_temperature': 0.8889541274013713, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 32 with value: -2.6392587710112174.\n",
      "[I 2025-05-26 22:55:55,714] Trial 49 finished with value: -2.62049095259236 and parameters: {'iterations': 837, 'learning_rate': 0.011869561403350519, 'depth': 5, 'l2_leaf_reg': 0.00036766811197560335, 'bootstrap_type': 'MVS', 'random_strength': 7.357847957981028e-05, 'bagging_temperature': 0.5444880078045479, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 32 with value: -2.6392587710112174.\n",
      "\n",
      "==================================================\n",
      "Training CatBoost\n",
      "==================================================\n",
      "Initial memory: 3483.6 MB\n",
      "Using original data for CatBoost\n",
      "Training CatBoost...\n",
      "Memory during training: 3483.6 MB\n",
      "Memory after training: 3493.5 MB\n",
      "Training memory increase: 9.9 MB\n",
      "Feature importance plot saved to catboost_feature_importance.png\n",
      "\n",
      "CatBoost Results:\n",
      "MSE: 0.006773\n",
      "RMSE: 0.082299\n",
      "MAE: 0.043268\n",
      "R2: 0.698140\n",
      "MAPE: 49.834205\n",
      "MAX_ERROR: 0.778773\n",
      "EXPLAINED_VARIANCE: 0.698142\n",
      "Final memory: 3494.4 MB\n",
      "Total memory increase: 10.8 MB\n",
      "Model saved to best_catboost_model.pkl\n",
      "Preprocessing objects saved to catboost_preprocessing.pkl\n",
      "Memory after cleanup: 3494.4 MB\n",
      "Memory after CatBoost cleanup: 3494.4 MB\n",
      "\n",
      "============================================================\n",
      "FINAL RESULTS\n",
      "============================================================\n",
      "1. XGBoost: R² = 0.699683\n",
      "2. CatBoost: R² = 0.698140\n",
      "3. LightGBM: R² = 0.693324\n",
      "\n",
      "Best Model: XGBoost\n",
      "Best R² Score: 0.699683\n",
      "Best RMSE: 0.082088\n",
      "\n",
      "Results saved to 'model_comparison_results.json'\n",
      "\n",
      "Comparison completed!\n",
      "Best model: XGBoost\n",
      "Best R²: 0.699683\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.datasets import make_regression  # Added missing import\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import json\n",
    "import joblib\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import gc  # Added missing import\n",
    "import psutil  # Added missing import\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def check_gpu_availability():\n",
    "    \"\"\"\n",
    "    Robustly check if GPU is available for XGBoost, LightGBM, and CatBoost\n",
    "    by actually testing model training, not just initialization\n",
    "    \"\"\"\n",
    "    print(\"Checking GPU availability...\")\n",
    "    \n",
    "    # Create small test data for actual GPU testing\n",
    "    X_test, y_test = make_regression(n_samples=100, n_features=5, noise=0.1, random_state=42)\n",
    "    \n",
    "    # Check XGBoost GPU support\n",
    "    xgb_device = 'cpu'\n",
    "    try:\n",
    "        import xgboost as xgb\n",
    "        \n",
    "        # Test actual GPU training\n",
    "        model = xgb.XGBRegressor(\n",
    "            device='cuda',\n",
    "            tree_method='hist',\n",
    "            n_estimators=10,\n",
    "            max_depth=3,\n",
    "            random_state=42\n",
    "        )\n",
    "        model.fit(X_test, y_test)\n",
    "        _ = model.predict(X_test)  # Test prediction too\n",
    "        \n",
    "        print(\"✓ XGBoost GPU support available and working\")\n",
    "        xgb_device = 'cuda'\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"✗ XGBoost not installed\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ XGBoost GPU support not available: {str(e)[:100]}\")\n",
    "        print(\"  → Using CPU for XGBoost\")\n",
    "    \n",
    "    # Check LightGBM GPU support\n",
    "    lgb_device = 'cpu'\n",
    "    try:\n",
    "        import lightgbm as lgb\n",
    "        \n",
    "        # Test actual GPU training\n",
    "        model = lgb.LGBMRegressor(\n",
    "            device='gpu',\n",
    "            n_estimators=10,\n",
    "            max_depth=3,\n",
    "            verbose=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "        model.fit(X_test, y_test)\n",
    "        _ = model.predict(X_test)\n",
    "        \n",
    "        print(\"✓ LightGBM GPU support available and working\")\n",
    "        lgb_device = 'gpu'\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"✗ LightGBM not installed\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ LightGBM GPU support not available: {str(e)[:100]}\")\n",
    "        print(\"  → Using CPU for LightGBM\")\n",
    "    \n",
    "    # Check CatBoost GPU support\n",
    "    cb_device = 'CPU'\n",
    "    try:\n",
    "        import catboost as cb\n",
    "        \n",
    "        # Test actual GPU training\n",
    "        model = cb.CatBoostRegressor(\n",
    "            task_type='GPU',\n",
    "            iterations=10,\n",
    "            depth=3,\n",
    "            verbose=False,\n",
    "            random_seed=42\n",
    "        )\n",
    "        model.fit(X_test, y_test)\n",
    "        _ = model.predict(X_test)\n",
    "        \n",
    "        print(\"✓ CatBoost GPU support available and working\")\n",
    "        cb_device = 'GPU'\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"✗ CatBoost not installed\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ CatBoost GPU support not available: {str(e)[:100]}\")\n",
    "        print(\"  → Using CPU for CatBoost\")\n",
    "    \n",
    "    print(f\"\\nFinal device configuration:\")\n",
    "    print(f\"  XGBoost: {xgb_device.upper()}\")\n",
    "    print(f\"  LightGBM: {lgb_device.upper()}\")\n",
    "    print(f\"  CatBoost: {cb_device}\")\n",
    "    \n",
    "    return xgb_device, lgb_device, cb_device\n",
    "\n",
    "def get_memory_usage():\n",
    "    \"\"\"Get current memory usage in MB\"\"\"\n",
    "    try:\n",
    "        process = psutil.Process()\n",
    "        return process.memory_info().rss / 1024 / 1024\n",
    "    except:\n",
    "        return 0.0  # Return 0 if psutil fails\n",
    "\n",
    "def prepare_data_with_memory_management(data, features, target, scale_for_tree_models=True):\n",
    "    \"\"\"\n",
    "    Enhanced data preparation with consistent scaling and memory management\n",
    "    \"\"\"\n",
    "    print(f\"Initial memory usage: {get_memory_usage():.1f} MB\")\n",
    "    print(f\"Data shape: {data.shape}\")\n",
    "    \n",
    "    # Convert features to list if needed\n",
    "    if isinstance(features, pd.DataFrame):\n",
    "        feature_list = features.columns.tolist()\n",
    "    elif isinstance(features, pd.Series):\n",
    "        feature_list = features.tolist()\n",
    "    elif isinstance(features, (list, tuple)):\n",
    "        feature_list = list(features)\n",
    "    else:\n",
    "        raise ValueError(f\"Features must be a list, tuple, Series, or DataFrame. Got {type(features)}\")\n",
    "    \n",
    "    # Convert target to string\n",
    "    if isinstance(target, pd.Series):\n",
    "        target_name = target.name if target.name else str(target.iloc[0])\n",
    "    elif isinstance(target, (list, tuple)):\n",
    "        target_name = target[0] if len(target) == 1 else str(target)\n",
    "    else:\n",
    "        target_name = str(target)\n",
    "    \n",
    "    # Validate features and target exist\n",
    "    missing_features = [f for f in feature_list if f not in data.columns]\n",
    "    if missing_features:\n",
    "        raise ValueError(f\"Features not found in data: {missing_features}\")\n",
    "    \n",
    "    if target_name not in data.columns:\n",
    "        raise ValueError(f\"Target '{target_name}' not found in data\")\n",
    "    \n",
    "    print(f\"Using {len(feature_list)} features and target: {target_name}\")\n",
    "    \n",
    "    # Create copies to avoid modifying original data\n",
    "    X = data[feature_list].copy()\n",
    "    y = data[target_name].copy()\n",
    "    \n",
    "    print(f\"Memory after data selection: {get_memory_usage():.1f} MB\")\n",
    "    \n",
    "    # Identify categorical and numeric columns\n",
    "    categorical_columns = []\n",
    "    numeric_columns = []\n",
    "    \n",
    "    for col in X.columns:\n",
    "        if X[col].dtype in ['object', 'category']:\n",
    "            categorical_columns.append(col)\n",
    "        elif pd.api.types.is_numeric_dtype(X[col]):\n",
    "            numeric_columns.append(col)\n",
    "        else:\n",
    "            # Handle edge cases\n",
    "            try:\n",
    "                pd.to_numeric(X[col])\n",
    "                numeric_columns.append(col)\n",
    "            except:\n",
    "                categorical_columns.append(col)\n",
    "    \n",
    "    print(f\"Categorical columns ({len(categorical_columns)}): {categorical_columns[:5]}...\")\n",
    "    print(f\"Numeric columns ({len(numeric_columns)}): {numeric_columns[:5]}...\")\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    label_encoders = {}\n",
    "    if categorical_columns:\n",
    "        print(\"Encoding categorical variables...\")\n",
    "        for col in categorical_columns:\n",
    "            le = LabelEncoder()\n",
    "            X[col] = le.fit_transform(X[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "    \n",
    "    # Handle missing values\n",
    "    if X.isnull().sum().sum() > 0:\n",
    "        print(\"Handling missing values...\")\n",
    "        for col in X.columns:\n",
    "            if X[col].isnull().sum() > 0:\n",
    "                if col in categorical_columns:\n",
    "                    X[col].fillna(X[col].mode()[0], inplace=True)\n",
    "                else:\n",
    "                    X[col].fillna(X[col].median(), inplace=True)\n",
    "    \n",
    "    # Remove rows with missing target values\n",
    "    if y.isnull().sum() > 0:\n",
    "        print(f\"Removing {y.isnull().sum()} rows with missing target values\")\n",
    "        mask = ~y.isnull()\n",
    "        X = X[mask]\n",
    "        y = y[mask]\n",
    "    \n",
    "    # Ensure all data is numeric\n",
    "    for col in X.columns:\n",
    "        if not pd.api.types.is_numeric_dtype(X[col]):\n",
    "            X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "            if X[col].isnull().sum() > 0:\n",
    "                X[col].fillna(X[col].median(), inplace=True)\n",
    "    \n",
    "    print(f\"Memory after preprocessing: {get_memory_usage():.1f} MB\")\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "    \n",
    "    # Prepare different versions for different model types\n",
    "    data_versions = {\n",
    "        'original': {\n",
    "            'X_train': X_train.copy(),\n",
    "            'X_test': X_test.copy(),\n",
    "            'description': 'Original data (best for CatBoost)'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Scale data if requested (for XGBoost and LightGBM)\n",
    "    if scale_for_tree_models:\n",
    "        print(\"Creating scaled versions for tree models...\")\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = pd.DataFrame(\n",
    "            scaler.fit_transform(X_train),\n",
    "            columns=X_train.columns,\n",
    "            index=X_train.index\n",
    "        )\n",
    "        X_test_scaled = pd.DataFrame(\n",
    "            scaler.transform(X_test),\n",
    "            columns=X_test.columns,\n",
    "            index=X_test.index\n",
    "        )\n",
    "        \n",
    "        data_versions['scaled'] = {\n",
    "            'X_train': X_train_scaled,\n",
    "            'X_test': X_test_scaled,\n",
    "            'scaler': scaler,\n",
    "            'description': 'Scaled data (best for XGBoost/LightGBM if using scaled features)'\n",
    "        }\n",
    "    else:\n",
    "        data_versions['scaled'] = data_versions['original']\n",
    "        print(\"Skipping scaling - using original data for all models\")\n",
    "    \n",
    "    print(f\"Final memory usage: {get_memory_usage():.1f} MB\")\n",
    "    \n",
    "    return {\n",
    "        'data_versions': data_versions,\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test,\n",
    "        'feature_list': feature_list,\n",
    "        'label_encoders': label_encoders,\n",
    "        'categorical_columns': categorical_columns,\n",
    "        'target_name': target_name,\n",
    "        'scaler': data_versions['scaled'].get('scaler', None) \n",
    "    }\n",
    "\n",
    "def custom_score(y_true, y_pred):\n",
    "    \"\"\"Enhanced scoring function combining multiple metrics\"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    # Combine metrics for a comprehensive score\n",
    "    score = r2  # Start with R²\n",
    "    if mse > 0:\n",
    "        score += 1 / (1 + mse)  # Add inverse MSE (normalized)\n",
    "    if mae > 0:\n",
    "        score += 1 / (1 + mae)  # Add inverse MAE (normalized)\n",
    "    return score\n",
    "\n",
    "def optimize_xgboost(X_train_scaled, y_train, n_trials, device='cuda'):\n",
    "    \"\"\"Optimize XGBoost hyperparameters using Optuna\"\"\"\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.5, log=True),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 20),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n",
    "            'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log=True),\n",
    "            'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log=True),\n",
    "            'max_leaves': trial.suggest_int('max_leaves', 0, 1000),\n",
    "            'max_bin': trial.suggest_int('max_bin', 200, 1000),\n",
    "            'device': device,\n",
    "            'tree_method': 'hist' if device == 'cuda' else 'auto'\n",
    "        }\n",
    "      \n",
    "        model = XGBRegressor(**params, random_state=42)\n",
    "        try:\n",
    "            scores = cross_val_score(\n",
    "                model, X_train_scaled, y_train,\n",
    "                cv=5,\n",
    "                scoring=make_scorer(custom_score, greater_is_better=True),\n",
    "                n_jobs=1 if device == 'cuda' else -1\n",
    "            )\n",
    "            return -scores.mean()\n",
    "        except Exception as e:\n",
    "            print(f\"Error in XGBoost trial: {e}\")\n",
    "            return float('inf')\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "    return study.best_params\n",
    "\n",
    "def optimize_lightgbm(X_train_scaled, y_train, n_trials, device='gpu'):\n",
    "    \"\"\"Optimize LightGBM hyperparameters using Optuna\"\"\"\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 5, 100),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.5, log=True),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 1, 300),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', -1, 20),\n",
    "            'min_split_gain': trial.suggest_float('min_split_gain', 1e-8, 1.0, log=True),\n",
    "            'max_bin': trial.suggest_int('max_bin', 200, 1000),\n",
    "            'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt', 'goss']),\n",
    "            'device': device,\n",
    "            'gpu_use_dp': True if device == 'gpu' else False,\n",
    "            'force_col_wise': True if device == 'gpu' else False\n",
    "        }\n",
    "        \n",
    "        model = LGBMRegressor(**params, random_state=42, verbose=-1)\n",
    "        try:\n",
    "            scores = cross_val_score(\n",
    "                model, X_train_scaled, y_train,\n",
    "                cv=5,\n",
    "                scoring=make_scorer(custom_score, greater_is_better=True),\n",
    "                n_jobs=1 if device == 'gpu' else -1\n",
    "            )\n",
    "            return -scores.mean()\n",
    "        except Exception as e:\n",
    "            print(f\"Error in LightGBM trial: {e}\")\n",
    "            return float('inf')\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "    return study.best_params\n",
    "\n",
    "def optimize_catboost(X_train, y_train, n_trials, device='GPU', cat_features=None):\n",
    "    \"\"\"Optimize CatBoost hyperparameters using Optuna\"\"\"\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'iterations': trial.suggest_int('iterations', 100, 3000),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.5, log=True),\n",
    "            'depth': trial.suggest_int('depth', 3, 16),\n",
    "            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 10.0, log=True),\n",
    "            'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'MVS']),\n",
    "            'random_strength': trial.suggest_float('random_strength', 1e-8, 10.0, log=True),\n",
    "            'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "            'od_type': trial.suggest_categorical('od_type', ['IncToDec', 'Iter']),\n",
    "            'od_wait': trial.suggest_int('od_wait', 10, 50),\n",
    "            'task_type': device,\n",
    "            'verbose': False,\n",
    "            'random_seed': 42\n",
    "        }\n",
    "        \n",
    "        # Add bootstrap-specific parameters\n",
    "        if params['bootstrap_type'] == 'Bayesian':\n",
    "            params['bagging_temperature'] = trial.suggest_float('bagging_temperature', 0.0, 1.0)\n",
    "        elif params['bootstrap_type'] == 'Bernoulli':\n",
    "            params['subsample'] = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "        \n",
    "        model = CatBoostRegressor(**params)\n",
    "        try:\n",
    "            scores = cross_val_score(\n",
    "                model, X_train, y_train,\n",
    "                cv=5,\n",
    "                scoring=make_scorer(custom_score, greater_is_better=True),\n",
    "                n_jobs=1\n",
    "            )\n",
    "            return -scores.mean()\n",
    "        except Exception as e:\n",
    "            print(f\"Error in CatBoost trial: {e}\")\n",
    "            return float('inf')\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "    return study.best_params\n",
    "\n",
    "def create_feature_importance_plot(model, feature_names, model_name, top_n=20):\n",
    "    \"\"\"Create and save feature importance plot\"\"\"\n",
    "    if not hasattr(model, 'feature_importances_'):\n",
    "        print(f\"Model {model_name} doesn't have feature_importances_ attribute\")\n",
    "        return None\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False).head(top_n)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(data=importance_df, x='importance', y='feature', palette='viridis')\n",
    "    plt.title(f'{model_name} - Top {top_n} Feature Importance')\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_filename = f'{model_name.lower()}_feature_importance.png'\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()  # Important for memory management\n",
    "    \n",
    "    print(f\"Feature importance plot saved to {plot_filename}\")\n",
    "    return plot_filename\n",
    "\n",
    "\n",
    "\n",
    "def train_model_with_memory_management(model_class, params, data_prep, model_name, use_scaled=True):\n",
    "    \"\"\"\n",
    "    Train a single model with proper memory management\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training {model_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    initial_memory = get_memory_usage()\n",
    "    print(f\"Initial memory: {initial_memory:.1f} MB\")\n",
    "    \n",
    "    # Choose appropriate data version\n",
    "    if use_scaled and 'scaled' in data_prep['data_versions']:\n",
    "        data_version = data_prep['data_versions']['scaled']\n",
    "        print(f\"Using scaled data for {model_name}\")\n",
    "    else:\n",
    "        data_version = data_prep['data_versions']['original']\n",
    "        print(f\"Using original data for {model_name}\")\n",
    "    \n",
    "    X_train = data_version['X_train']\n",
    "    X_test = data_version['X_test']\n",
    "    y_train = data_prep['y_train']\n",
    "    y_test = data_prep['y_test']\n",
    "    \n",
    "    # Add model-specific verbose settings\n",
    "    if model_class.__name__ == 'LGBMRegressor':\n",
    "        params['verbose'] = -1\n",
    "    elif model_class.__name__ == 'CatBoostRegressor':\n",
    "        params['verbose'] = False\n",
    "    \n",
    "    # Initialize and train model\n",
    "    model = model_class(**params, random_state=42)\n",
    "    \n",
    "    print(f\"Training {model_name}...\")\n",
    "    training_memory = get_memory_usage()\n",
    "    \n",
    "    # Train with categorical features for CatBoost\n",
    "    if model_class.__name__ == 'CatBoostRegressor' and data_prep['categorical_columns']:\n",
    "        # Map categorical column names to indices\n",
    "        cat_feature_indices = [i for i, col in enumerate(data_prep['feature_list']) \n",
    "                              if col in data_prep['categorical_columns']]\n",
    "        model.fit(X_train, y_train, cat_features=cat_feature_indices)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    post_training_memory = get_memory_usage()\n",
    "    print(f\"Memory during training: {training_memory:.1f} MB\")\n",
    "    print(f\"Memory after training: {post_training_memory:.1f} MB\")\n",
    "    print(f\"Training memory increase: {post_training_memory - training_memory:.1f} MB\")\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'mse': mean_squared_error(y_test, y_pred),\n",
    "        'rmse': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        'mae': mean_absolute_error(y_test, y_pred),\n",
    "        'r2': r2_score(y_test, y_pred),\n",
    "        'mape': np.mean(np.abs((y_test - y_pred) / np.maximum(np.abs(y_test), 1e-8))) * 100,  # Fixed division by zero\n",
    "        'max_error': np.max(np.abs(y_test - y_pred)),\n",
    "        'explained_variance': 1 - np.var(y_test - y_pred) / np.var(y_test)\n",
    "    }\n",
    "\n",
    "    # Create feature importance plot\n",
    "    plot_filename = create_feature_importance_plot(\n",
    "        model, \n",
    "        data_prep['feature_list'], \n",
    "        model_name, \n",
    "        top_n=min(20, len(data_prep['feature_list']))\n",
    "    )\n",
    "    \n",
    "    # Add to result dictionary:\n",
    "   \n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric.upper()}: {value:.6f}\")\n",
    "    \n",
    "    final_memory = get_memory_usage()\n",
    "    print(f\"Final memory: {final_memory:.1f} MB\")\n",
    "    print(f\"Total memory increase: {final_memory - initial_memory:.1f} MB\")\n",
    "    \n",
    "    # Save model with memory-efficient approach\n",
    "    model_filename = f'best_{model_name.lower()}_model.pkl'\n",
    "    joblib.dump(model, model_filename)\n",
    "    print(f\"Model saved to {model_filename}\")\n",
    "\n",
    "    preprocessing_objects = {\n",
    "        'scaler': data_prep.get('scaler'),\n",
    "        'label_encoders': data_prep['label_encoders'],\n",
    "        'feature_list': data_prep['feature_list'],\n",
    "        'categorical_columns': data_prep['categorical_columns'],\n",
    "        'target_name': data_prep['target_name']\n",
    "    }\n",
    "    preprocessing_filename = f'{model_name.lower()}_preprocessing.pkl'\n",
    "    joblib.dump(preprocessing_objects, preprocessing_filename)\n",
    "    print(f\"Preprocessing objects saved to {preprocessing_filename}\")\n",
    "    \n",
    "    result = {\n",
    "        'model_name': model_name,\n",
    "        'metrics': metrics,\n",
    "        'params': params,\n",
    "        'feature_importance': model.feature_importances_ if hasattr(model, 'feature_importances_') else None,\n",
    "        'model_file': model_filename,\n",
    "        'preprocessing_file': preprocessing_filename,  \n",
    "        'importance_plot': plot_filename  \n",
    "    }\n",
    "    \n",
    "\n",
    "    del model, X_train, X_test\n",
    "    gc.collect()\n",
    "    \n",
    "    cleanup_memory = get_memory_usage()\n",
    "    print(f\"Memory after cleanup: {cleanup_memory:.1f} MB\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def compare_models_memory_efficient(data, features, target, models_to_compare=None, n_trials=100):\n",
    "    \"\"\"\n",
    "    Memory-efficient model comparison that processes one model at a time\n",
    "    \"\"\"\n",
    "    if models_to_compare is None:\n",
    "        models_to_compare = ['XGBoost', 'LightGBM', 'CatBoost']\n",
    "    \n",
    "    print(\"Starting memory-efficient model comparison...\")\n",
    "    print(f\"Initial system memory: {get_memory_usage():.1f} MB\")\n",
    "    \n",
    "    # Check GPU availability\n",
    "    xgb_device, lgb_device, cb_device = check_gpu_availability()\n",
    "    \n",
    "    # Prepare data once\n",
    "    print(\"\\nPreparing data...\")\n",
    "    data_prep = prepare_data_with_memory_management(data, features, target)\n",
    "    \n",
    "    # Store results without keeping models in memory\n",
    "    all_results = {}\n",
    "    \n",
    "    # Process each model individually\n",
    "    for model_name in models_to_compare:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing {model_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            if model_name == 'XGBoost':\n",
    "                # Optimize hyperparameters\n",
    "                print(f\"Optimizing XGBoost hyperparameters (n_trials={n_trials})...\")\n",
    "                best_params = optimize_xgboost(\n",
    "                    data_prep['data_versions']['scaled']['X_train'],\n",
    "                    data_prep['y_train'],\n",
    "                    n_trials,\n",
    "                    xgb_device\n",
    "                )\n",
    "                result = train_model_with_memory_management(\n",
    "                    XGBRegressor, best_params, data_prep, model_name, use_scaled=True\n",
    "                )\n",
    "            \n",
    "            elif model_name == 'LightGBM':\n",
    "                # Optimize hyperparameters\n",
    "                print(f\"Optimizing LightGBM hyperparameters (n_trials={n_trials})...\")\n",
    "                best_params = optimize_lightgbm(\n",
    "                    data_prep['data_versions']['scaled']['X_train'],\n",
    "                    data_prep['y_train'],\n",
    "                    n_trials,\n",
    "                    lgb_device\n",
    "                )\n",
    "                result = train_model_with_memory_management(\n",
    "                    LGBMRegressor, best_params, data_prep, model_name, use_scaled=True\n",
    "                )\n",
    "            \n",
    "            elif model_name == 'CatBoost':\n",
    "                # Optimize hyperparameters\n",
    "                print(f\"Optimizing CatBoost hyperparameters (n_trials={n_trials})...\")\n",
    "                best_params = optimize_catboost(\n",
    "                    data_prep['data_versions']['original']['X_train'],\n",
    "                    data_prep['y_train'],\n",
    "                    n_trials,\n",
    "                    cb_device,\n",
    "                    data_prep['categorical_columns']\n",
    "                )\n",
    "                result = train_model_with_memory_management(\n",
    "                    CatBoostRegressor, best_params, data_prep, model_name, use_scaled=False\n",
    "                )\n",
    "            \n",
    "            all_results[model_name] = result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error training {model_name}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Force garbage collection between models\n",
    "        gc.collect()\n",
    "        print(f\"Memory after {model_name} cleanup: {get_memory_usage():.1f} MB\")\n",
    "    \n",
    "    # Rank models by performance\n",
    "    if all_results:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"FINAL RESULTS\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        model_rankings = sorted(all_results.items(), key=lambda x: x[1]['metrics']['r2'], reverse=True)\n",
    "        \n",
    "        for i, (model_name, results) in enumerate(model_rankings, 1):\n",
    "            print(f\"{i}. {model_name}: R² = {results['metrics']['r2']:.6f}\")\n",
    "        \n",
    "        best_model_name = model_rankings[0][0]\n",
    "        best_metrics = model_rankings[0][1]['metrics']\n",
    "        \n",
    "        print(f\"\\nBest Model: {best_model_name}\")\n",
    "        print(f\"Best R² Score: {best_metrics['r2']:.6f}\")\n",
    "        print(f\"Best RMSE: {best_metrics['rmse']:.6f}\")\n",
    "        \n",
    "        # Save results summary\n",
    "        results_summary = {\n",
    "            'best_model': best_model_name,\n",
    "            'model_rankings': [(name, results['metrics']['r2']) for name, results in model_rankings],\n",
    "            'detailed_results': {name: results['metrics'] for name, results in all_results.items()}\n",
    "        }\n",
    "        \n",
    "        with open('model_comparison_results.json', 'w') as f:\n",
    "            json.dump(results_summary, f, indent=4)\n",
    "        \n",
    "        print(\"\\nResults saved to 'model_comparison_results.json'\")\n",
    "        \n",
    "        return all_results, best_model_name, best_metrics\n",
    "    \n",
    "    else:\n",
    "        print(\"No models were successfully trained!\")\n",
    "        return {}, None, None\n",
    "\n",
    "results, best_model, best_metrics = compare_models_memory_efficient(\n",
    "    data=enhanced_df,\n",
    "    features=[col for col in enhanced_df.columns if col != 'xG'],\n",
    "    target='xG',\n",
    "    n_trials=50  \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nComparison completed!\")\n",
    "if best_model:\n",
    "    print(f\"Best model: {best_model}\")\n",
    "    print(f\"Best R²: {best_metrics['r2']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d233f9",
   "metadata": {
    "papermill": {
     "duration": 0.02961,
     "end_time": "2025-05-26T22:56:18.196744",
     "exception": false,
     "start_time": "2025-05-26T22:56:18.167134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11962.93995,
   "end_time": "2025-05-26T22:56:21.147281",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-26T19:36:58.207331",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1b0d3254250d45de86e3f833e0447b8e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1d03996fb4924127936e252c4dc8f8e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c5814fab4d394e508b84fbc8bee29933",
       "placeholder": "​",
       "style": "IPY_MODEL_af164a17b8c543bc80a9c9a8a756f593",
       "value": " 50/50 [13:49&lt;00:00,  3.66s/it]"
      }
     },
     "3f55229a9ea5480c8e86419c1daa3e7d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4346ecbcbf244e4ab2b5572b1577b073": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f9e91511510e492290157735abc49e34",
       "max": 50.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9275be5f1be34c01b3cd20b2f5072125",
       "value": 50.0
      }
     },
     "5b59060793ab4b54a507eca7531c696f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3f55229a9ea5480c8e86419c1daa3e7d",
       "max": 50.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7152c729205440d39949070b6e8d8394",
       "value": 50.0
      }
     },
     "5fb095f8cf934fa3a1ee72660dc6e6c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "68fb3e8425e9427cbca495ce57da5f85": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f03f1a5402674c5bba7c1fc9e840d6b4",
       "placeholder": "​",
       "style": "IPY_MODEL_83567d45b76c41deb92703f1981ab44b",
       "value": " 50/50 [45:36&lt;00:00, 16.15s/it]"
      }
     },
     "7152c729205440d39949070b6e8d8394": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "74de3bf8fc774c4bafba96e187f99233": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7736b199b1274d6fb3b36b2b0df06ff9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7d43d55f2865405686f72debc8fdeb2c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "83567d45b76c41deb92703f1981ab44b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "85e195f5dee043019fb54a51f8b5e25e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8624921d674d4e388f547d92db5190cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_de490c0221dd491eba367afbd9b951cd",
       "placeholder": "​",
       "style": "IPY_MODEL_b6c123846b9e48a195e1c3d0eebeab6a",
       "value": "Best trial: 17. Best value: -2.63925: 100%"
      }
     },
     "8c07a4da19b740f78a7f52cab210c436": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "90d4a3ddb2da4e4894d0f603adce060a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9153c0c9f8ca470b9ef71d6da0ff76cf",
        "IPY_MODEL_4346ecbcbf244e4ab2b5572b1577b073",
        "IPY_MODEL_1d03996fb4924127936e252c4dc8f8e4"
       ],
       "layout": "IPY_MODEL_b60b8aaae3ee4f829cc514a5c9b53053"
      }
     },
     "9153c0c9f8ca470b9ef71d6da0ff76cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1b0d3254250d45de86e3f833e0447b8e",
       "placeholder": "​",
       "style": "IPY_MODEL_85e195f5dee043019fb54a51f8b5e25e",
       "value": "Best trial: 41. Best value: -2.62909: 100%"
      }
     },
     "9275be5f1be34c01b3cd20b2f5072125": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "92fcf06f9b744cb7a198a13144b5235f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a639f6f7b0e6477590f7c6d6ed1f3f97": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "af164a17b8c543bc80a9c9a8a756f593": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b60b8aaae3ee4f829cc514a5c9b53053": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b6c123846b9e48a195e1c3d0eebeab6a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b8e96d2e490d4ba7883fd4b33d9a72b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8624921d674d4e388f547d92db5190cf",
        "IPY_MODEL_5b59060793ab4b54a507eca7531c696f",
        "IPY_MODEL_d5d87311c767487cbc880166d8e7efb8"
       ],
       "layout": "IPY_MODEL_a639f6f7b0e6477590f7c6d6ed1f3f97"
      }
     },
     "bd68888279684f0984247cdeb8da0707": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8c07a4da19b740f78a7f52cab210c436",
       "placeholder": "​",
       "style": "IPY_MODEL_5fb095f8cf934fa3a1ee72660dc6e6c4",
       "value": "Best trial: 32. Best value: -2.63926: 100%"
      }
     },
     "c3f97b77bf9c446197a08cf165c5003a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c5814fab4d394e508b84fbc8bee29933": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d5d87311c767487cbc880166d8e7efb8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_92fcf06f9b744cb7a198a13144b5235f",
       "placeholder": "​",
       "style": "IPY_MODEL_c3f97b77bf9c446197a08cf165c5003a",
       "value": " 50/50 [49:55&lt;00:00, 64.25s/it]"
      }
     },
     "de490c0221dd491eba367afbd9b951cd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f03f1a5402674c5bba7c1fc9e840d6b4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f29655fc8c2542e1bddd2e82eeb762c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7d43d55f2865405686f72debc8fdeb2c",
       "max": 50.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7736b199b1274d6fb3b36b2b0df06ff9",
       "value": 50.0
      }
     },
     "f75dd7e5b20c4ed588c8e8115eb9b70c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bd68888279684f0984247cdeb8da0707",
        "IPY_MODEL_f29655fc8c2542e1bddd2e82eeb762c7",
        "IPY_MODEL_68fb3e8425e9427cbca495ce57da5f85"
       ],
       "layout": "IPY_MODEL_74de3bf8fc774c4bafba96e187f99233"
      }
     },
     "f9e91511510e492290157735abc49e34": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
